Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@misc{spfibre,
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - ECSS-E-ST-50-11C – SpaceFibre – Very high-speed serial link (15 May 2019) European Cooperation for Space Standa.pdf:pdf},
institution = {European Cooperation for Space Standardization},
title = {{SpaceFibre – Very high-speed serial link}},
url = {https://ecss.nl/standard/ecss-e-st-50-11c-spacefibre-very-high-speed-serial-link/},
year = {2019}
}
@inproceedings{Hund2010,
abstract = {Especially for synchronization-critical wireless networks like ultrawideband impulse radio (UWB-IR), data packets are lost not only due to single bit errors in the payload but also to a large degree because of synchronization errors or preamble failures. Current FEC codes only address bit errors inside a packet. Packets that are lost because of errors in preambles or headers can only be recovered on packet level. In this Paper we propose a low-complexity adaptive packet-level FEC and prove by simulation that it can reduce packet loss with very small overhead. {\textcopyright} 2010 IEEE.},
author = {Hund, Johannes and Heinrich, Andreas and Ziller, Andreas and Schwingenschl{\"{o}}gl, Christian and Kraemer, Rolf},
booktitle = {Proceedings of the 2010 7th Workshop on Positioning, Navigation and Communication, WPNC'10},
doi = {10.1109/WPNC.2010.5653666},
isbn = {9781424471577},
keywords = {Erasure coding,FEC,IEEE 802.15.4a,UWB},
pages = {1--3},
title = {{A packet-level adaptive forward error correction scheme for wireless networks}},
year = {2010}
}
@techreport{Roca2006a,
author = {Roca, Vincent and Neumann, Christoph},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roca, Neumann - 2006 - Design, Evaluation and Comparison of Four Large Block FEC Codecs, LDPC, LDGM, LDGM Staircase and LDGM Triangle, p.pdf:pdf},
title = {{Design, Evaluation and Comparison of Four Large Block FEC Codecs, LDPC, LDGM, LDGM Staircase and LDGM Triangle, plus a Reed-Solomon Small Block FEC Codec}},
url = {https://hal.inria.fr/inria-00070770},
year = {2006}
}
@incollection{DeCola2008,
author = {{De Cola}, Tomaso and Ernst, Harald and Marchese, Mario},
doi = {10.1007/978-0-387-47524-0_49},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Cola, Ernst, Marchese - 2008 - Application of Long Erasure Codes and ARQ Schemes for Achieving High Data Transfer Performance Over Lo.pdf:pdf},
pages = {643--656},
title = {{Application of Long Erasure Codes and ARQ Schemes for Achieving High Data Transfer Performance Over Long Delay Networks}},
url = {http://link.springer.com/10.1007/978-0-387-47524-0_49},
year = {2008}
}
@article{HaibinZhang2008,
annote = {Not applicable to our},
author = {{Haibin Zhang} and {Jia Zhu} and {Huifeng Shi} and {Dawei Wang}},
doi = {10.1109/TCSI.2008.916433},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haibin Zhang et al. - 2008 - Layered Approx-Regular LDPC Code Construction and EncoderDecoder Design.pdf:pdf},
issn = {1549-8328},
journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
month = {mar},
number = {2},
pages = {572--585},
title = {{Layered Approx-Regular LDPC: Code Construction and Encoder/Decoder Design}},
url = {http://ieeexplore.ieee.org/document/4432803/},
volume = {55},
year = {2008}
}
@techreport{Stream2010,
institution = {ARM},
title = {{AMBA AXI4-Stream Protocol Specification v1.0}},
url = {http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.ihi0051a/index.html},
year = {2010}
}
@article{Mahdi2014,
annote = {-U,L are not based on circulants
-U,L are random, the exhibit no structure
=> No storage compression possible
=> VMM architecture not applicable
-This leaves us only with fully parallel option
=>Critical path (from Octave search): log2(504)=9
=>BUT: gates required: 1536(H1T)+423040(L)+144409(U)=568985},
author = {Mahdi, Ahmed and Paliouras, Vassilis},
doi = {10.1109/TSP.2014.2314435},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahdi, Paliouras - 2014 - A Low Complexity-High Throughput QC-LDPC Encoder.pdf:pdf},
issn = {1053-587X},
journal = {IEEE Transactions on Signal Processing},
month = {may},
number = {10},
pages = {2696--2708},
title = {{A Low Complexity-High Throughput QC-LDPC Encoder}},
url = {http://ieeexplore.ieee.org/document/6781047/},
volume = {62},
year = {2014}
}
@article{Bocharova2019,
abstract = {A new method is presented for low-complexity near-maximum-likelihood (ML) decoding of low-density parity-check (LDPC) codes over the additive white Gaussian noise channel. The proposed method termed belief-propagation-list erasure decoding (BP-LED) is based on erasing carefully chosen unreliable bits performed in case of BP decoding failure. A strategy of introducing erasures into the received vector and a new erasure decoding algorithm are proposed. The new erasure decoding algorithm, called list erasure decoding, combines ML decoding over the BEC with list decoding applied if the ML decoder fails to find a unique solution. The asymptotic exponent of the average list size for random regular LDPC codes from the Gallager ensemble is analyzed. Furthermore, a few examples of irregular quasi-cyclic LDPC as well as randomly constructed regular LDPC codes of short and moderate lengths are studied by simulations and their performance is compared to the tightened upper bound on the LDPC ensemble-average performance and the upper bound on the average performance of random linear codes under ML decoding. A comparison of the BP decoding and BP-LED performance of the WiMAX standard codes and performance of the near-ML BEAST decoding are presented. The new algorithm is applied to decoding a short nonbinary (NB) LDPC code over extensions of the binary Galois field. The obtained simulation results are compared to the tightened upper bound on the ensemble-average performance of the binary image of regular NB LDPC codes.},
archivePrefix = {arXiv},
arxivId = {1705.09507},
author = {Bocharova, Irina E. and Kudryashov, Boris D. and Skachek, Vitaly and Yakimenka, Yauhen},
doi = {10.1109/TIT.2018.2866879},
eprint = {1705.09507},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bocharova et al. - 2019 - BP-LED decoding algorithm for LDPC Codes over AWGN channels.pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Channel coding,iterative decoding,low-density parity-check codes,maximum-likelihood decoding},
month = {mar},
number = {3},
pages = {1677--1693},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{BP-LED decoding algorithm for LDPC Codes over AWGN channels}},
volume = {65},
year = {2019}
}
@article{Paolini2012,
author = {Paolini, Enrico and Liva, Gianluigi and Matuz, Balazs and Chiani, Marco},
doi = {10.1109/TCOMM.2012.081012.110363},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paolini et al. - 2012 - Maximum Likelihood Erasure Decoding of LDPC Codes Pivoting Algorithms and Code Design.pdf:pdf},
issn = {0090-6778},
journal = {IEEE Transactions on Communications},
month = {nov},
number = {11},
pages = {3209--3220},
title = {{Maximum Likelihood Erasure Decoding of LDPC Codes: Pivoting Algorithms and Code Design}},
url = {http://ieeexplore.ieee.org/document/6266770/},
volume = {60},
year = {2012}
}
@article{Dimitrov2016,
abstract = {In this paper, a packet-level forward error correction coding technique and pre-distortion adaptive optics technology are applied to a digital transmission scheme for optical feeder links in a geostationary Earth orbit satellite communication system. The architectures of the gateway and the satellite are defined, including the building blocks of the interface between the radio frequency front-end and the optical front-end, as well as the digital signal processor. The system is designed to cater for Terabit/s high-throughput satellite applications. The performance of the digital transmission scheme is evaluated in the forward and return links. The turbulent atmospheric optical channel is modeled for different optical ground station altitudes. It is shown that fade mitigation techniques such as packet-level forward error correction coding and pre-distortion adaptive optics in the forward link, as well as large-aperture optical ground station telescope in the return link, are essential to close the link budget of a Terabit/s satellite communication system. Copyright {\textcopyright} 2015 John Wiley & Sons, Ltd.},
author = {Dimitrov, Svilen and Barrios, Ricardo and Matuz, Balazs and Liva, Gianluigi and Mata-Calvo, Ramon and Giggenbach, Dirk},
doi = {10.1002/sat.1163},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dimitrov et al. - 2016 - Digital modulation and coding for satellite optical feeder links with pre-distortion adaptive optics.pdf:pdf},
issn = {15420973},
journal = {International Journal of Satellite Communications and Networking},
keywords = {Terabit/s satellite communication,correlated fading,digital modulation,optical feeder link,packet-level coding,pre-distortion adaptive optics,scintillation,turbulent optical channel},
month = {sep},
number = {5},
pages = {625--644},
publisher = {John Wiley and Sons Ltd},
title = {{Digital modulation and coding for satellite optical feeder links with pre-distortion adaptive optics}},
url = {http://doi.wiley.com/10.1002/sat.1163},
volume = {34},
year = {2016}
}
@article{Zhong2007,
abstract = {By implementing a field-programmable gate array (FPGA)-based simulator, we investigate the performance of randomly constructed high-rate quasi-cyclic (QC) low-density parity-check (LDPC) codes for the magnetic recording channel at very low block sector error rates. On the basis of extensive simulations, we conjecture guidelines for designing randomly constructed high-rate regular QC-LDPC codes with low error floor for the magnetic recording channel. Experimental results show that our high-rate regular QC-LDPC codes do not suffer from error floor, at least at block error rates of 10-9 , and can realize significant coding gains over Reed-Solomon codes that are used in current practice. Furthermore, we develop a QC-LDPC decoder hardware architecture that is well suited to achieving high decoding throughput. Finally, to evaluate the implementation feasibility of LDPC codes for the magnetic recording channel, using 0.13 $\mu$m standard cell and memory libraries, we designed a read channel signal processing datapath consisting of a parallel max-log-MAP detector and a QC-LDPC decoder, which can achieve a throughput up to 1.8 Gb/s. {\textcopyright} 2007 IEEE.},
annote = {Another for MR-hardware aware},
author = {Zhong, Hao and Zhong, Tong and Haratsch, Erich F.},
doi = {10.1109/TMAG.2006.888607},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhong, Zhong, Haratsch - 2007 - Quasi-cyclic LDPC codes for the magnetic recording channel Code design and VLSI implementation.pdf:pdf},
issn = {00189464},
journal = {IEEE Transactions on Magnetics},
keywords = {Decoder,Error floor,LDPC,VLSI architecture},
month = {mar},
number = {3},
pages = {1118--1123},
title = {{Quasi-cyclic LDPC codes for the magnetic recording channel: Code design and VLSI implementation}},
volume = {43},
year = {2007}
}
@inproceedings{ZhaohuiWangXinHaoChangxingLin2018,
address = {Chongqing},
annote = {FUCK THEM UP!!!!!},
author = {{Zhaohui Wang, Xin Hao, Changxing Lin}, Qiuyu Wu},
booktitle = {2018 IEEE 18th International Conference on Communication Technology (ICCT)},
doi = {10.1109/ICCT.2018.8599970},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhaohui Wang, Xin Hao, Changxing Lin - 2018 - An Efficient Hardware LDPC Encoder Based on Partial Parallel Structure for CCSDS.pdf:pdf},
pages = {136--139},
publisher = {IEEE},
title = {{An Efficient Hardware LDPC Encoder Based on Partial Parallel Structure for CCSDS}},
url = {https://ieeexplore.ieee.org/document/8599970},
year = {2018}
}
@article{Tseng2015,
abstract = {In this letter, we present a low-complexity encoding method for quasi-cyclic (QC) low-density parity-check (LDPC) codes in the case of non-full-rank parity-check matrices. Gaussian elimination can achieve systematic encoding, but it is usually too complex to implement. For QC-LDPC codes, efficient encoding methods have been presented by using shift-registers, but the encoded codewords are not systematic when parity-check matrices are non-full-rank. However, a systematic structure is important in practice. Therefore, we propose an encoding method which allows all information bits appear piecewise in the codeword, called piecewise systematic encoding.},
author = {Tseng, Chien Fu and Tarng, Jenn Hwan},
doi = {10.1109/LCOMM.2015.2411255},
issn = {10897798},
journal = {IEEE Communications Letters},
title = {{Low-complexity and piecewise systematic encoding of non-full-rank QC-LDPC codes}},
year = {2015}
}
@book{Parkes2012,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
author = {Parkes, Steve},
file = {:hd/di/spacefibre/SpaceWire-Users-Guide.pdf:pdf},
isbn = {9780957340800},
pages = {117},
publisher = {Star-Dundee},
title = {{SpaceWire User's Guide}},
year = {2012}
}
@misc{iprium2014,
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - LDPC NASA EncoderDecoder IP Core Specifccaton.pdf:pdf},
title = {{LDPC NASA Encoder/Decoder IP Core Specifccaton}},
url = {https://www.iprium.com/bins/pdf/iprium_ug_ldpc_nasa_codec.pdf}
}
@article{Miles2006,
annote = {The patent!},
author = {Miles, L.H. and Gambles, J.W. and Maki, G.K. and Ryan, W.E. and Whitaker, S.R.},
doi = {10.1109/JSSC.2006.877253},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miles et al. - 2006 - An 860-Mbs (8158,7136) Low-Density Parity-Check Encoder.pdf:pdf},
issn = {0018-9200},
journal = {IEEE Journal of Solid-State Circuits},
month = {aug},
number = {8},
pages = {1686--1691},
title = {{An 860-Mb/s (8158,7136) Low-Density Parity-Check Encoder}},
url = {http://ieeexplore.ieee.org/document/1661745/},
volume = {41},
year = {2006}
}
@misc{openFec,
title = {{OpenFEC.org – home}},
url = {http://openfec.org/},
urldate = {2021-04-11}
}
@article{GuilleniFabregas2006,
abstract = {In this correspondence, we study an M-ary block-erasure channel with B blocks, where with probability $\epsilon$ a block of L coded symbols is erased. The behavior of the error probability of coded systems over such channels is studied, and we show that, if the code is diversity-wise maximum-distance separable, its word error probability is equal to the outage probability, which admits a very simple expression. This correspondence is intended to complement the error probability analysis in previous work by Lapidoth and shed some light on the design of coding schemes for nonergodic channels. {\textcopyright} 2006 IEEE.},
author = {{Guill{\'{e}}n i F{\`{a}}bregas}, Albert},
doi = {10.1109/TIT.2006.883556},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guill{\'{e}}n i F{\`{a}}bregas - 2006 - Coding in the block-erasure channel.pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Diversity,Erasure channels,Error probability,Maximum-distance separable (MDS) codes,Maximum-likelihood (ML) decoding,Non-ergodic channels,Outage probability},
month = {nov},
number = {11},
pages = {5116--5121},
title = {{Coding in the block-erasure channel}},
volume = {52},
year = {2006}
}
@book{MacKay2003,
abstract = {1. Introduction to information theory -- 2. Probability, entropy, and inference -- 3. More about inference -- Part I. Data compression. 4. The source coding theorem -- 5. Symbol codes -- 6. Stream codes -- 7. Codes for integers -- Part II. Noisy-channel coding. 8. Correlated random variables -- 9. Communication over a noisy channel -- 10. The noisy-channel coding theorem -- 11. Error-correcting codes and real channels -- Part III. Further topics in information theory. 12. Hash codes: codes for efficient information retrieval -- 13. Binary codes -- 14. Very good linear codes exist -- 15. Further exercises on information theory -- 16. Message passing -- 17. Communication over constrained noiseless channels -- 18. An aside: crosswords and codebreaking -- 19. Why have sex? Information acquisition and evolution -- Part IV. Probabilities and inference. 20. An example inference task: clustering -- 21. Exact inference by complete enumeration -- 22. Maximum likelihood and clustering -- 23. Useful probability distributions -- 24. Exact marginalization -- 25. Exact marginalization in trellises -- 26. Exact marginalization in graphs -- 27. Laplace's method -- 28. Model comparison and Occam's razor -- 29. Monte Carlo methods -- 30. Efficient Monte Carlo methods -- 31. Ising models -- 32. Exact Monte Carlo sampling -- 33. Variational methods -- 34. Independent component analysis and latent variable modelling -- 35. Random inference topics -- 36. Decision theory -- 37. Bayesian inference and sampling theory -- Part V. Neural networks. 38. Introduction to neural networks -- 39. The single neuron as a classifier -- 40. Capacity of a single neuron -- 41. Learning as inference -- 42. Hopfield networks -- 43. Boltzmann machines -- 44. Supervised learning in multilayer networks -- 45. Gaussian processes -- 46. Deconvolution -- Part VI. Sparse graph codes. 47. Low-density parity-check codes -- 48. Convolutional codes and turbo codes -- 49. Repeat-accumulate codes -- 50. Digital fountain codes -- Part VII. Appendices. A. Notation -- B. Some physics -- C. Some mathematics.},
author = {MacKay, David J. C. and C., David J.},
isbn = {0521642981},
pages = {628},
publisher = {Cambridge University Press},
title = {{Information theory, inference, and learning algorithms}},
url = {https://dl.acm.org/citation.cfm?id=971143},
year = {2003}
}
@inproceedings{Lee2004,
abstract = {We describe a flexible hardware encoder for regular and irregular low-density parity-check (LDPC) codes. Although LDPC codes achieve achieve better performance and lower decoding complexity than Turbo codes, a major drawback of LDPC codes is their apparently high encoding complexity. Using an efficient encoding method proposed by Richardson and Urbanke, we present a hardware LDPC encoder with linear encoding complexity. The encoder is flexible, supporting arbitrary H matrices, rates and block lengths. An implementation for a rate 1/2 irregular length 2000 LDPC code encoder on a Xilinx Virtex-II XC2V4000-6 FPGA takes up 4% of the device. It runs at 143MHz and has a throughput of 45 million codeword bits per second (or 22 million information bits per second) with a la-tency of 0.18ms. The performance can be improved by exploiting parallelism: several instances of the encoder can be mapped onto the same chip to encode multiple message blocks concurrently. An implementation of 16 instances of the encoder on the same device at 82MHz is capable of 410 million codeword bits per second, 80 times faster than an Intel Pentium-IV 2.4GHz PC.},
annote = {RU method on non-QC codes, using forward substitution on sparse matrices
Lower-triangular matrices
Very low throughput},
author = {Lee, Dong-U and Luk, Wayne and Wang, Connie and Jones, Christopher and Smith, Michael and Villasenor, John},
booktitle = {12th Annual IEEE Symposium on Field-Programmable Custom Computing Machines},
doi = {10.1109/FCCM.2004.4},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2004 - A Flexible Hardware Encoder for Low-Density Parity-Check Codes.pdf:pdf},
pages = {101--111},
publisher = {ΙΕΕΕ},
title = {{A Flexible Hardware Encoder for Low-Density Parity-Check Codes}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.86.9061&rep=rep1&type=pdf},
year = {2004}
}
@inproceedings{Ren2018,
abstract = {This article mainly proposes a high-speed encoding and decoding method for LDPC code on FPGA. This method converts a quasi-cyclic LDPC code into a block quasi-cyclic LDPC code, and uses a similar transformation to generate a corresponding generator matrix, thereby improving the parallelism of encoder and decoder and making them have high throughput. Finally, we implemented high-speed encoding and decoding on the FPGA chip of the Kintex7 system by using the CCSDS-recommended (8176, 7154) LDPC code, and these encoder and decoder achieve a throughput of 2.97 Gbps under the condition of 5 iterations.},
author = {Ren, Weiji and Liu, Hao},
booktitle = {2018 10th International Conference on Communication Software and Networks, ICCSN 2018},
doi = {10.1109/ICCSN.2018.8488239},
isbn = {9781538672235},
keywords = {LDPC code,high throughput,quasi-cyclic LDPC code},
month = {oct},
pages = {427--432},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{The Design and Implementation of High-Speed Codec Based on FPGA}},
year = {2018}
}
@article{Alessi2020,
abstract = {Interplanetary networks are affected by long propagation delays, intermittent connectivity, possible packet losses due to residual errors, and other impairments. To cope with these challenges, the delay-/disruption-tolerant networking (DTN) architecture utilizes the Licklider transmission protocol (LTP) as convergence layer on space links. The LTP reliable service (red) relies on Automatic Repeat reQuest, but very long propagation delays make packet layer forward error correcting (PL-FEC) codes very appealing to protect LTP segments from losses. The key advantage of FEC is that LTP retransmissions would be limited to the unlikely case of decoding failures. To this end, a new FEC-based protocol, to be inserted immediately below LTP, the erasure coding link service adapter (ECLSA), is presented here. ECLSA is completely transparent to LTP, relies on two alternative external libraries for coding/decoding, LibecDLR and OpenFEC, both using low density parity check codes and it is fully integrated with the ION DTN software package of NASA-JPL. This paper aims to provide a solid description of ECLSA, including features functional in a real deployment (such as the dynamic selection of codes). Performance is evaluated at the end of the paper, with nearly ideal results. ECLSA is released as free software and is already included in the 'contrib' section of ION.},
annote = {RFC5170 are random codes (random different columns). We cannot use Fvn module for incidence calculations
ML (gaussian elim.) vs IT (trivial) decoding algorithm. We can use hybrid (start with IT and continue with ML)
Very important is Fig.13},
author = {Alessi, Nicola and Caini, Carlo and {De Cola}, Tomaso and Raminella, Marco},
doi = {10.1109/TAES.2019.2916271},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alessi et al. - 2020 - Packet Layer Erasure Coding in Interplanetary Links The LTP Erasure Coding Link Service Adapter.pdf:pdf},
issn = {15579603},
journal = {IEEE Transactions on Aerospace and Electronic Systems},
keywords = {Delay-/disruption-tolerant networking (DTN),InterPlanetary Networking (IPN),Licklider transmission protocol (LTP),low density parity check (LDPC) codes,upper layer forward error correcting (FEC)},
month = {feb},
number = {1},
pages = {403--414},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Packet Layer Erasure Coding in Interplanetary Links: The LTP Erasure Coding Link Service Adapter}},
volume = {56},
year = {2020}
}
@misc{lce01c2013,
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Small World Communications LCE01C CCSDS (8160,7136) LDPC Encoder.pdf:pdf},
title = {{Small World Communications LCE01C CCSDS (8160,7136) LDPC Encoder}},
url = {http://www.sworld.com.au},
year = {2013}
}
@article{Kaji2006,
author = {Kaji, Yuichi},
doi = {10.1093/ietfec/e89-a.10.2510},
journal = {IEICE Trans. Fundamentals Electron., Commun. Comput.Sci},
keywords = {LDPC codes,encoding algorithm,sparse matrix,triangular factorization},
number = {10},
title = {{Encoding LDPC Codes Using the Triangular Factorization}},
year = {2006}
}
@article{Luby2001,
abstract = {We introduce a simple erasure recovery algorithm for codes derived from cascades of sparse bipartite graphs and analyze the algorithm by analyzing a corresponding discrete-time random process. As a result, we obtain a simple criterion involving the fractions of nodes of different degrees on both sides of the graph which is necessary and sufficient for the decoding process to finish successfully with high probability. By carefully designing these graphs we can construct for any given rate R and any given real number $\epsilon$ a family of linear codes of rate R which can be encoded in time proportional to ln(1/$\epsilon$) times their block length n. Furthermore, a codeword can be recovered with high probability from a portion of its entries of length (1 + $\epsilon$) Rn or more. The recovery algorithm also runs in time proportional to n ln(1/$\epsilon$). Our algorithms have been implemented and work well in practice; various implementation issues are discussed.},
annote = {They propose a acscade parity bits structure. Experiment with packet level code 640k packets 256 bytes each, rate 1/2},
author = {Luby, Michael G. and Mitzenmacher, Michael and Shokrollahi, M. Amin and Spielman, Daniel A.},
doi = {10.1109/18.910575},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luby et al. - 2001 - Efficient erasure correcting codes.pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Erasure channel,Large deviation analysis,Low-density parity-check codes},
number = {2},
pages = {569--584},
title = {{Efficient erasure correcting codes}},
volume = {47},
year = {2001}
}
@inproceedings{Chen2016,
abstract = {For two-way relay channel-coded physical network coding (CPNC) systems with sufficiently low code rate, the separate complete decoding (SCD) scheme outperforms the joint channel-physical network coding (JCNC) scheme. Hence, this paper addresses the design of protograph LDPC codes to approach the SCD-based CPNC capacity. In fact, due to virtual erasures induced by CPNC transmission, the conventional protograph that approaches point to point (P2P) AWGN capacity may not perform well in SCD-based CPNC channel in terms of error rates. We then use the finite-length EXIT chart to calculate iterative decoding threshold of a joint code graph formed by two codes in the SCD. Furthermore, we investigate the serial separate complete decoding (S-SCD) and parallel separate decoding (P-SCD). Simulation results show that with the S-SCD, the proposed protograph codes have within 0.9 dB of their capacity limits for rates from 1/3 to 3/5.},
author = {Chen, Pingping and Su, Kaixiong and Fang, Yi and Kong, Lingjun},
booktitle = {IEEE International Symposium on Personal, Indoor and Mobile Radio Communications, PIMRC},
doi = {10.1109/PIMRC.2016.7794683},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2016 - The design of protograph LDPC codes for channel-coded physical-layer network coding.pdf:pdf},
isbn = {9781509032549},
keywords = {Physical-layer network coding,protograph code,separate complete decoding},
month = {dec},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{The design of protograph LDPC codes for channel-coded physical-layer network coding}},
year = {2016}
}
@misc{leon3,
title = {{LEON3}},
url = {https://www.gaisler.com/index.php/products/processors/leon3},
urldate = {2021-04-12}
}
@article{Liva2013a,
abstract = {In many applications erasure correcting codes are used to recover packet losses at high protocol stack layers. The objects (e.g. files) to be transmitted often have variable sizes, resulting in a variable number of packets to be encoded by the packet-level encoder. In this paper, algorithms for the (on-line) flexible design of parity-check matrices for irregular-repeat-accumulate codes are investigated. The proposed algorithms allow designing in fast manner parity-check matrices that are suitable for low-complexity maximum-likelihood decoding. The code ensembles generated by the algorithms are analyzed via extrinsic information transfer charts. Numerical results show how the designed codes can attain codeword error rates as low as 10^{-5} without appreciable losses w.r.t. the performance of idealized maximum-distance separable codes. Finally, we apply the proposed codes to the upcoming aeronautical communication standard, showing large performance improvements and proving the efficiency and the flexibility of the developed method. {\textcopyright} 2013 IEEE.},
author = {Liva, Gianluigi and Pulini, Paola and Chiani, Marco},
doi = {10.1109/TWC.2012.121412120053},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liva, Pulini, Chiani - 2013 - On-line construction of irregular repeat accumulate codes for packet erasure channels.pdf:pdf},
issn = {15361276},
journal = {IEEE Transactions on Wireless Communications},
keywords = {Fountain codes,aeronautical communications,erasure channel,low-density parity-check codes,reliable multicast},
number = {2},
pages = {680--689},
title = {{On-line construction of irregular repeat accumulate codes for packet erasure channels}},
volume = {12},
year = {2013}
}
@article{JTC2014,
abstract = {Siret N° 348 623 562 00017-NAF 742 C Association {\`{a}} but non lucratif enregistr{\'{e}}e {\`{a}} la Sous-Pr{\'{e}}fecture de Grasse (06) N° 7803/88},
author = {{Digital Video Broadcasting/ETSI}},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Digital Video BroadcastingETSI - 2014 - Second generation framing structure, channel coding and modulation systems for Broadcasting, Int.pdf:pdf},
journal = {European Standard (Telecommunications series)},
keywords = {BSS,DVB,TV,digital,modulation,satellite},
title = {{Second generation framing structure, channel coding and modulation systems for Broadcasting, Interactive Services, News Gathering and other broadband satellite applications; Part 1: DVB-S2}},
volume = {1.},
year = {2014}
}
@article{ZongwangLi2006,
annote = {-Serial SRAA is the naive approach described in standard. More registers would be needed for pipelined operation. Circuits for loading circulants not taken into account
-Parallel SRAA calculates one parity bit from all input bits. Cannot scale well in practical applications
-Two stage CASE1 is in effect H2inv * H1
-Two stage CASE2 is the same as case 1, for non full-rank (C2), but degenerates to case 1 for C2},
author = {{Zongwang Li} and {Lei Chen} and {Lingqi Zeng} and Lin, S. and Fong, W.H.},
doi = {10.1109/TCOMM.2005.861667},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zongwang Li et al. - 2006 - Efficient encoding of quasi-cyclic low-density parity-check codes.pdf:pdf},
issn = {0090-6778},
journal = {IEEE Transactions on Communications},
month = {jan},
number = {1},
pages = {71--81},
title = {{Efficient encoding of quasi-cyclic low-density parity-check codes}},
url = {http://ieeexplore.ieee.org/document/1576951/},
volume = {54},
year = {2006}
}
@techreport{CCSDS141,
author = {CCSDS141.11-O-1},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/CCSDS141.11-O-1 - 2018 - Optical High Data Rate ( Hdr ) Communication — 1064 nm Optical High Data Rate ( Hdr ) Communication —.pdf:pdf},
institution = {CCSDS},
number = {December},
title = {{Optical High Data Rate ( Hdr ) Communication — 1064 nm Optical High Data Rate ( Hdr ) Communication —}},
year = {2018}
}
@techreport{Thorpe2003,
abstract = {We introduce a new class of low-density parity-check (LDPC) codes constructed from a template called a protograph. The protograph serves as a blueprint for constructing LDPC codes of arbitrary size whose performance can be predicted by analyzing the protograph. We apply standard density evolution techniques to predict the performance of large protograph codes. Finally, we use a randomized search algorithm to find good protographs.},
author = {Thorpe, J},
booktitle = {IPNPR},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thorpe - 2003 - Low-Density Parity-Check (LDPC) Codes Constructed from Protographs.pdf:pdf},
pages = {1--7},
title = {{Low-Density Parity-Check (LDPC) Codes Constructed from Protographs}},
volume = {42-154},
year = {2003}
}
@misc{ion,
title = {{ION-DTN}},
url = {https://sourceforge.net/projects/ion-dtn/},
urldate = {2020-12-21}
}
@article{Paolini2006,
abstract = {In space communications, traditional error correction/detection techniques deliver to the upper layers of the communication stack only the data units for which integrity can be guaranteed. The uncorrectable data units are then "lost", and the upper layers have typically to face data units erasures. Hence, the packet erasure channel (PEC) is the most proper channel model from the point of view of the upper layers. Automatic re-peat/retransmission query (ARQ) is the "traditional" solution implemented at the upper layers in order to face data units erasures. However, ARQ is not always possible for space or satellite communications. In such situations, forward error correction (FEC) must be used. Nowadays new techniques for FEC are available also for application at the upper layers. Long erasure correcting (LEC) codes represent a new and very promising proposal for packet erasure FEC. They are able to overcome the complexity limitations of other types of codes, while preserving very good erasure correction capability. They are currently under investigation within the CCSDS (Consultative Committee for Space Data Systems) long erasure codes Bird of Feather (LEC-BOF), where a leading role has been so far played by ESA/ESOC and NASA-JPL. In this paper, the activity of the LEC-BOF is be illustrated. More in detail, the basic ideas behind LEC codes are presented, as well as the possible codes structures, the encoding and decoding rules, some theoretical properties. Some numerical results are presented, showing the performance of LEC codes on both memory-less and burst erasure channel.},
author = {Paolini, Enrico and Chiani, Marco and Calzolari, Gian Paolo},
doi = {10.2514/6.2006-5827},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paolini, Chiani, Calzolari - 2006 - Long Erasure Correcting Codes the New Frontier for Zero Loss in Space Applications.pdf:pdf},
title = {{Long Erasure Correcting Codes: the New Frontier for Zero Loss in Space Applications?}},
url = {http://arc.aiaa.org},
year = {2006}
}
@article{Tsigkanos2020,
abstract = {Nowadays, hyperspectral imaging is recognized as a cornerstone remote sensing technology. Next generation, high-speed airborne, and space-borne imagers have increased resolution, resulting in an explosive growth in data volume and instrument data rate in the range of gigapixel per second. This competes with limited on-board resources and bandwidth, making hyperspectral image compression a mission critical on-board processing task. At the same time, the 'new space' trend is emerging, where launch costs decrease, and agile approaches are exploited building smallsats using commercial-off-the-shelf (COTS) parts. In this contribution, we introduce a high-performance parallel implementation of the CCSDS-123.0-B-1 hyperspectral compression algorithm targeting SRAM field-programmable gate array (FPGA) technology. The architecture exploits image segmentation to provide the robustness to data corruption and enables scalable throughput performance by leveraging segment-level parallelism. Furthermore, we exploit the capabilities of a COTS FPGA system-on-chip (SoC) device to optimize size, weight, power, and cost (SWaP-C). The architecture partitions a hyperspectral cube stored in a DRAM framebuffer into segments, compressing them in parallel using a flexible software scheduler hosted in the SoC CPU and several compressor accelerator cores in the FPGA fabric. A 5-core implementation demonstrated on a Zynq-7045 FPGA achieves a throughput performance of 1387 Msamples/s [22.2 Gb/s at 16 bits per pixel per band (bpppb)] and outperforms previous implementations in equivalent FPGA technology, allowing seamless integration with next-generation hyperspectral sensors.},
author = {Tsigkanos, Antonis and Kranitis, Nektarios and Theodoropoulos, DImitris and Paschalis, Antonios},
doi = {10.1109/TVLSI.2020.3020164},
issn = {15579999},
journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
keywords = {Consultative Committee for Space Data Systems (CCS,field-programmable gate array (FPGA),hyperspectral compression,on-board data processing,system-on-chip (SoC)},
month = {nov},
number = {11},
pages = {2397--2409},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{High-Performance COTS FPGA SoC for Parallel Hyperspectral Image Compression with CCSDS-123.0-B-1}},
volume = {28},
year = {2020}
}
@inproceedings{Kopparthi2007,
annote = {802.16e},
author = {Kopparthi, Sunitha and Gruenbacher, Don M.},
booktitle = {2007 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing},
doi = {10.1109/PACRIM.2007.4313268},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kopparthi, Gruenbacher - 2007 - Implementation of a Flexible Encoder for Structured Low-Density Parity-Check Codes.pdf:pdf},
isbn = {1-4244-1190-4},
month = {aug},
pages = {438--441},
publisher = {IEEE},
title = {{Implementation of a Flexible Encoder for Structured Low-Density Parity-Check Codes}},
url = {http://ieeexplore.ieee.org/document/4313268/},
year = {2007}
}
@article{Brink2001,
abstract = {Mutual information transfer characteristics of soft in/soft out decoders are proposed as a tool to better understand the convergence behavior of iterative decoding schemes. The exchange of extrinsic information is visualized as a decoding trajectory in the extrinsic information transfer chart (EXIT chart). This allows the prediction of turbo cliff position and bit error rate after an arbitrary number of iterations. The influence of code memory, code polynomials as well as different constituent codes on the convergence behavior is studied for parallel concatenated codes. A code search based on the EXIT chart technique has been performed yielding new recursive systematic convolutional constituent codes exhibiting turbo cliffs at lower signal-to-noise ratios than attainable by previously known constituent codes.},
author = {Brink, Stephan Ten},
doi = {10.1109/26.957394},
issn = {00906778},
journal = {IEEE Transactions on Communications},
keywords = {Convergence,Iterative decoding,Mutual information,Turbo codes},
month = {oct},
number = {10},
pages = {1727--1737},
title = {{Convergence behavior of iteratively decoded parallel concatenated codes}},
volume = {49},
year = {2001}
}
@inproceedings{Perez2010a,
annote = {Spcial case: H2 is lower triangular},
author = {P{\'{e}}rez, Jes{\'{u}}s M. and Fern{\'{a}}ndez, V{\'{i}}ctor},
booktitle = {2010 European Wireless Conference, EW 2010},
doi = {10.1109/EW.2010.5483407},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perez, Fernandez - 2010 - 3GPP2802.20 RCQC-LDPC encoding.pdf:pdf},
isbn = {9781424459995},
keywords = {3GPP2,802.20,RC/QC-LDPC,VLSI},
title = {{3GPP2/802.20 RC/QC-LDPC encoding}},
year = {2010}
}
@article{Nguyen2013,
abstract = {This letter produces a family of rate-compatible protograph-based LDPC codes approaching the independent and uniformly distributed (i.u.d.) capacity of inter-symbol interference (ISI) channels. This problem is highly nontrivial due to the joint design of structured (protograph-based) LDPC codes and the state structure of ISI channels. We describe a method to design nested high-rate protograph codes by adding variable nodes to the protograph of a lower rate code. We then design a family of rate-compatible protograph codes using the extension method. The resulting protograph codes have iterative decoding thresholds close to the i.u.d. capacity. Our results are supported by numerical simulations. {\textcopyright} 2013 IEEE.},
author = {Nguyen, Thuy Van and Nosratinia, Aria and Divsalar, Dariush},
doi = {10.1109/LCOMM.2013.060513.130498},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Nosratinia, Divsalar - 2013 - Rate-compatible protograph-based LDPC codes for inter-symbol interference channels.pdf:pdf},
issn = {10897798},
journal = {IEEE Communications Letters},
keywords = {LPDC,inter-symbol interference,protograph,rate-compatible},
number = {8},
pages = {1632--1635},
title = {{Rate-compatible protograph-based LDPC codes for inter-symbol interference channels}},
volume = {17},
year = {2013}
}
@article{Cohen2009,
annote = {Interesting: compute p1 in R-U from G and p2 from p2T=AsT+Bp1T
For us: p1 is half the bits (4m)
=> Critical path is the same
In any case, f-1 (4m x 4) is at least G/2 (4m x 8,16,32)

Add to this what Mahdi said},
author = {Cohen, A.E. and Parhi, K.K.},
doi = {10.1109/TSP.2009.2022919},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen, Parhi - 2009 - A Low-Complexity Hybrid LDPC Code Encoder for IEEE 802.3an (10GBase-T) Ethernet.pdf:pdf},
issn = {1053-587X},
journal = {IEEE Transactions on Signal Processing},
month = {oct},
number = {10},
pages = {4085--4094},
title = {{A Low-Complexity Hybrid LDPC Code Encoder for IEEE 802.3an (10GBase-T) Ethernet}},
url = {http://ieeexplore.ieee.org/document/4915776/},
volume = {57},
year = {2009}
}
@article{Han2005,
abstract = {In this paper, we introduce packet low-density parity-check (packet-LDPC) codes for high-density tape storage systems. We report on the performance of two error control code (ECC) architectures based on the packet-LDPC codes. The architectures are designed to be (approximately) compatible with the widely used ECMA-319 ECC standard based on two interleaved concatenated 8-bit Reed-Solomon (RS) codes. One architecture employs an inner RS code; the other employs an inner turbo product code with single parity-check constituent codes (TPC-SPC). Both employ a packet-LDPC code as the outer code. As for the ECMA-319 system, both schemes are required to correct noise bursts due to media defects and synchronization loss, as well as the loss of one of eight tracks (due to a head clog, for example). We show that the first packet-LDPC code architecture substantially outperforms the ECMA-319 scheme and is only a few tenths of a decibel inferior to a long, highly complex 12-bit RS scheme. The second architecture outperforms both the ECMA-319 and the long RS code scheme. {\textcopyright} 2005 IEEE.},
author = {Han, Yang and Ryan, William E.},
doi = {10.1109/TMAG.2005.844834},
issn = {00189464},
journal = {IEEE Transactions on Magnetics},
keywords = {Error control code (ECC),Low-density parity-check (LDPC),Packet-LDPC,Tape recording},
month = {apr},
number = {4},
pages = {1340--1347},
title = {{Packet-LDPC codes for tape drives}},
volume = {41},
year = {2005}
}
@misc{CCSDS142,
abstract = {CCSDS;},
author = {CCSDS142.0-B-1},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/CCSDS142.0-B-1 - 2018 - Optical Communications Coding and Communications Coding and.pdf:pdf},
number = {June},
title = {{Optical Communications Coding and Communications Coding and}},
year = {2018}
}
@inproceedings{10.1007/978-3-319-56258-2_21,
abstract = {In recent years, so called FPGA-SoCs have been introduced by Intel (formerly Altera) and Xilinx. These devices combine multi-core processors with programmable logic. This paper analyzes the various memory and communication interconnects found in actual devices, particularly the Zynq-7020 and Zynq-7045 from Xilinx and the Cyclone V SE SoC from Intel. Issues such as different access patterns, cache coherence and full-duplex communication are analyzed, for both generic accesses as well as for a real workload from the field of video coding. Furthermore, the paper shows that by carefully choosing the memory interconnect networks as well as the software interface, high-speed memory access can be achieved for various scenarios.},
address = {Cham},
author = {G{\"{o}}bel, Matthias and Elhossini, Ahmed and Chi, Chi Ching and Alvarez-Mesa, Mauricio and Juurlink, Ben},
booktitle = {Applied Reconfigurable Computing},
editor = {Wong, Stephan and Beck, Antonio Carlos and Bertels, Koen and Carro, Luigi},
isbn = {978-3-319-56258-2},
pages = {241--252},
publisher = {Springer International Publishing},
title = {{A Quantitative Analysis of the Memory Architecture of FPGA-SoCs}},
year = {2017}
}
@misc{Vunit21,
author = {Asplund, Lars},
title = {{VUnit: a test framework for HDL — VUnit documentation}},
url = {https://vunit.github.io/},
urldate = {2021-01-21},
year = {2020}
}
@article{Andrews2007,
annote = {Each protograph was first lifted by a factor of T = 4 with PEG (yielding 20 variable nodes, 16 of them transmitted) to eliminate parallel edges. The resulting graph was then
lifted by a factor of T/ n=16 using circulants with Bphases[ selected by a Viterbi-like algorithm from [48]},
author = {Andrews, Kenneth S. and Divsalar, Dariush and Dolinar, Sam and Hamkins, Jon and Jones, Christopher R. and Pollara, Fabrizio},
doi = {10.1109/JPROC.2007.905132},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrews et al. - 2007 - The Development of Turbo and LDPC Codes for Deep-Space Applications.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
month = {nov},
number = {11},
pages = {2142--2156},
title = {{The Development of Turbo and LDPC Codes for Deep-Space Applications}},
url = {http://ieeexplore.ieee.org/document/4383367/},
volume = {95},
year = {2007}
}
@article{Fang2016,
abstract = {The authors study the performance of protograph low-density parity-check (LDPC) codes over two-dimensional (2D) intersymbol interference (ISI) channels in this study. To begin with, the authors propose a modified version of finitelength (FL) extrinsic information transfer (EXIT) algorithm so as to facilitate the convergence analysis of protograph codes. Exploiting the FL-EXIT analyses, the authors observe that the protograph codes optimised for 1D ISI channels, e.g. the 1DISI protograph code, cannot maintain their advantages in the 2D-ISI scenarios. To address this problem, the authors develop a simple design scheme for constructing a family of rate-compatible improved protograph (RCIP) codes particularly for 2D-ISI channels, which not only outperform the 1D-ISI protograph code, but also are superior to the regular column-weight-3 code and optimised irregular LDPC codes in terms of the convergence speed and error performance. More importantly, such RCIP codes benefit from relatively lower error-floor as well as linear encoding and fast decoding. Thanks to these advantages, the proposed RCIP codes stand out as better alternatives in comparison with other error-correction codes for ultra-high-density data storage systems.},
author = {Fang, Yi and Han, Guojun and Guan, Yong Liang and Bi, Guoan and Lau, Francis C.M. and Kong, Lingjun},
doi = {10.1049/iet-com.2015.1233},
issn = {17518628},
journal = {IET Communications},
month = {jul},
number = {11},
pages = {1303--1311},
publisher = {Institution of Engineering and Technology},
title = {{Finite-length extrinsic information transfer analysis and design of protograph lowdensity parity-check codes for ultra-highdensity magnetic recording channels}},
volume = {10},
year = {2016}
}
@inproceedings{VanNguyen2012,
abstract = {This paper addresses the design of a protograph-based LDPC code which can approach the independent and uniformly distributed (i.u.d.) capacity of partial response channels. We propose a method to calculate the iterative decoding threshold of a joint graph between a protograph and the state structure of a partial response channel using the extrinsic information transfer (EXIT) chart. We then describe a simple method to search for a protograph code whose threshold is close to the i.u.d. capacity limit. This new class of codes is needed because experiments show a protograph that is capacity approaching in the AWGN channel may not perform well in partial response channels. In particular, protographs with punctured nodes are often used to produce good AWGN codes, but they perform poorly with the BCJR equalizer. Numerical results support our analysis. {\textcopyright} 2012 IEEE.},
author = {{Van Nguyen}, Thuy and Nosratinia, Aria and Divsalar, Dariush},
booktitle = {IEEE International Conference on Communications},
doi = {10.1109/ICC.2012.6364385},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Nguyen, Nosratinia, Divsalar - 2012 - Protograph-based LDPC codes for partial response channels.pdf:pdf},
isbn = {9781457720529},
issn = {15503607},
pages = {2166--2170},
title = {{Protograph-based LDPC codes for partial response channels}},
year = {2012}
}
@article{Richardson2001,
abstract = {Low-density parity-check (LDPC) codes can be considered serious competitors to turbo codes in terms of performance and complexity and they are based on a similar philosophy: constrained random code ensembles and iterative decoding algorithms. In this paper, we consider the encoding problem for LDPC codes. More generally, we consider the encoding problem for codes specified by sparse parity-check matrices. We show how to exploit the sparseness of the parity-check matrix to obtain efficient encoders. For the (3 6)-regular LDPC code, for example, the complexity of encoding is essentially quadratic in the block length. However, we show that the associated coefficient can be made quite small, so that encoding codes even of length 100 000 is still quite practical. More importantly, we will show that "optimized" codes actually admit linear time encoding.},
author = {Richardson, Thomas J and Urbanke, R{\"{u}}diger L},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Richardson, Urbanke - 2001 - Efficient Encoding of Low-Density Parity-Check Codes.pdf:pdf},
journal = {IEEE TRANSACTIONS ON INFORMATION THEORY},
keywords = {Index Terms-Binary erasure channel,decoding,encoding,parity check,random graphs,sparse matrices,turbo codes},
number = {2},
title = {{Efficient Encoding of Low-Density Parity-Check Codes}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.8553&rep=rep1&type=pdf},
volume = {47},
year = {2001}
}
@article{Fang2019,
author = {Fang, Yi and Chen, Pingping and Cai, Guofa and Lau, Francis C.M. and Liew, Soung Chang and Han, Guojun},
doi = {10.1109/MVT.2019.2903343},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fang et al. - 2019 - Outage-Limit-Approaching Channel Coding for Future Wireless Communications Root-Protograph Low-Density Parity-Check.pdf:pdf},
issn = {1556-6072},
journal = {IEEE Vehicular Technology Magazine},
month = {jun},
number = {2},
pages = {85--93},
title = {{Outage-Limit-Approaching Channel Coding for Future Wireless Communications: Root-Protograph Low-Density Parity-Check Codes}},
url = {https://ieeexplore.ieee.org/document/8693678/},
volume = {14},
year = {2019}
}
@article{Kong2015,
abstract = {In this paper, protograph-based quasi-cyclic (QC) low-density parity-check (LDPC) codes are proposed for the efficient structure coding of LDPC codes in 2-D intersymbol interference (ISI) ultrahigh density magnetic recording channels, such as bit-patterned magnetic recording and 2-D magnetic recording, where a reduced-complexity 2-D detector based on the iterative row-column soft detection feedback with Gaussian approximation is employed instead of the full 2-D Bahl-Cocke-Jelinek-Raviv detector. The proposed protograph-based codes, whose base matrices are constructed according to the degree sequences for 2-D-ISI channels, have a low-complexity QC encoder structure with a readily parallelizable protograph decoder structure. Simulation results show that the proposed protograph-based QC-LDPC codes outperform the random LDPC codes optimized for additive white Gaussian noise channels. Furthermore, the performance of the QC codes is similar to that exhibited by ISI-optimized random LDPC codes designed for 2-D-ISI channels, while retaining the implementational benefits.},
author = {Kong, Lingjun and He, Liwen and Chen, Pingping and Han, Guojun and Fang, Yi},
doi = {10.1109/TMAG.2015.2437397},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kong et al. - 2015 - Protograph-Based Quasi-Cyclic LDPC Coding for Ultrahigh Density Magnetic Recording Channels.pdf:pdf},
issn = {00189464},
journal = {IEEE Transactions on Magnetics},
keywords = {low-density parity-check (LDPC) codes,protograph LDPC codes,quasi-cyclic (QC) LDPC codes,two dimensional (2D) intersymbol interference (ISI},
month = {nov},
number = {11},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Protograph-Based Quasi-Cyclic LDPC Coding for Ultrahigh Density Magnetic Recording Channels}},
volume = {51},
year = {2015}
}
@inproceedings{Wang2014,
abstract = {A serial-input serial-output encoder based on pipelined rotate-left-accumulator (RLA) circuits is designed for multi-rate Quasi-Cyclic Low-Density Parity-Check (QC-LDPC) codes of Chinese digital terrestrial/television multimedia broadcasting (DTMB) standard. The RLA circuit can make the area usage economical, and the pipelined architecture can simplify the memory structure. The encoder is implemented on FPGA. Simulation results demonstrate that the design meets the requirement of DTMB standard with lower energy consumption and fewer hardware resources.},
author = {Wang, Fei and Zhang, Peng and Wan, Xin and Liu, Jin},
booktitle = {Proceedings - 2014 7th International Congress on Image and Signal Processing, CISP 2014},
doi = {10.1109/CISP.2014.7003945},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2014 - Design of a multi-rate quasi-cyclic low-density parity-check encoder based on pipelined rotate-left-accumulator cir.pdf:pdf},
isbn = {9781479958351},
keywords = {DTMB,Encoder,FPGA,QC-LDPC,Rotate-Left-Accumulator(RLA)},
month = {jan},
pages = {1105--1109},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Design of a multi-rate quasi-cyclic low-density parity-check encoder based on pipelined rotate-left-accumulator circuits}},
year = {2014}
}
@article{Yen2012,
author = {Yen, Shao-Wei and Hung, Shiang-Yu and Chen, Chih-Lung and Chang, Hsie-Chia and Jou, Shyh-Jye and Lee, Chen-Yi},
doi = {10.1109/JSSC.2012.2194176},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yen et al. - 2012 - A 5.79-Gbs Energy-Efficient Multirate LDPC Codec Chip for IEEE 802.15.3c Applications.pdf:pdf},
issn = {0018-9200},
journal = {IEEE Journal of Solid-State Circuits},
month = {sep},
number = {9},
pages = {2246--2257},
title = {{A 5.79-Gb/s Energy-Efficient Multirate LDPC Codec Chip for IEEE 802.15.3c Applications}},
url = {http://ieeexplore.ieee.org/document/6198294/},
volume = {47},
year = {2012}
}
@article{DeCola2010,
abstract = {Achieving reliable communications in deep space environments poses formidable networking challenges because of the extreme physical medium peculiarities. In this view, two possible approaches can be considered to carry out reliable data transfers over deep space channels: automatic repeat request schemes and packet layer coding algorithms applied with long erasure codes. In this respect, this article surveys the mechanisms currently available from the Consultative Committee for Space Data Systems protocol stack, by reserving special attention, on one hand, to the ARQ schemes currently implemented at the application layer and, on the other hand, to the potential offered by erasure coding schemes. A comparative analysis gives some insights about the performance improvements the packet layer coding methodology can bring. In particular, the results show that the use of erasure coding is able to attain more satisfactory performance results than ARQ-based schemes in terms of reliability, data transfer delay, resource network utilization, and power consumption. {\textcopyright} 2010 IEEE.},
author = {{De Cola}, Tomaso and Marchese, Mario},
doi = {10.1109/MWC.2010.5450661},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Cola, Marchese - 2010 - Reliable data delivery over deep space networks Benefits of long erasure codes over arq strategies.pdf:pdf},
issn = {15361284},
journal = {IEEE Wireless Communications},
month = {apr},
number = {2},
pages = {57--65},
title = {{Reliable data delivery over deep space networks: Benefits of long erasure codes over arq strategies}},
volume = {17},
year = {2010}
}
@misc{spwire,
institution = {European Cooperation for Space Standardization},
title = {{SpaceWire – Links, nodes, routers and networks}},
url = {https://ecss.nl/standard/ecss-e-st-50-12c-rev-1-spacewire-links-nodes-routers-and-networks-15-may-2019/},
year = {2019}
}
@article{Kschischang2001,
author = {Kschischang, F.R. and Frey, B.J. and Loeliger, H.-A.},
doi = {10.1109/18.910572},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kschischang, Frey, Loeliger - 2001 - Factor graphs and the sum-product algorithm.pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
number = {2},
pages = {498--519},
title = {{Factor graphs and the sum-product algorithm}},
url = {http://ieeexplore.ieee.org/document/910572/},
volume = {47},
year = {2001}
}
@article{Chen2015,
abstract = {This paper investigates the performance of the protograph-based low-density parity-check (LDPC) codes for 2-D intersymbol interference (ISI) channels with magnetic recording density. The protograph LDPC codes have been shown to possess simple hardware implementation and excellent error performance over additive white Gaussian noise channels and over partial response channels. We propose a design scheme and construct two new protograph LDPC codes for 2-D ISI channel, with the help of extrinsic information transfer chart analysis and asymptotic ensemble weight distribution analysis. The theoretical analyses and simulated results show that the proposed codes outperform the previously optimized irregular LDPC code in both low- and high-SNR regions. Thus, the proposed codes are good alternatives compared with other error-correction codes for the use in magnetic recording systems.},
author = {Chen, Pingping and Kong, Lingjun and Fang, Yi and Wang, Lin},
doi = {10.1109/TMAG.2015.2437414},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2015 - The Design of Protograph LDPC Codes for 2-D Magnetic Recording Channels.pdf:pdf},
issn = {00189464},
journal = {IEEE Transactions on Magnetics},
keywords = {Extrinsic information transfer (EXIT),low-density parity-check (LDPC),magnetic recording channel,protograph channel code},
month = {nov},
number = {11},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{The Design of Protograph LDPC Codes for 2-D Magnetic Recording Channels}},
volume = {51},
year = {2015}
}
@article{Mattoussi2019,
abstract = {Hybrid broadcast broadband TV is a technique providing Push-VoD services over an interactive hybrid TV. These services are broadcast using a file delivery protocol (FDP), which includes different coding strategies to ensure reliable delivery. This protocol is characterized by three levels of data representation giving rise to segmentation of packet losses, which may result in poor recovery capabilities. This paper provides a first thorough investigation of the coding FDP framework for reliable delivery of Push-VoD service over DVB networks. We propose Markov modeling for characterizing inter-layer loss propagation within FDP on a wide variety of burst erasure channels. Based on this analytical analysis and a simulation study, we determine the possible recovering areas and the accurate loss measurements within FDP. The latter is then used to effectively investigate and configure the different coding strategies provided within FDP. In addition, we present a suitable recovering strategy for FDP, which guarantees transmission robustness against the broadcast network impairments.},
author = {Mattoussi, Ferdaouss and Crussiere, Matthieu and Helard, Jean Francois and Zaharia, Gheorghe},
doi = {10.1109/ACCESS.2019.2893756},
issn = {21693536},
journal = {IEEE Access},
keywords = {AL-FEC,DVB,HbbTV,Markov chain,Push-VoD services,repetition code},
pages = {15489--15508},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Analysis of Coding Strategies Within File Delivery Protocol Framework for HbbTV Based Push-VoD Services over DVB Networks}},
volume = {7},
year = {2019}
}
@article{Gallager1962,
author = {Gallager, R.},
doi = {10.1109/TIT.1962.1057683},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gallager - 1962 - Low-density parity-check codes.pdf:pdf},
issn = {0018-9448},
journal = {IRE Transactions on Information Theory},
month = {jan},
number = {1},
pages = {21--28},
title = {{Low-density parity-check codes}},
url = {http://ieeexplore.ieee.org/document/1057683/},
volume = {8},
year = {1962}
}
@article{Sae-YoungChung2001,
author = {{Sae-Young Chung} and Forney, G.D. and Richardson, T.J. and Urbanke, R.},
doi = {10.1109/4234.905935},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sae-Young Chung et al. - 2001 - On the design of low-density parity-check codes within 0.0045 dB of the Shannon limit.pdf:pdf},
issn = {1089-7798},
journal = {IEEE Communications Letters},
number = {2},
pages = {58--60},
title = {{On the design of low-density parity-check codes within 0.0045 dB of the Shannon limit}},
url = {http://ieeexplore.ieee.org/document/905935/},
volume = {5},
year = {2001}
}
@article{Cheour2019,
author = {Cheour, Rym and Khriji, Sabrine and Houssaini, Dhouha El and Baklouti, Mouna and Abid, Mohamed and Kanoun, Olfa},
doi = {10.1109/MAES.2019.2901134},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheour et al. - 2019 - Recent Trends of FPGA Used for Low-Power Wireless Sensor Network.pdf:pdf},
issn = {1557959X},
journal = {IEEE Aerospace and Electronic Systems Magazine},
month = {oct},
number = {10},
pages = {28--38},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Recent Trends of FPGA Used for Low-Power Wireless Sensor Network}},
volume = {34},
year = {2019}
}
@article{Reed1960,
abstract = {This paper presents a survey of coding theory for statisticians and mathematicians who have some familiarity with modern algebra, finite fields and possibly some acquaintance with block designs. No knowledge of stochastic processes, information theory or ...},
author = {Reed, I. S. and Solomon, G.},
doi = {10.1137/0108018},
issn = {0368-4245},
journal = {Journal of the Society for Industrial and Applied Mathematics},
month = {jun},
number = {2},
pages = {300--304},
publisher = {Society for Industrial & Applied Mathematics (SIAM)},
title = {{Polynomial Codes Over Certain Finite Fields}},
volume = {8},
year = {1960}
}
@misc{creonicC2,
abstract = {Features • Support for code rate 223/255 (7136/8160) • Coded block size 8160 bits • Compliant with "TM Synchronization and Channel Coding, Recommended Standard, CCSDS 131.0-B-2, Blue Book, August 2011". Applications • Near-Earth and Deep-Space communication. • Space links communication. • Space internetworking services.},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2016 - CCSDS (8160, 7136) LDPC Encoder and Decoder Product Brief.pdf:pdf},
title = {{CCSDS (8160, 7136) LDPC Encoder and Decoder Product Brief}},
url = {www.creonic.com.},
year = {2016}
}
@inproceedings{XiangranSun2011,
annote = {Typical L-U},
author = {{Xiangran Sun} and {Dongxin Shi}},
booktitle = {2011 International Conference on Computer Science and Service System (CSSS)},
doi = {10.1109/CSSS.2011.5974805},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiangran Sun, Dongxin Shi - 2011 - Design and optimization of LDPC encoder based on LU decomposition with simulated annealing.pdf:pdf},
isbn = {978-1-4244-9762-1},
month = {jun},
pages = {2181--2184},
publisher = {IEEE},
title = {{Design and optimization of LDPC encoder based on LU decomposition with simulated annealing}},
url = {http://ieeexplore.ieee.org/document/5974805/},
year = {2011}
}
@inproceedings{Yin2013,
abstract = {This paper designs and implements a novel parallel LDPC encoder. It based on LU decomposition, according to the inherent characteristics of LDPC Parity-Check Matrix in CMMB. It is applied to design CMMB baseband exciter, which can support 2 different code rates (1/2 and 3/4). The SIMD parallel architecture is proposed to solve the encoding delay caused by iteration of LU algorithm, full pipeline and multistage Ping-Pong buffer structure are also used to improve throughput in high-speed encoding. It meets the requirements both in real-time performance and resource utilization. Furthermore, this method is generic and can be adapted easily for other LDPC codes; thus, it has a significant practical value. {\textcopyright} 2013 IEEE.},
author = {Yin, Hang and Du, Weitao and Zhu, Nanhao},
booktitle = {2013 IEEE 3rd International Conference on Information Science and Technology, ICIST 2013},
doi = {10.1109/ICIST.2013.6747774},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yin, Du, Zhu - 2013 - Design of improved LDPC encoder for CMMB based on SIMD architecture.pdf:pdf},
pages = {1292--1295},
publisher = {IEEE Computer Society},
title = {{Design of improved LDPC encoder for CMMB based on SIMD architecture}},
year = {2013}
}
@article{Tanner1981,
abstract = {A method is described for constructing long error-correcting codes from one or more shorter error-correcting codes, referred to as subcodes, and a bipartite graph. A graph is shown which specifies carefully chosen subsets of the digits of the new codes that must be codewords in one of the shorter subcodes. Lower bounds to the rate and the minimum distance of the new code are derived in terms of the parameters of the graph and the subcodes. Both the encoders and decoders proposed are shown to take advantage of the code's explicit decomposition into subcodes to decompose and simplify the associated computational processes. Bounds on the performance of two specific decoding algorithms are established, and the asymptotic growth of the complexity of decoding for two types of codes and decoders is analyzed. The proposed decoders are able to make effective use of probabilistic information supplied by the channel receiver, e.g., reliability information, without greatly increasing the number of computations required. It is shown that choosing a transmission order for the digits that is appropriate for the graph and the subcodes can give the code excellent burst-error correction abilities. The construction principles are illustrated by several examples. {\textcopyright} 1981 IEEE},
author = {Tanner, R. Michael},
doi = {10.1109/TIT.1981.1056404},
issn = {15579654},
journal = {IEEE Transactions on Information Theory},
number = {5},
pages = {533--547},
title = {{A Recursive Approach to Low Complexity Codes}},
volume = {27},
year = {1981}
}
@article{Rhee2010,
abstract = {In this paper, we propose a concatenated Reed-Solomon code with a Hamming code for dynamic random access memory (DRAM) controller. The concatenated code consists of a Reed-Solomon outer code, two shortened Reed-Solomon codes, and a Hamming inner code. The proposed code takes the advantages of Reed-Solomon codes and Hamming codes to protect DRAM memory data against single event upsets and multiple bit upsets. At the byte error rate of 10-7, the proposed decoder shows about 1.3 dB of coding gain over that of the conventional Reed-Solomon decoder. We implement the proposed concatenated Reed-Solomon code on a very large-scale integration (VLSI) chip with 0.13 $\mu$m complementary metal oxide semiconductor (CMOS) standard cell library at a supply voltage of 1.2 V. The core area of proposed architecture is 1.12 mm2 with the gate counts of 121,900. The synthesized result shows the maximum throughput of 1.71 Gbps and the measured power consumption of 69 mW at 259 MHz. {\textcopyright} 2010 IEEE.},
author = {Rhee, Sunwook and Kim, Changgeun and Kim, Juhee and Jee, Yong},
doi = {10.1109/ICCEA.2010.65},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rhee et al. - 2010 - Concatenated Reed-Solomon code with hamming code for DRAM controller.pdf:pdf},
journal = {2010 2nd International Conference on Computer Engineering and Applications, ICCEA 2010},
keywords = {Concatenated codes,Error correcting codes(ECC),Hamming code,Memory controller,Reed-Solomon code},
pages = {291--295},
title = {{Concatenated Reed-Solomon code with hamming code for DRAM controller}},
volume = {1},
year = {2010}
}
@inproceedings{Hariri2014,
annote = {Basic Dual-diagonal. Recursive calculatiuon of parity bits},
author = {Hariri, Alaa Aldin Al and Monteiro, Fabrice and Sieler, Loic and Dandache, Abbas},
booktitle = {2014 21st IEEE International Conference on Electronics, Circuits and Systems (ICECS)},
doi = {10.1109/ICECS.2014.7050104},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hariri et al. - 2014 - Configurable and high-throughput architectures for Quasi-cyclic low-density parity-check codes.pdf:pdf},
isbn = {978-1-4799-4242-8},
month = {dec},
pages = {790--793},
publisher = {IEEE},
title = {{Configurable and high-throughput architectures for Quasi-cyclic low-density parity-check codes}},
url = {http://ieeexplore.ieee.org/document/7050104/},
year = {2014}
}
@article{TenBrink1999,
abstract = {A novel method for visualizing the convergence behaviour of iterative decoding schemes is proposed. Each constituent decoder is represented by a mutual information transfer characteristic which describes the flow of extrinsic information through the soft in/soft out decoder. The exchange of extrinsic information between constituent decoders is plotted in an extrinsic information transfer chart. The concepts are illustrated for an iterative demapping and decoding scheme.},
author = {ten Brink, S.},
doi = {10.1049/el:19990555},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ten Brink - 1999 - Convergence of iterative decoding.pdf:pdf},
issn = {00135194},
journal = {Electronics Letters},
number = {13},
pages = {1117--1118},
publisher = {IEE},
title = {{Convergence of iterative decoding}},
volume = {35},
year = {1999}
}
@techreport{Hamkins2010,
author = {Hamkins, J.},
booktitle = {undefined},
file = {:hd/di/erasure/NASA-Interleaved.pdf:pdf},
title = {{Optimal Codes for the Burst Erasure Channel}},
year = {2010}
}
@inproceedings{Theodoropoulos2016,
author = {Theodoropoulos, Dimitris and Kranitis, Nektarios and Paschalis, Antonios},
booktitle = {2016 IEEE 22nd International Symposium on On-Line Testing and Robust System Design (IOLTS)},
doi = {10.1109/IOLTS.2016.7604689},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Theodoropoulos, Kranitis, Paschalis - 2016 - An efficient LDPC encoder architecture for space applications.pdf:pdf},
isbn = {978-1-5090-1507-8},
month = {jul},
pages = {149--154},
publisher = {IEEE},
title = {{An efficient LDPC encoder architecture for space applications}},
url = {http://ieeexplore.ieee.org/document/7604689/},
year = {2016}
}
@inproceedings{Sun2010,
abstract = {We present a low-complexity high-efficiency LDPC encoder, based on classic method of Richardson and Urbanke with a novel backtracking algorithm, which we propose to substitute greedy algorithm for approximate triangulation with sparse matrix of LDPC codes. For the LDPC code in CMMB, for example, the complexity of encoding is reduced effectively, and an implementation of LDPC encoder for two different code rate (1/2 and 3/4) on Altera Stratix II EP1S180F102014 can achieve encoding rate 34 Mbps and 69 Mbps. {\textcopyright}2010 IEEE.},
author = {Sun, Xiangran and Zeng, Zhibin and Yang, Zhanxin},
booktitle = {2010 International Conference on Multimedia Technology, ICMT 2010},
doi = {10.1109/ICMULT.2010.5631468},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun, Zeng, Yang - 2010 - A novel low complexity LDPC encoder based on optimized RU algorithm with backtracking.pdf:pdf},
isbn = {9781424478743},
keywords = {Backtracking,CMMB,Encoder,LDPC},
title = {{A novel low complexity LDPC encoder based on optimized RU algorithm with backtracking}},
year = {2010}
}
@article{Nguyen2019,
abstract = {<p>This paper presents a novel efficient encoding method and a high-throughput low-complexity encoder architecture for quasi-cyclic low-density parity-check (QC-LDPC) codes for the 5th-generation (5G) New Radio (NR) standard. By storing the quantized value of the permutation information for each submatrix instead of the whole parity check matrix, the required memory storage size is considerably reduced. In addition, sharing techniques are employed to reduce the hardware complexity. The encoding complexity of the proposed method was analyzed, and indicated a substantial reduction in the required area as well as memory storage when compared with existing state-of-the-art encoding approaches. The proposed method requires only 61% gate area, and 11% ROM storage when compared with a similar LDPC encoder using the Richardson–Urbanke method. Synthesis results on TSMC 65-nm complementary metal-oxide semiconductor (CMOS) technology with different submatrix sizes were carried out, which confirmed that the design methodology is flexible and can be adapted for multiple submatrix sizes. For all the considered submatrix sizes, the throughput ranged from 22.1–202.4 Gbps, which sufficiently meets the throughput requirement for the 5G NR standard.</p>},
author = {Nguyen, Tram Thi Bao and {Nguyen Tan}, Tuy and Lee, Hanho},
doi = {10.3390/electronics8060668},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Nguyen Tan, Lee - 2019 - Efficient QC-LDPC Encoder for 5G New Radio.pdf:pdf},
issn = {2079-9292},
journal = {Electronics},
month = {jun},
number = {6},
pages = {668},
title = {{Efficient QC-LDPC Encoder for 5G New Radio}},
url = {https://www.mdpi.com/2079-9292/8/6/668},
volume = {8},
year = {2019}
}
@article{Tian2004a,
abstract = {This letter explains the effect of graph connectivity on error-floor performance of low-density parity-check (LDPC) codes under message-passing decoding. A new metric, called extrinsic message degree (EMD), measures cycle connectivity in bipartite graphs of LDPC codes. Using an easily computed estimate of EMD, we propose a Viterbi-like algorithm that selectively avoids small cycle clusters that are isolated from the rest of the graph. This algorithm is different from conventional girth conditioning by emphasizing the connectivity as well as the length of cycles. The algorithm yields codes with error floors that are orders of magnitude below those of random codes with very small degradation in capacity-approaching capability. {\textcopyright} 2004 IEEE.},
author = {Tian, Tao and Jones, Christopher R. and Villasenor, John D. and Wesel, Richard D.},
doi = {10.1109/TCOMM.2004.833048},
issn = {00906778},
journal = {IEEE Transactions on Communications},
month = {aug},
number = {8},
pages = {1242--1247},
title = {{Selective avoidance of cycles in irregular LDPC code construction}},
volume = {52},
year = {2004}
}
@inproceedings{Li2012,
abstract = {Because of good systematicness of its parity check matrix, linear relationship between the minimum distance and code length, and inheritance of punching property of ARA(accumulate repeat accumulate) code, AR4JA (accumulate-repeat-4-jagged-accumulate) code is thought to be the most suitable error correction channel code for deep space reliable communication in the future. Given that the accurate channel model of deep communication environment is lacked, in the paper, the absorption, reflection or other uncertain effects of different kinds of particles in aerospace were described with Rician fading model. Then the performance of AR4JA code in deep space Rician fading channel with BP algorithm and Min-Sum algorithm were studied in the paper. Simulation results show that in Rician fading channel, compared with BP algorithm, Min-Sum algorithm declines decoding complexity with few gain loss, which is beneficial to realize miniaturization of deep space communication receiver. Through further analysis, relationship of iteration times of Min-Sum algorithm and SNR is also given for the better use of decoding AR4JA codes by Min-Sum algorithm. {\textcopyright} 2012 IEEE.},
annote = {Say about the study on Rician fading channel},
author = {Li, Hui and Gao, Jianan and Yang, Mingchuan and Lv, Gu and Li, Ming and Guo, Qing},
booktitle = {2012 7th International ICST Conference on Communications and Networking in China, CHINACOM 2012 - Proceedings},
doi = {10.1109/ChinaCom.2012.6417466},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2012 - Study on AR4JA code in deep space fading channel.pdf:pdf},
isbn = {9781467326995},
keywords = {AR4JA code,Min-Sum decoding algorithm,Rician fading channel,deep space communication},
pages = {150--154},
title = {{Study on AR4JA code in deep space fading channel}},
year = {2012}
}
@misc{Scott,
author = {Scott, K and Burleigh, S},
title = {{Bundle Protocol Specification}},
url = {https://www.rfc-editor.org/rfc/rfc5050.txt},
urldate = {2020-12-21}
}
@article{Burshtein2004,
abstract = {We show how asymptotic estimates of powers of polynomials with nonnegative coefficients can be used in the analysis of low-density parity-check (LDPC) codes. In particular, we show how these estimates can be used to derive the asymptotic distance spectrum of both regular and irregular LDPC code ensembles. We then consider the binary erasure channel (BEC). Using these estimates we derive lower bounds on the error exponent, under iterative decoding, of LDPC codes used over the BEC. Both regular and irregular code structures are considered. These bounds are compared to the corresponding bounds when optimal (maximum-likelihood (ML)) decoding is applied.},
author = {Burshtein, David and Miller, Gadi},
doi = {10.1109/TIT.2004.828064},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Binary erasure channel (BEC),Code ensembles,Code spectrum,Iterative decoding,Low-density parity-check (LDPC) codes},
month = {jun},
number = {6},
pages = {1115--1131},
title = {{Asymptotic enumeration methods for analyzing LDPC codes}},
volume = {50},
year = {2004}
}
@article{Fang2016a,
abstract = {The authors study the performance of protograph low-density parity-check (LDPC) codes over two-dimensional (2D) intersymbol interference (ISI) channels in this study. To begin with, the authors propose a modified version of finitelength (FL) extrinsic information transfer (EXIT) algorithm so as to facilitate the convergence analysis of protograph codes. Exploiting the FL-EXIT analyses, the authors observe that the protograph codes optimised for 1D ISI channels, e.g. the 1DISI protograph code, cannot maintain their advantages in the 2D-ISI scenarios. To address this problem, the authors develop a simple design scheme for constructing a family of rate-compatible improved protograph (RCIP) codes particularly for 2D-ISI channels, which not only outperform the 1D-ISI protograph code, but also are superior to the regular column-weight-3 code and optimised irregular LDPC codes in terms of the convergence speed and error performance. More importantly, such RCIP codes benefit from relatively lower error-floor as well as linear encoding and fast decoding. Thanks to these advantages, the proposed RCIP codes stand out as better alternatives in comparison with other error-correction codes for ultra-high-density data storage systems.},
author = {Fang, Yi and Han, Guojun and Guan, Yong Liang and Bi, Guoan and Lau, Francis C.M. and Kong, Lingjun},
doi = {10.1049/iet-com.2015.1233},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fang et al. - 2016 - Finite-length extrinsic information transfer analysis and design of protograph lowdensity parity-check codes for ul.pdf:pdf},
issn = {17518628},
journal = {IET Communications},
month = {jul},
number = {11},
pages = {1303--1311},
publisher = {Institution of Engineering and Technology},
title = {{Finite-length extrinsic information transfer analysis and design of protograph lowdensity parity-check codes for ultra-highdensity magnetic recording channels}},
volume = {10},
year = {2016}
}
@inproceedings{HuiLi2012,
author = {{Hui Li} and {Jianan Gao} and {Mingchuan Yang} and {Gu Lv} and {Ming Li} and {Qing Guo}},
booktitle = {7th International Conference on Communications and Networking in China},
doi = {10.1109/ChinaCom.2012.6417466},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hui Li et al. - 2012 - Study on AR4JA code in deep space fading channel.pdf:pdf},
isbn = {978-1-4673-2699-5},
month = {aug},
pages = {150--154},
publisher = {IEEE},
title = {{Study on AR4JA code in deep space fading channel}},
url = {http://ieeexplore.ieee.org/document/6417466/},
year = {2012}
}
@article{Courtade2011,
abstract = {For a block-fading channel, this paper optimizes the allocation of redundancy between packet-level erasure coding (which provides additional packets to compensate for packet loss) and physical layer channel coding (which lowers the probability of packet loss). After some manipulation, standard optimization techniques determine the trade-off between the amount of packet-level erasure coding and physical-layer channel coding that minimizes the transmit power required to provide reliable communication. Our results indicate that the optimal combination of packet-level erasure coding and physical-layer coding provides a significant benefit over pure physical-layer coding when no form of channel diversity is present within a packet transmission. However, the benefit of including packet-level erasure coding diminishes as more diversity becomes available within a packet transmission. Even with no diversity within a packet transmission, this paper shows that as the total redundancy becomes large the optimal redundancy for packet-level erasure coding reaches a limit while the optimal redundancy for physical-layer coding continues to increase. Hence providing limitless redundancy at the packet-level with rateless codes such as fountain codes is not the best use of limitless redundancy for block-fading channels. {\textcopyright} 2011 IEEE.},
author = {Courtade, Thomas A. and Wesel, Richard D.},
doi = {10.1109/TCOMM.2011.062311.090277},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Courtade, Wesel - 2011 - Optimal allocation of redundancy between packet-level erasure coding and physical-layer channel coding in fadin.pdf:pdf},
issn = {00906778},
journal = {IEEE Transactions on Communications},
keywords = {Cross-layer coding,Rayleigh fading channels,cross-layer optimization,rateless codes,selection diversity},
month = {aug},
number = {8},
pages = {2101--2109},
title = {{Optimal allocation of redundancy between packet-level erasure coding and physical-layer channel coding in fading channels}},
volume = {59},
year = {2011}
}
@article{Fang2015a,
abstract = {Low-density parity-check (LDPC) codes have attracted much attention over the past two decades since they can asymptotically approach the Shannon capacity in a variety of data transmission and storage scenarios. As a type of promising structured LDPC codes, the protograph LDPC codes not only inherit the advantage of conventional LDPC codes, i.e., excellent error performance, but also possess simple representations to realize fast encoding and efficient decoding. This paper provides a comprehensive survey on the state-of-the-art in protograph LDPC code design and analysis for different channel conditions, including the additive white Gaussian noise (AWGN) channels, fading channels, partial response (PR) channels, and Poisson pulse-position modulation (PPM) channels. Moreover, the applications of protograph LDPC codes to joint source-and-channel coding (JSCC) and joint channel-and-physical-layer-network coding (JCPNC) are reviewed and studied. In particular, we focus our attention on the encoding design and assume the decoder is implemented by the belief propagation (BP) algorithm. Hopefully, this survey may facilitate research in this area.},
author = {Fang, Yi and Bi, Guoan and Guan, Yong Liang and Lau, Francis C.M.},
doi = {10.1109/COMST.2015.2436705},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fang et al. - 2015 - A Survey on Protograph LDPC Codes and Their Applications(2).pdf:pdf},
issn = {1553877X},
journal = {IEEE Communications Surveys and Tutorials},
keywords = {Asymptotic weight distribution (AWD),decoding threshold,extrinsic information transfer (EXIT),protograph lowdensity parity-check (LDPC) codes},
month = {oct},
number = {4},
pages = {1989--2016},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{A Survey on Protograph LDPC Codes and Their Applications}},
volume = {17},
year = {2015}
}
@article{Divsalar2009,
abstract = {This paper discusses construction of protographbased low-density parity-check (LDPC) codes. Emphasis is placed on protograph ensembles whose typical minimum distance grows linearly with block size. Asymptotic performance analysis for both weight enumeration and iterative decoding threshold determination is provided and applied to a series of code constructions. Construction techniques that yield both low thresholds and linear minimum distance growth are introduced by way of example throughout. The paper also examines implementation strategies for high throughput decoding derived from first principles of belief propagation on bipartite graphs. {\textcopyright} 2009 IEEE.},
author = {Divsalar, Dariush and Dolinar, Sam and Jones, Christopher R. and Andrews, Kenneth},
doi = {10.1109/JSAC.2009.090806},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Divsalar et al. - 2009 - Capacity-approaching protograph codes.pdf:pdf},
issn = {07338716},
journal = {IEEE Journal on Selected Areas in Communications},
keywords = {Decoder Implementation,Iterative decoding threshold,LDPC codes,Protograph codes,Rate-compatible codes,Weight enumeration},
month = {aug},
number = {6},
pages = {876--888},
title = {{Capacity-approaching protograph codes}},
volume = {27},
year = {2009}
}
@article{Chen2019,
abstract = {As a subfield of network coding, PNC can effectively enhance the throughput of wireless networks by mapping superimposed signals at the receiver to other forms of user messages. Over the past 20 years, PNC has received significant research attention and has been widely studied in various communication scenarios, for example, TWRC, NOMA in 5G networks, random access networks, and so on. Later on, channel-coded PNC and related communication techniques were investigated to ensure network reliability, such as the design of channel code, low-complexity decoding, and cross-layer design. In this article, we briefly review the variants of channel-coded PNC-aided wireless communications with the aim of inspiring future research activities in this area. We also put forth open research problems along with a few selected research directions under PNC-aided frameworks.},
archivePrefix = {arXiv},
arxivId = {1907.08983},
author = {Chen, Pingping and Xie, Zhaopeng and Fang, Yi and Chen, Zhifeng and Mumtaz, Shahid and Rodrigues, Joel J.P.C.},
doi = {10.1109/MNET.001.1900289},
eprint = {1907.08983},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2019 - Physical-Layer Network Coding An Efficient Technique for Wireless Communications.pdf:pdf},
issn = {1558156X},
journal = {IEEE Network},
keywords = {Channel coding,Decoding,Modulation,NOMA,Network coding,Relays},
pages = {1--7},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Physical-Layer Network Coding: An Efficient Technique for Wireless Communications}},
year = {2019}
}
@inproceedings{Chia-YuLin2008,
annote = {Interesting. Add to the different (?) But basically it is H2},
author = {{Chia-Yu Lin} and {Chih-Chun Wei} and {Mong-Kai Ku}},
booktitle = {APCCAS 2008 - 2008 IEEE Asia Pacific Conference on Circuits and Systems},
doi = {10.1109/APCCAS.2008.4746353},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chia-Yu Lin, Chih-Chun Wei, Mong-Kai Ku - 2008 - Efficient encoding for dual-diagonal structured LDPC codes based on parity bit predicti.pdf:pdf},
isbn = {978-1-4244-2341-5},
month = {nov},
pages = {1648--1651},
publisher = {IEEE},
title = {{Efficient encoding for dual-diagonal structured LDPC codes based on parity bit prediction and correction}},
url = {http://ieeexplore.ieee.org/document/4746353/},
year = {2008}
}
@inproceedings{Mazzali2020,
abstract = {Following the recent publication of the first recommended standard on optical communications by the Consultative Committee for Space Data Systems (CCSDS), the focus of the standardization group turns now to the optical low Earth orbit (LEO) direct-to-Earth (DTE) satellite link scenario. This scenario is nicknamed optical on-off keying (O3K) due to the choice of this binary modulation format. In optical LEO DTE links the main impairment is atmospheric turbulence, which is a slow fading process with relatively long coherence time (typically some milliseconds). To mitigate this and to allow for any forward error correction (FEC) code to operate properly, a long channel interleaver is usually employed at the physical layer. The present paper provides some practical guidance on how to dimension such an interleaver by performing a realistic numerical analysis based on a comprehensive software simulator, along with a statistical analysis to gain a deeper insight. Overall, this work is meant to support the CCSDS O3K standardization activity.},
author = {Mazzali, Nicolo and Arapoglou, Pantelis Daniel},
booktitle = {2020 10th Advanced Satellite Multimedia Systems Conference and the 16th Signal Processing for Space Communications Workshop, ASMS/SPSC 2020},
doi = {10.1109/ASMS/SPSC48805.2020.9268852},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mazzali, Arapoglou - 2020 - Channel Interleaver Dimensioning for Optical LEO Direct-to-Earth Systems.pdf:pdf},
isbn = {9781728157948},
keywords = {LEO,channel interleaver,direct-to-Earth,optical},
month = {oct},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Channel Interleaver Dimensioning for Optical LEO Direct-to-Earth Systems}},
year = {2020}
}
@inproceedings{Jia-ningSu2005,
annote = {How we and Mahdi make L-U},
author = {{Jia-ning Su} and {Hou Iang} and Ke iu and Iao-yang eng and {Ao Min} and {Ao Min}},
booktitle = {2005 6th International Conference on ASIC},
doi = {10.1109/ICASIC.2005.1611277},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jia-ning Su et al. - 2005 - An Efficient Low Complexity LDPC Encoder Based On Factorization With Pivoting.pdf:pdf},
isbn = {0-7803-9210-8},
pages = {168--171},
publisher = {IEEE},
title = {{An Efficient Low Complexity LDPC Encoder Based On Factorization With Pivoting}},
url = {http://ieeexplore.ieee.org/document/1611277/},
volume = {1},
year = {2005}
}
@inproceedings{Edwards2019,
abstract = {International space agencies around the world are working together in the Interagency Operation Advisory Group (IOAG) and the Consultative Committee for Space Data Systems (CCSDS) to develop interoperability standards for optical communications. The standards support optical communication systems for both Near Earth and Deep Space robotic and human-rated spacecraft. The standards generally address both free space links between spacecraft and free space links between spacecraft and ground. This paper will overview the history and structure of the CCSDS Optical Communications Working Group and provide an update on the set of optical communications standards being developed. The paper will address the ongoing work on High Photon Efficiency communications, High Data Rate communications, and Optical On/Off Keying communications. It will also cover the work being done within CCSDS on documenting atmospheric measurement techniques and link operations concepts.},
author = {Edwards, Bernard L. and Daddato, Robert and Schulz, Klaus Juergen and Alliss, Randall and Hamkins, Jon and Giggenbach, DIrk and Robinson, Bryan and Braatz, Lena},
booktitle = {2019 IEEE International Conference on Space Optical Systems and Applications, ICSOS 2019},
doi = {10.1109/ICSOS45490.2019.8978979},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Edwards et al. - 2019 - An Update on the CCSDS Optical Communications Working Group Interoperability Standards.pdf:pdf},
isbn = {9781728105000},
month = {oct},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{An Update on the CCSDS Optical Communications Working Group Interoperability Standards}},
year = {2019}
}
@article{Adhikary2020,
abstract = {To maximize file transfer from deep-space vehicles, a space-to-earth content-transfer protocol that combines turbo codes, RaptorQ codes, real-time channel prediction, and dynamic code-rate selection is proposed. The protocol features a signal-to-noise ratio prediction model that facilitates the periodic adjustment of turbo encoder to achieve adaptive-rate transmission, and fountain codes to eliminate retransmission of specific packets. Simulation results indicate that an increase of about 132% in file transfer rate is achievable compared to fixed-rate transmission scheme.},
author = {Adhikary, Rojina and Daigle, John N. and Cao, Lei},
doi = {10.1109/TAES.2019.2921212},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adhikary, Daigle, Cao - 2020 - Dynamic Code Selection Method for Content Transfer in Deep-Space Network.pdf:pdf},
issn = {15579603},
journal = {IEEE Transactions on Aerospace and Electronic Systems},
keywords = {Channel prediction,RaptorQ codes,deep-space communications,dynamic code selection method (DCSM),turbo codes},
month = {feb},
number = {1},
pages = {456--474},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Dynamic Code Selection Method for Content Transfer in Deep-Space Network}},
volume = {56},
year = {2020}
}
@article{Liang2020,
abstract = {Emerging computing paradigm edge computing expects to store and process data at the network edge with reduced latency and improved network bandwidth. To the best of our knowledge, key performance issues such as coding performance of erasure-coded storage systems haven't been investigated for edge computing. In this paper, we present an erasure-coded storage system for edge computing. Unlike the data center and cloud storage systems, it employs edge devices to perform encoding and decoding operations, which can be a performance bottleneck of the whole storage system due to limited computing power. Hence, we present a comprehensive study of the performance of erasure coding to see if it can match the network performance of 5G and Wi-Fi 6 at the network edge. We use the popular edge device Jetson Nano and two state-of-the-art coding libraries: Jerasure and G-CRS. Our evaluation results reveal unsatisfied performance for Jerasure and high variance for G-CRS. To obtain better and stable performance, we accelerate erasure code with OpenMP on a multi-core CPU. Our work demonstrates our acceleration can bring stable performance and match the network bandwidth of 5G and Wi-Fi 6 for some commonly used cases. Besides, our work offers a better understanding of erasure-coded storage systems for edge computing and can be served as a reference to any further optimization for such kind of systems at the network edge.},
author = {Liang, Lixin and He, Huan and Zhao, Jian and Liu, Chengjian and Luo, Qiuming and Chu, Xiaowen},
doi = {10.1109/ACCESS.2020.2995973},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang et al. - 2020 - An erasure-coded storage system for edge computing.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Erasure-coded storage system,edge computing,erasure coding,jetson nano},
pages = {96271--96283},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{An erasure-coded storage system for edge computing}},
volume = {8},
year = {2020}
}
@inproceedings{Mattoussi2015,
abstract = {Content broadcasting over wireless networks heavily relies on Application-Level FEC codes to improve transmission robustness in front of channel erasures. Because they operate in the higher layers of the protocol stack, they benefit from a lot of flexibility. In particular, since streaming applications and bulk transfer applications have different constraints, different packet scheduling strategies may be used by the sender, offering different trade-offs between decoding latency and long erasure burst protection. This work tries to find the best packet scheduling scheme(s) at a sender for a given type of AL-FEC codes. The contributions are twofold: first we define a methodology to measure the impacts of packet scheduling on AL-FEC performance, both under ITerative (IT) and Maximum Likelihood (ML) decoding, for a large set of channels; then we apply this methodology to GLDPC-Staircase codes, an extension of LDPC-Staircase codes using Reed Solomon codes as inner codes. In previous works we showed that these codes have erasure recovery performance close to ideals codes when packets are transmitted in a random order. In this work we show that these codes perform extremely well when sending source packets sequentially first (a key requirement to keep latency minimum with streaming applications) and then extra-repair packets followed by LDPC repair packets, both in a random order.},
author = {Mattoussi, Ferdaouss and Roca, Vincent and Sayadi, Bessem},
booktitle = {2015 European Conference on Networks and Communications, EuCNC 2015},
doi = {10.1109/EuCNC.2015.7194119},
isbn = {9781467373593},
month = {aug},
pages = {465--470},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Impacts of the packet scheduling on the performance of erasure codes: Methodology and application to GLDPC-Staircase codes}},
year = {2015}
}
@article{Berger2008,
abstract = {To achieve reliable packet transmission over a wireless link without feedback, we propose a layered coding approach that uses error-correction coding within each packet and erasure-correction coding across the packets. This layered approach is also applicable to an end-to-end data transport over a network where a wireless link is the performance bottleneck. We investigate how to optimally combine the strengths of error- and erasure-correction coding to optimize the system performance with a given resource constraint, or to maximize the resource utilization efficiency subject to a prescribed performance. Our results determine the optimum tradeoff in splitting redundancy between error-correction coding and erasure-correction codes, which depends on the fading statistics and the average signal to noise ratio (SNR) of the wireless channel. For severe fading channels, such as Rayleigh fading channels, the tradeoff leans towards more redundancy on erasure-correction coding across packets, and less so on error-correction coding within each packet. For channels with better fading conditions, more redundancy can be spent on error-correction coding. The analysis has been extended to a limiting case with a large number of packets, and a scenario where only discrete rates are available via a finite number of transmission modes. {\textcopyright} 2008 IEEE.},
author = {Berger, Christian R. and Zhou, Shengli and Wen, Yonggang and Willett, Peter and Pattipati, Krishna},
doi = {10.1109/T-WC.2008.070581},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berger et al. - 2008 - Optimizing joint erasure- and error-correction coding for wireless packet transmissions.pdf:pdf},
issn = {15361276},
journal = {IEEE Transactions on Wireless Communications},
keywords = {Adaptive modulation and coding,Fountain codes,Inter- and intra-packet coding,Layered coding,Reliable transmission},
month = {nov},
number = {11},
pages = {4586--4595},
title = {{Optimizing joint erasure- and error-correction coding for wireless packet transmissions}},
volume = {7},
year = {2008}
}

@inproceedings{ZhiyongHe2006,
annote = {Very special code design, inferior to AR4JA
iterative encoding procedure, based on the fact that H2 is lower triangular},
author = {{Zhiyong He} and Roy, S. and Fortier, P.},
booktitle = {2006 IEEE International Symposium on Circuits and Systems},
doi = {10.1109/ISCAS.2006.1693323},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhiyong He, Roy, Fortier - 2006 - Encoder architecture with throughput over 10 Gbitsec for quasi-cyclic LDPC codes.pdf:pdf},
isbn = {0-7803-9389-9},
pages = {4},
publisher = {IEEE},
title = {{Encoder architecture with throughput over 10 Gbit/sec for quasi-cyclic LDPC codes}},
url = {http://ieeexplore.ieee.org/document/1693323/},
year = {2006}
}
@article{Roza2014,
abstract = {In order to transmit large amount of various payload data with the limited capacity channel, satellite requires payload data handling system. This paper presents the design and implementation of payload data handling for microsatellite based on FPGA Altera Cyclone IV EP4CE115F29C7. The proposed payload data handling design was divided into two main modules, CCSDS packet module and Reed-Solomon encoder module. Both modules were based on Packet Telemetry CCSDS recommendation. We proposed to use Reed-Solomon (223,255,16) interleave 5 for the outer code. Then followed by pseudo-random sequence and attached sync marker. The functional and performance test result shows and verify the functionality of Payload data handling FPGA implementation. The time required for generating 1 Frame was 54.68 ms for 25 Mbps. In order to synchronize the frame delay transition it requires 89 bytes dummy data. The proposed design uses 1627 total logic element and 92160 bit memory.},
author = {Roza, Widya and {El Amin}, Deddy and Nasser, Eriko Nasemuddin},
doi = {10.1109/ICARES.2014.7024397},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roza, El Amin, Nasser - 2014 - Design and implementation of payload data handling based on field programmable gate array.pdf:pdf},
journal = {Proceeding - ICARES 2014: 2014 IEEE International Conference on Aerospace Electronics and Remote Sensing Technology},
keywords = {CCSDS,FPGA,PDH,Reed-solomon},
month = {jan},
pages = {48--54},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Design and implementation of payload data handling based on field programmable gate array}},
year = {2014}
}
@article{HaoZhong2005,
annote = {PhiInv in parallel!},
author = {{Hao Zhong} and {Tong Zhang}},
doi = {10.1109/TCSI.2005.844113},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hao Zhong, Tong Zhang - 2005 - Block-LDPC a practical LDPC coding system design approach.pdf:pdf},
issn = {1057-7122},
journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
month = {apr},
number = {4},
pages = {766--775},
title = {{Block-LDPC: a practical LDPC coding system design approach}},
url = {http://ieeexplore.ieee.org/document/1417070/},
volume = {52},
year = {2005}
}
@inproceedings{Edwards2019a,
abstract = {International space agencies around the world are working together in the Interagency Operation Advisory Group (IOAG) and the Consultative Committee for Space Data Systems (CCSDS) to develop interoperability standards for optical communications. The standards support optical communication systems for both Near Earth and Deep Space robotic and human-rated spacecraft. The standards generally address both free space links between spacecraft and free space links between spacecraft and ground. This paper will overview the history and structure of the CCSDS Optical Communications Working Group and provide an update on the set of optical communications standards being developed. The paper will address the ongoing work on High Photon Efficiency communications, High Data Rate communications, and Optical On/Off Keying communications. It will also cover the work being done within CCSDS on documenting atmospheric measurement techniques and link operations concepts.},
author = {Edwards, Bernard L. and Daddato, Robert and Schulz, Klaus Juergen and Alliss, Randall and Hamkins, Jon and Giggenbach, DIrk and Robinson, Bryan and Braatz, Lena},
booktitle = {2019 IEEE International Conference on Space Optical Systems and Applications, ICSOS 2019},
doi = {10.1109/ICSOS45490.2019.8978979},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Edwards et al. - 2019 - An Update on the CCSDS Optical Communications Working Group Interoperability Standards.pdf:pdf},
isbn = {9781728105000},
month = {oct},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{An Update on the CCSDS Optical Communications Working Group Interoperability Standards}},
year = {2019}
}
@inproceedings{Ostovari2015,
abstract = {One of the main challenges in wireless networks is addressing the unreliability of the wireless links, and providing reliable transmissions. Two important sources of errors in wireless transmissions are noise and interference. In order to address the errors due to noise, forward error correction methods can be used, in which redundancy is added to the packets to detect and correct the bit errors. However, when the environment is too noisy, or there is interference among the transmissions, the forward error correction codes might not be able to correct the bit errors, resulting in packet erasures. In this case, application layer erasure codes, such as network coding, are useful. In this paper, we consider a wireless network which faces both random bit errors and packet erasures. In order to provide reliable transmissions, we benefit from joint forward error correction and erasure codes, and formulate the successful transmission probability. We also propose a low-complexity method to find the optimal redundancy that should be assign to the forward error correction and erasure code. Our method consists of two phases: offline and online phases. In the offline phase, we generate a reference table, which shows the successful delivery of the packets for each possible transmission strategy. The source node uses this reference table in the second phase to find the optimal strategy depending on the noise and interference level. We show the effectiveness of our proposed method through extensive simulations.},
author = {Ostovari, Pouya and Wu, Jie},
booktitle = {Proceedings - 2015 IEEE 12th International Conference on Mobile Ad Hoc and Sensor Systems, MASS 2015},
doi = {10.1109/MASS.2015.68},
isbn = {9781467391009},
keywords = {Broadcast,error-prone channel,forward error correction,packet erasure,random linear network coding,reedsolomon,wireless networks},
month = {dec},
pages = {324--332},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Reliable broadcast with joint forward error correction and erasure codes in wireless communication networks}},
year = {2015}
}
@inproceedings{Yasotharan2009,
author = {Yasotharan, Hemesh and Carusone, Anthony Chan},
booktitle = {2009 52nd IEEE International Midwest Symposium on Circuits and Systems},
doi = {10.1109/MWSCAS.2009.5236155},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yasotharan, Carusone - 2009 - A flexible hardware encoder for systematic low-density parity-check codes.pdf:pdf},
isbn = {978-1-4244-4479-3},
month = {aug},
pages = {54--57},
publisher = {IEEE},
title = {{A flexible hardware encoder for systematic low-density parity-check codes}},
url = {http://ieeexplore.ieee.org/document/5236155/},
year = {2009}
}
@inproceedings{Gobel2017,
abstract = {In recent years, so called FPGA-SoCs have been introduced by Intel (formerly Altera) and Xilinx. These devices combine multi-core processors with programmable logic. This paper analyzes the various memory and communication interconnects found in actual devices, particularly the Zynq-7020 and Zynq-7045 from Xilinx and the Cyclone V SE SoC from Intel. Issues such as different access patterns, cache coherence and full-duplex communication are analyzed, for both generic accesses as well as for a real workload from the field of video coding. Furthermore, the paper shows that by carefully choosing the memory interconnect networks as well as the software interface, high-speed memory access can be achieved for various scenarios.},
author = {G{\"{o}}bel, Matthias and Elhossini, Ahmed and Chi, Chi Ching and Alvarez-Mesa, Mauricio and Juurlink, Ben},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-56258-2_21},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\"{o}}bel et al. - 2017 - A quantitative analysis of the memory architecture of FPGA-SoCs.pdf:pdf},
isbn = {9783319562575},
issn = {16113349},
pages = {241--252},
publisher = {Springer Verlag},
title = {{A quantitative analysis of the memory architecture of FPGA-SoCs}},
url = {https://link.springer.com/chapter/10.1007/978-3-319-56258-2_21},
volume = {10216 LNCS},
year = {2017}
}
@techreport{CCSDS130,
author = {CCSDS130.0-G.3},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/CCSDS130.0-G.3 - 2014 - Overview of Space Communication Protocols.pdf:pdf},
institution = {CCSDS},
title = {{Overview of Space Communication Protocols}},
year = {2014}
}
@inproceedings{Garrammone2012,
abstract = {The use of erasure codes in space communications has proved to be promising in order to make communication more robust against both independent and correlated data losses. In particular, erasure codes are an appealing solution to provide space communications with increased reliability, especially in scenarios where large latencies make the use of automatic repeat request (ARQ) strategies problematic. In this regard, preliminary studies on the use of binary low-density parity-check (LDPC) codes under maximum likelihood (ML)/iterative (IT) decoding have been carried out showing the performance benefit they can bring over traditional schemes based on retransmissions. This paper extends the analysis conducted in previous studies towards non-binary LDPC codes. Performance assessment is carried out with respect to reliability metrics (codeword error rate) and encoding/decoding complexity, taking into consideration the limitations of space communications in terms of storage and processing capabilities. Finally, the paper sketches some design guidelines on the integration of the proposed codes into the Consultative Committee for Space Data Systems (CCSDS) protocol stack, implemented as extension of the Licklider Transmission Protocol (LTP). {\textcopyright} 2012 IEEE.},
author = {Garrammone, Giuliano and {De Cola}, Tomaso and Matuz, Balazs and Liva, Gianluigi},
booktitle = {2012 6th Advanced Satellite Multimedia Systems Conference, ASMS 2012 and 12th Signal Processing for Space Communications Workshop, SPSC 2012},
doi = {10.1109/ASMS-SPSC.2012.6333092},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garrammone et al. - 2012 - Erasure codes for space communications Recent findings and new challenges.pdf:pdf},
isbn = {9781467326766},
pages = {29--35},
title = {{Erasure codes for space communications: Recent findings and new challenges}},
year = {2012}
}
@inproceedings{Gomes2007,
annote = {DVB is upper triangular},
author = {Gomes, Marco and Falcao, Gabriel and Sengo, Alexandre and Ferreira, Vitor and Silva, Vitor and Falcao, Miguel},
booktitle = {2007 Internatonal Conference on Microelectronics},
doi = {10.1109/ICM.2007.4497709},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gomes et al. - 2007 - High throughput encoder architecture for DVB-S2 LDPC-IRA codes.pdf:pdf},
isbn = {978-1-4244-1846-6},
month = {dec},
pages = {271--274},
publisher = {IEEE},
title = {{High throughput encoder architecture for DVB-S2 LDPC-IRA codes}},
url = {http://ieeexplore.ieee.org/document/4497709/},
year = {2007}
}
@article{Chen2017,
abstract = {This paper proposes a novel encoder architecture of low-density parity-check (LDPC) generator matrix in frequency modulation-China digital radio (CDR), which was promulgated in August 2013. We utilize the specific structure of LDPC parity matrix to parallelize row and column encoding operations. An optimized method is also proposed to control memories, which can be reused for the LDPC code with different code rates to improve the utilization of hardware resources. The proposed LDPC encoder and decoder are implemented on Xilinx FPGA. According to simulation results of ModelSim and MATLAB, we also verify that the proposed method has the advantages of reduced resource consumption, low power, and high accuracy. The proposed encoder can achieve throughput up to 400 Mbps. In particular, with Lena binary image as the test transmission data, we find that the decoded result meets the error requirements of CDR.},
author = {Chen, Dongying and Chen, Pingping and Fang, Yi},
doi = {10.1109/ACCESS.2017.2723046},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Chen, Fang - 2017 - Low-Complexity High-Performance Low-Density Parity-Check Encoder Design for China Digital Radio Standard.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {China digital radio (CDR),FPGA,Frequency modulation,LDPC,encoder},
month = {jul},
pages = {20880--20886},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Low-Complexity High-Performance Low-Density Parity-Check Encoder Design for China Digital Radio Standard}},
volume = {5},
year = {2017}
}
@article{Theodoropoulos2020,
author = {Theodoropoulos, Dimitris and Kranitis, Nektarios and Tsigkanos, Antonis and Paschalis, Antonios},
doi = {10.1109/tvlsi.2020.2975050},
issn = {1063-8210},
journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
month = {mar},
pages = {1--10},
publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
title = {{Efficient Architectures for Multigigabit CCSDS LDPC Encoders}},
year = {2020}
}
@inproceedings{AlHariri2013,
author = {{Al Hariri}, Alaa Aldin and Monteiro, Fabrice and Sieler, Loic and Dandache, Abbas},
booktitle = {2013 IEEE 19th International On-Line Testing Symposium (IOLTS)},
doi = {10.1109/IOLTS.2013.6604069},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Al Hariri et al. - 2013 - A high throughput configurable parallel encoder architecture for Quasi-Cyclic Low-Density Parity-Check Codes.pdf:pdf},
isbn = {978-1-4799-0664-2},
month = {jul},
pages = {163--166},
publisher = {IEEE},
title = {{A high throughput configurable parallel encoder architecture for Quasi-Cyclic Low-Density Parity-Check Codes}},
url = {http://ieeexplore.ieee.org/document/6604069/},
year = {2013}
}
@book{Athavale2005,
abstract = {High-speed serial I/O can be used to solve system interconnect design challenges. Such I/Os, when integrated into a highly programmable digital environment such as an FPGA, allow you to create high-performance designs that were never possible before. This book discusses the many aspects of high-speed serial designs with real world examples of how to implement working designs, including: ■ Basic I/O Concepts-Differential signaling, System Synchronous, and Source Synchronous design techniques. ■ Pros and Cons of different implemenations-How to evaluate the cost advantages, the reduced EMI, the maximum data flow, and so on. ■ SERDES Design-Basic theory, how to implement highly efficient serial to parallel channels, coding schemes, and so on. ■ Design Considerations-Standard and custom protocols, signal integrity, impedance, shielding, and so on. ■ Testing-Interpreting eye patterns, reducing jitter, interoperability considerations, bit error testers, and so on.},
author = {Athavale, Abhijit and Christensen, Carl},
edition = {1.0},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Athavale - 2005 - How Do You Get 10-Gbps IO Performance High-Speed Serial I0 Made Simple A Designers' Guide, with FPGA Applications.pdf:pdf},
keywords = {64b/66b,8b/10b,asic,assp,fpga,programmable logic,serialio,spartan,virtex,xilinx},
publisher = {Xilinx},
title = {{High-Speed Serial I/0 Made Simple}},
url = {www.xilinx.com/xcell},
year = {2005}
}
@inproceedings{Neto2015,
annote = {Typical Dual-Diagonal Structure. Recursive calculation},
author = {Neto, Nelson Alves Ferreira and de Oliveira, Joaquim Ranyere S. and de Oliveira, Wagner Luiz A. and Bittencourt, Joao Carlos N.},
booktitle = {2015 25th International Workshop on Power and Timing Modeling, Optimization and Simulation (PATMOS)},
doi = {10.1109/PATMOS.2015.7347589},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neto et al. - 2015 - VLSI architecture design and implementation of a LDPC encoder for the IEEE 802.22 WRAN standard.pdf:pdf},
isbn = {978-1-4673-9419-2},
month = {sep},
pages = {71--76},
publisher = {IEEE},
title = {{VLSI architecture design and implementation of a LDPC encoder for the IEEE 802.22 WRAN standard}},
url = {http://ieeexplore.ieee.org/document/7347589/},
year = {2015}
}
@incollection{Hu2012,
abstract = {Low density parity-check (LDPC) code is, currently, one kind of sparse parity-check matrix based linear block error-correcting codes which could highly approach the Shannon limit with iterative decoding. LDPC codes' superior performance, which may surpass Turbo code, makes it suitable for transmitting large amount of data in multimedia broadcasting system. CMMB is the first multimedia broadcasting system in China that is targeted at handheld devices with small screens, such as mobile phones and PDA. For its superior performance, CMMB uses LDPC as its channel coding. Moreover, CMMB adopts OFDM as its means of transmission, which make it more resistant to interference. This paper first introduces the encoding of LDPC based on LU decomposition, and then derives the transform process of LU decomposition algorithm of sparse matrix. Finally, based on the decomposition results of sparse matrix for the LDPC code used in CMMB, it is verified that the mincolproduct algorithm has achieved its expected goal. {\textcopyright} 2012 Springer-Verlag GmbH Berlin Heidelberg.},
address = {Berlin, Heidelberg},
author = {Hu, Junyang and Jiang, Kangming},
booktitle = {Frontiers in Computer Education. Advances in Intelligent and Soft Computing},
doi = {10.1007/978-3-642-27552-4_114},
editor = {{Sambath S.}, Zhu E.},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Jiang - 2012 - The improved LU-based decomposition algorithm for sparse matrix of LDPC code.pdf:pdf},
isbn = {9783642275517},
issn = {18675662},
keywords = {CMMB,LDPC encoder,LU-based min-colproduct decomposition algorithm},
pages = {867--874},
publisher = {Springer},
title = {{The improved LU-based decomposition algorithm for sparse matrix of LDPC code}},
volume = {133},
year = {2012}
}
@techreport{CCSDS130Green,
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2012 - TM SYNCHRONIZATION AND CHANNEL CODING— SUMMARY OF CONCEPT AND RATIONALE INFORMATIONAL REPORT CCSDS 130.1-G-2.pdf:pdf},
title = {{TM SYNCHRONIZATION AND CHANNEL CODING— SUMMARY OF CONCEPT AND RATIONALE INFORMATIONAL REPORT CCSDS 130.1-G-2}},
url = {https://public.ccsds.org/Pubs/130x1g2.pdf},
year = {2012}
}
@article{Nguyen2019a,
abstract = {Optical wireless communications using a laser is a strong candidate for the next generation satellite communications due to its large bandwidth. However, the channel environment of satellite communications is very tough, suffering from fading by atmospheric turbulence. Therefore, an efficient channel coding such as low-density parity check (LDPC) coding is required to satisfy stable transmission. In this paper, fading noise from atmospheric turbulence is reproduced to simulate the satellite channel. Then, this time-varying signal is used to evaluate the performance of the LDPC codes in different channel environments. At the same time, in order to improve the system performance further, an interleaving method in combination with LDPC codes is proposed to overcome the problem of burst error, which frequently occurs in the optical satellite communication systems (OSC). Simulation results show that the block-interleaving scheme can achieve a 5 dB gain compared to the pure LDPC scheme. The processing time is considered to determine the proper size of interleaving blocks suitable for optical satellite communications.},
author = {Nguyen, Duy Thong and Park, Youngil},
doi = {10.1016/j.optcom.2019.02.071},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Park - 2019 - Performance analysis of interleaved LDPC for optical satellite communications.pdf:pdf},
issn = {00304018},
journal = {Optics Communications},
keywords = {Atmospheric turbulence,Block interleaving,Fading,Low-density parity check (LDPC),Optical satellite communications (OSC),Optical wireless communications (OWC)},
month = {jul},
pages = {13--18},
publisher = {Elsevier B.V.},
title = {{Performance analysis of interleaved LDPC for optical satellite communications}},
url = {https://doi.org/10.1016/j.optcom.2019.02.071},
volume = {442},
year = {2019}
}
@article{Tang2020,
abstract = {Recently, a new polynomial basis over finite fields was proposed such that the computational complexity of the fast Fourier transform (FFT) is O(n\log n). Based on FFTs, the encoding and decoding algorithms for Reed-Solomon (RS) codes were proposed, which are shown to have the lowest computational complexity in the literature. However, these algorithms require that the code length and the number of parity symbols must be power of two. In this letter, we present the encoding and decoding algorithms for arbitrary RS codes based on FFTs. Furthermore, these new algorithms also reach the best known complexity bound.},
author = {Tang, Nianqi and Lin, Yun},
doi = {10.1109/LCOMM.2020.2965453},
issn = {15582558},
journal = {IEEE Communications Letters},
keywords = {Decoding algorithm,Fast fourier transform,Reed-solomon codes},
month = {apr},
number = {4},
pages = {716--719},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Fast Encoding and Decoding Algorithms for Arbitrary F2m}},
volume = {24},
year = {2020}
}
@misc{CCSDS2017,
author = {CCSDS},
booktitle = {CCSDS 131.0-B-1},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2017 - BLUE BOOK TM SYNCHRONIZATION AND CHANNEL CODING RECOMMENDED STANDARD.pdf:pdf},
title = {{TM Synchronization and Channel Coding}},
year = {2017}
}
@article{Shannon,
author = {{E. Shannon}, Claude},
doi = {10.1145/584091.584093},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/E. Shannon - 1948 - A Mathematical Theory of Communication.pdf:pdf},
journal = {Bell System Technical Journal},
pages = {379--423},
title = {{A Mathematical Theory of Communication}},
volume = {27},
year = {1948}
}
@article{Fang2012,
abstract = {We investigate the performance of the protograph low-density parity-check (LDPC) codes, which have been shown to possess simple structures and outstanding error performance over additive white Gaussian noise (AWGN) channels, over partial response (PR) channels using the finite-length extrinsic information transfer (EXIT) algorithm. Due to the intersymbol interference (ISI) caused by the PR channels, we observe that the conventional protograph LDPC codes do not perform well in terms of error rates. We further propose a new design scheme and construct three new types of protograph LDPC codes. Unlike conventional protograph LDPC codes in which the highest-degree variable nodes are punctured, the new protograph LDPC codes have their lowest-degree variable nodes punctured. Moreover, some edge re-connections are made in one of the proposed codes. The EXIT-chart analysis, the convergence analysis and the bit-error-rate simulation have shown that all three new codes outperform the conventional protograph LDPC codes. Moreover, two of the proposed codes are superior to the regular column-weight-3 LDPC code and thus they are good alternatives compared to other error-correction codes for use in data storage systems. {\textcopyright} 2012 IEEE.},
annote = {Reference [89] in design guidelines. Talks about AR4JA. See [36] (AR4JA). Focus on conclusion

The AR3A code and the AR4JA code have been shown to
possess excellent error performance over an AWGN channel.

We also consider the regular column-weight-3 LDPC code
[41], which has been shown to provide better error perfor-
mance than the irregular LDPC codes over PR channels, but
is found to be outperformed by the AR3A code and the AR4JA
code in AWGN channels},
author = {Fang, Yi and Chen, Pingping and Wang, Lin and Lau, Francis C.M.},
doi = {10.1109/TCOMM.2012.072412.110464},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fang et al. - 2012 - Design of protograph LDPC codes for partial response channels.pdf:pdf},
issn = {00906778},
journal = {IEEE Transactions on Communications},
keywords = {Finite-length EXIT algorithm,intersymbol interference (ISI),partial response (PR) channels,protograph LDPC codes},
number = {10},
pages = {2809--2819},
title = {{Design of protograph LDPC codes for partial response channels}},
volume = {60},
year = {2012}
}
@techreport{Chiani2007,
annote = {Interesting EXAMPLE PROFILES for block lengths and data rates.
Decoding demystified (somewhat)},
author = {Chiani, Marco and Paolini, Enrico},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chiani, Paolini - 2007 - Long Erasure Codes for CCSDS Applications Authors.pdf:pdf},
title = {{Long Erasure Codes for CCSDS Applications Authors}},
url = {https://pdfs.semanticscholar.org/6100/8d83881d98a81a49b94e6ac5da9e1fa46317.pdf},
year = {2007}
}
@inproceedings{Poulenard2019,
abstract = {A simulation framework based on a physical-layer based abstraction to predict physical layer performances and to compare different forward error correcting (FEC) codes is presented. This framework is used to jointly design interleaving and FEC schemes for free space optical link. A sub-class of regular Low-Density Parity-Check codes is shown to be an interesting alternative to current space communication standard for optical links that require low error floor and high decoder throughput. End-to-end simulations show the feasibility of error free link from a LEO satellite to a high complexity ground station at 25Gbits/s and from a LEO satellite to low complexity optical ground station at 10 Gbits/s. The proposed protection scheme is composed of FG LDPC code and a bit interleaver to span the burst of errors.},
author = {Poulenard, S. and Gadat, B. and Chouteau, J. F. and Anfray, T. and Poulliat, C. and Jego, C. and Hartmann, O. and Artaud, G. and Meric, H.},
booktitle = {International Conference on Space Optics — ICSO 2018},
doi = {10.1117/12.2536120},
editor = {Karafolas, Nikos and Sodnik, Zoran and Cugny, Bruno},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Poulenard et al. - 2019 - Forward error correcting code for high data rate LEO satellite optical downlinks.pdf:pdf},
isbn = {9781510630772},
keywords = {LDPC code,Optical link,decoder design,error correcting code},
month = {jul},
pages = {200},
publisher = {SPIE},
title = {{Forward error correcting code for high data rate LEO satellite optical downlinks}},
url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11180/2536120/Forward-error-correcting-code-for-high-data-rate-LEO-satellite/10.1117/12.2536120.full},
volume = {11180},
year = {2019}
}
@techreport{com1811soft,
abstract = {The COM-1811SOFT is a high-speed LDPC code error correction encoder/decoder written in generic VHDL. The entire VHDL source code is deliverable. Key features and performance:  Includes encoding, decoding, frame synchronization and data randomization.  Compliant with the C2 code specified in CCSDS 131.0-B-3, Blue Book, section 7.3 o C2 code, rate 223/255 o fixed-length frame size (8160,7136)  Typical Bit Error Rate / Frame Error Rate: BER = 6 10-6 FER = 6 10-4 @ E b /N o = 3.8 dB  Throughput: Encoding: > 1 Gbits/s Decoding: 50-500 Mbits/s depending on FPGA type and operating E b /N o  Provided with IP core: o VHDL source code o Matlab .m file for simulating the encoding and decoding algorithms, for generating stimulus files for VHDL simulation and for end-to-end BER/FER performance analysis at various signal to noise ratios o VHDL testbench Target Hardware The code is written in generic standard VHDL and is thus portable to a variety of FPGAs. The code was developed and tested on a Xilinx 7-series FPGA but is expected to work similarly on other targets.},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2019 - COM-1811SOFT CCSDS LDPC C2 code encoderdecoder VHDL source code overview IP core Overview.pdf:pdf},
title = {{COM-1811SOFT CCSDS LDPC C2 code encoder/decoder VHDL source code overview / IP core Overview}},
url = {https://comblock.com/download/com1811soft.pdf},
year = {2019}
}
@article{Hu2005,
abstract = {We propose a general method for constructing Tanner graphs having a large girth by establishing edges or connections between symbol and check nodes in an edge-by-edge manner, called progressive edge-growth (PEG) algorithm. Lower bounds on the girth of PEG Tanner graphs and on the minimum distance of the resulting low-density parity-check (LDPC) codes are derived in terms of parameters of the graphs. Simple variations of the PEG algorithm can also be applied to generate linear-time encodeable LDPC codes. Regular and irregular LDPC codes using PEG Tanner graphs and allowing symbol nodes to take values over GF(q) (q > 2) are investigated. Simulation results show that the PEG algorithm is a powerful algorithm to generate good short-block-length LDPC codes. {\textcopyright} 2005 IEEE.},
annote = {PEG algorithm},
author = {Hu, Xiao Yu and Eleftheriou, Evangelos and Arnold, Dieter M.},
doi = {10.1109/TIT.2004.839541},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Eleftheriou, Arnold - 2005 - Regular and irregular progressive edge-growth tanner graphs.pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Girth,LDPC codes over GF(q),Low-density parity check (LDPC) codes,PEG Tanner graphs,Progressive edge growth (PEG)},
month = {jan},
number = {1},
pages = {386--398},
title = {{Regular and irregular progressive edge-growth tanner graphs}},
volume = {51},
year = {2005}
}
@inproceedings{Sklyarov2015,
abstract = {Zynq-7000 devices from Xilinx incorporate a dual-core processing unit running software, programmable logic that can be customized to implement different hardware circuits, and interfaces enabling interactions and data exchange between software and hardware components to be provided. Such devices permit complete solutions for embedded systems to be integrated on a chip. The paper compares different types of Zynq-based systems and studies communications between the processing unit and the programmable logic. Thorough evaluation of the available on-chip high-performance interfaces is done based on the results of numerous experiments. Two types of projects that are data sorters and popcount computations were chosen for particular assessments. We found that efficiency of software/hardware solutions depends on many mutually related factors such as the volume of processed data, applied parallelism, and involved high-performance ports. Concrete recommendations based on experiments and comparisons are given and discussed.},
author = {Sklyarov, Valery and Skliarova, Iouliia and Silva, Joao and Sudnitson, Alexander},
booktitle = {Proceedings - 18th Euromicro Conference on Digital System Design, DSD 2015},
doi = {10.1109/DSD.2015.45},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sklyarov et al. - 2015 - Analysis and comparison of attainable hardware acceleration in all programmable systems-on-chip.pdf:pdf},
isbn = {9781467380355},
keywords = {Communication overheads,High-performance ports,Programmable system-on-chip,Software/hardware systems},
month = {oct},
pages = {345--352},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Analysis and comparison of attainable hardware acceleration in all programmable systems-on-chip}},
year = {2015}
}
@misc{CCSDS131,
author = {CCSDS131.5-O-1},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/CCSDS131.5-O-1 - 2014 - Erasure Correcting Codes for Use in Near-Earth and Deep Space Communications.pdf:pdf},
title = {{Erasure Correcting Codes for Use in Near-Earth and Deep Space Communications}},
year = {2014}
}
@article{Schmidt2009,
abstract = {Interleaved Reed-Solomon codes are applied in numerous data processing, data transmission, and data storage systems. They are generated by interleaving several codewords of ordinary Reed-Solomon codes. Usually, these codewords are decoded independently by classical algebraic decoding methods. However, by collaborative algebraic decoding approaches, such interleaved schemes allow the correction of error patterns beyond half the minimum distance, provided that the errors in the received signal occur in bursts. In this work, collaborative decoding of interleaved Reed-Solomon codes by multisequence shift-register synthesis is considered and analyzed. Based on the framework of interleaved Reed-Solomon codes, concatenated code designs are investigated, which are obtained by interleaving several Reed-Solomon codes, and concatenating them with an inner code. {\textcopyright} 2009 IEEE.},
author = {Schmidt, Georg and Sidorenko, Vladimir R. and Bossert, Martin},
doi = {10.1109/TIT.2009.2021308},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidt, Sidorenko, Bossert - 2009 - Collaborative decoding of interleaved Reed-Solomon codes and concatenated code designs.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
keywords = {Collaborative decoding,Concatenated codes,Heterogeneous IRS codes,Homogeneous interleaved Reed-Solomon (IRS) codes,Interleaved Reed-Solomon (IRS) codes,Multiple sequences,Shift-register synthesis},
number = {7},
pages = {2991--3012},
title = {{Collaborative decoding of interleaved Reed-Solomon codes and concatenated code designs}},
volume = {55},
year = {2009}
}
@article{Yu2014,
annote = {Uses SRAA for dense PhiInv. Interesting},
author = {Yu, Shuo and Liu, Changyin and Zhang, Peng and Jiang, Lanxiang},
doi = {10.1049/el.2013.2390},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu et al. - 2014 - Efficient encoding of QC-LDPC codes with multiple-diagonal parity-check structure.pdf:pdf},
issn = {0013-5194},
journal = {Electronics Letters},
month = {feb},
number = {4},
pages = {320--321},
title = {{Efficient encoding of QC-LDPC codes with multiple-diagonal parity-check structure}},
url = {https://digital-library.theiet.org/content/journals/10.1049/el.2013.2390},
volume = {50},
year = {2014}
}
@article{Fang2015,
abstract = {Low-density parity-check (LDPC) codes have attracted much attention over the past two decades since they can asymptotically approach the Shannon capacity in a variety of data transmission and storage scenarios. As a type of promising structured LDPC codes, the protograph LDPC codes not only inherit the advantage of conventional LDPC codes, i.e., excellent error performance, but also possess simple representations to realize fast encoding and efficient decoding. This paper provides a comprehensive survey on the state-of-the-art in protograph LDPC code design and analysis for different channel conditions, including the additive white Gaussian noise (AWGN) channels, fading channels, partial response (PR) channels, and Poisson pulse-position modulation (PPM) channels. Moreover, the applications of protograph LDPC codes to joint source-and-channel coding (JSCC) and joint channel-and-physical-layer-network coding (JCPNC) are reviewed and studied. In particular, we focus our attention on the encoding design and assume the decoder is implemented by the belief propagation (BP) algorithm. Hopefully, this survey may facilitate research in this area.},
author = {Fang, Yi and Bi, Guoan and Guan, Yong Liang and Lau, Francis C.M.},
doi = {10.1109/COMST.2015.2436705},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fang et al. - 2015 - A Survey on Protograph LDPC Codes and Their Applications.pdf:pdf},
issn = {1553877X},
journal = {IEEE Communications Surveys and Tutorials},
keywords = {Asymptotic weight distribution (AWD),decoding threshold,extrinsic information transfer (EXIT),protograph lowdensity parity-check (LDPC) codes},
month = {oct},
number = {4},
pages = {1989--2016},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{A Survey on Protograph LDPC Codes and Their Applications}},
volume = {17},
year = {2015}
}
@inproceedings{Wang2008,
annote = {LU},
author = {Wang, Peng and Chen, Yong-en},
booktitle = {2008 International Conference on Intelligent Information Hiding and Multimedia Signal Processing},
doi = {10.1109/IIH-MSP.2008.15},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Chen - 2008 - Low-Complexity Real-Time LDPC Encoder Design for CMMB.pdf:pdf},
isbn = {978-0-7695-3278-3},
month = {aug},
pages = {1209--1212},
publisher = {IEEE},
title = {{Low-Complexity Real-Time LDPC Encoder Design for CMMB}},
url = {http://ieeexplore.ieee.org/document/4604260/},
year = {2008}
}
@article{Wang2017,
author = {Wang, Xiumin and Ge, Tingting and Li, Jun and Su, Chen and Hong, Fangfei},
doi = {10.1049/cje.2017.01.006},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2017 - Efficient Multi-rate Encoder of QC-LDPC Codes Based on FPGA for WIMAX Standard.pdf:pdf},
issn = {1022-4653},
journal = {Chinese Journal of Electronics},
month = {mar},
number = {2},
pages = {250--255},
title = {{Efficient Multi-rate Encoder of QC-LDPC Codes Based on FPGA for WIMAX Standard}},
url = {http://digital-library.theiet.org/content/journals/10.1049/cje.2017.01.006},
volume = {26},
year = {2017}
}
@article{Burshtein2004a,
abstract = {We propose an efficient maximum-likelihood (ML) decoding algorithm for decoding low-density parity-check (LDPC) codes over the binary-erasure channel (BEC). We also analyze the computational complexity of the proposed algorithm. {\textcopyright} 2004 IEEE.},
author = {Burshtein, David and Miller, Gadi},
doi = {10.1109/TIT.2004.836694},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burshtein, Miller - 2004 - An efficient maximum-likelihood decoding of LDPC codes over the binary erasure channel.pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
month = {nov},
number = {11},
pages = {2837--2844},
title = {{An efficient maximum-likelihood decoding of LDPC codes over the binary erasure channel}},
volume = {50},
year = {2004}
}
@inproceedings{Schmidt2018,
abstract = {Direct optical downlinks from small LEO spacecraft to Earth have the potential to solve the increasing demands for higher data rates due to increased mission requirements. The Institute of Communications and Navigation of the German Aerospace Center (DLR) has been working since more than 10 years on the development and demonstration of highly compact and lightweight experimental terminals to enable optical communications for small LEO spacecraft. In the framework of the OSIRIS program (Optical Space Infrared Downlink System), the optical communication payload for DLR's BiROS satellite has been developed. Launched in 2016, BiROS and OSIRIS will demonstrate their performance in a measurement campaign in 2017. This paper will give an overview over the program OSIRIS and the development roadmap.},
author = {Schmidt, Christopher and Fuchs, Christian},
booktitle = {2017 IEEE International Conference on Space Optical Systems and Applications, ICSOS 2017},
doi = {10.1109/ICSOS.2017.8357205},
isbn = {9781509065110},
keywords = {Free-Space Optics,Optical Communication,Satellite Communication},
month = {may},
pages = {19--22},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{The OSIRIS program - First results and Outlook}},
year = {2018}
}
@article{Davarian2020a,
abstract = {This article is the second of a three-part series in which we present the results of a study exploring concepts for improving communications and tracking capabilities of deep space SmallSats. In Part I, we discussed SmallSat direct-to-earth links and SmallSat communications equipment, and provided recommendations for future work. In Part II, we focus on SmallSat navigation options, Disruption Tolerant Networking (DTN), proximity links, and the use of the communication link for science observations, and we provide recommendations for future work. We have examined both radio and optical navigation options, and considered autonomous and semiautonomous navigation to reduce operational costs for planetary SmallSats. We note that communication link resilience to delay and disruption enhances spacecraft autonomy; therefore, we have provided a discussion of DTN to indicate that using DTN allows for automated data transmission and recovery, therefore, reducing manual operations. SmallSats in deep space may utilize a relay spacecraft for communications with earth or function as a relay for landed and in-orbit assets. We present a detailed examination of relay proximity links and networks where we address both proximity hardware and networking scenarios. The proximity link features that we examine include the network architecture and its relationship to DTN, proximity radios and antennas, communications link performance, and proximity navigation. The use of the communication link for science has been practiced by primary missions in deep space scenarios. (Two examples of past planetary radio science experiments can be found in the following: https://solarsystem.nasa.gov/missions/cassini/mission/spacecraft/cassini-orbiter/radio-science-subsystem/ and https://www.boulder.swri.edu/pkb/ssr/ssr-rex.pdf) Likewise, SmallSats can offer their radio links for radio science investigations. This article provides a brief introduction to radio science and presents the prerequisite features necessary for radio science observations by SmallSats. We conclude with nine recommendations based on the findings of the study. These recommendations are guidelines on the design, implementation, and operation of deep space SmallSat communication links. The adoption of some or all of the guidelines should result in an enhanced communication and tracking capability for the deep space SmallSat missions.},
author = {Davarian, Faramaz and Asmar, Sami and Angert, Matt and Baker, John and Gao, Jay and Hodges, Richard and Israel, David and Landau, Damon and Lay, Norman and Torgerson, Leigh and Walsh, William},
doi = {10.1109/MAES.2020.2975260},
issn = {1557959X},
journal = {IEEE Aerospace and Electronic Systems Magazine},
month = {jul},
number = {7},
pages = {26--40},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Improving Small Satellite Communications and Tracking in Deep Space - A Review of the Existing Systems and Technologies with Recommendations for Improvement. Part II: Small Satellite Navigation, Proximity Links, and Communications Link Science}},
volume = {35},
year = {2020}
}
@inproceedings{Hisamatsu2010,
abstract = {Packet-level erasure correction is considered for downstream packets each of which is delivered from a base station to an individual receiver (i.e., user) over a lossy shared wireless network where only a very limited upstream feedback is provided. Note that, while the destination of each packet is a single user, each packet can be overheard by all users in the shared network. With exploiting this overhearing property of wireless links, we focus on packet recovery by exclusive-OR (XOR) packet composition-based forward-erasure- correction (FEC). For network applications with packet-loss tolerance and delay-time limitation, our goal is to increase the effective packet received rate (the ratio of finally received/recovered packets after applying FEC) of each user with fairness in a low-cost manner. We propose a simple XOR packet composition scheme that can approximately maximize the minimum effective packet received rate among users, based on an experimentally suggested linear relation between the packet loss rates and the optimal packet composition ratios among users. Simulation results clearly indicate the potential effectiveness of the proposal. {\textcopyright}2010 IEEE.},
author = {Hisamatsu, Satoshi and Tamura, Hitomi and Tsuru, Masato and Oie, Yuji},
booktitle = {IEEE International Symposium on Personal, Indoor and Mobile Radio Communications, PIMRC},
doi = {10.1109/PIMRCW.2010.5670506},
isbn = {9781424491162},
keywords = {FEC/FZC (Forward Erasure Correction),Lossy wireless network,Packet composition,Packet recovery},
pages = {496--501},
title = {{Packet-level forward erasure correction with user fairness in lossy wireless networks}},
year = {2010}
}
@article{Calzolari2007,
abstract = {Future space missions will put severe constraints on communication links in terms of data rates, bandwidth occupancy, complexity, and performance. The requirements imposed by the new missions and their consequences on channel code design are presented in the first part of the paper. All relevant issues, including code rates, frame lengths, modulation formats, performance metrics, complexity, and others, are discussed. In the second part of the paper, long erasure correcting codes are presented and their properties explained. These codes operate at the upper layers of the space link protocol and constitute an attractive new frontier for zero packet loss in future space communications. {\textcopyright} 2006 IEEE.},
author = {Calzolari, Gian Paolo and Chiani, Marco and Chiaraluce, Franco and Garello, Roberto and Paolini, Enrico},
doi = {10.1109/JPROC.2007.905134},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Calzolari et al. - 2007 - Channel coding for future space missions New requirements and trends.pdf:pdf},
journal = {Proceedings of the IEEE},
keywords = {Channel coding,Forward error correction,Long erasure correcting codes,Low-density parity-check codes,Packet erasures},
number = {11},
pages = {2157--2170},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Channel coding for future space missions: New requirements and trends}},
volume = {95},
year = {2007}
}
@article{Zhong2007a,
abstract = {By implementing a field-programmable gate array (FPGA)-based simulator, we investigate the performance of randomly constructed high-rate quasi-cyclic (QC) low-density parity-check (LDPC) codes for the magnetic recording channel at very low block sector error rates. On the basis of extensive simulations, we conjecture guidelines for designing randomly constructed high-rate regular QC-LDPC codes with low error floor for the magnetic recording channel. Experimental results show that our high-rate regular QC-LDPC codes do not suffer from error floor, at least at block error rates of 10-9 , and can realize significant coding gains over Reed-Solomon codes that are used in current practice. Furthermore, we develop a QC-LDPC decoder hardware architecture that is well suited to achieving high decoding throughput. Finally, to evaluate the implementation feasibility of LDPC codes for the magnetic recording channel, using 0.13 $\mu$m standard cell and memory libraries, we designed a read channel signal processing datapath consisting of a parallel max-log-MAP detector and a QC-LDPC decoder, which can achieve a throughput up to 1.8 Gb/s. {\textcopyright} 2007 IEEE.},
author = {Zhong, Hao and Zhong, Tong and Haratsch, Erich F.},
doi = {10.1109/TMAG.2006.888607},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhong, Zhong, Haratsch - 2007 - Quasi-cyclic LDPC codes for the magnetic recording channel Code design and VLSI implementation(2).pdf:pdf},
issn = {00189464},
journal = {IEEE Transactions on Magnetics},
keywords = {Decoder,Error floor,LDPC,VLSI architecture},
month = {mar},
number = {3},
pages = {1118--1123},
title = {{Quasi-cyclic LDPC codes for the magnetic recording channel: Code design and VLSI implementation}},
volume = {43},
year = {2007}
}
@inproceedings{Tzimpragos2013,
annote = {This is what we get if we had no phiInv},
author = {Tzimpragos, Georgios and Kachris, Christoforos and Soudris, Dimitrios and Tomkos, Ioannis},
booktitle = {2013 23rd International Conference on Field programmable Logic and Applications},
doi = {10.1109/FPL.2013.6645587},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tzimpragos et al. - 2013 - A low-complexity implementation of QC-LDPC encoder in reconfigurable logic.pdf:pdf},
isbn = {978-1-4799-0004-6},
month = {sep},
pages = {1--4},
publisher = {IEEE},
title = {{A low-complexity implementation of QC-LDPC encoder in reconfigurable logic}},
url = {http://ieeexplore.ieee.org/document/6645587/},
year = {2013}
}
@misc{ECSS,
author = {ECSS},
title = {{ECSS-E-ST-50-11C – SpaceFibre – Very high-speed serial link}},
url = {https://ecss.nl/standard/ecss-e-st-50-11c-spacefibre-very-high-speed-serial-link/},
year = {2019}
}
@inproceedings{YongminJung2012,
annote = {Perfect dual diagonal},
author = {{Yongmin Jung} and {Chulho Chung} and {Jaeseok Kim} and {Yunho Jung}},
booktitle = {2012 International SoC Design Conference (ISOCC)},
doi = {10.1109/ISOCC.2012.6407078},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yongmin Jung et al. - 2012 - 7.7Gbps encoder design for IEEE 802.11nac QC-LDPC codes.pdf:pdf},
isbn = {978-1-4673-2990-3},
month = {nov},
pages = {215--218},
publisher = {IEEE},
title = {{7.7Gbps encoder design for IEEE 802.11n/ac QC-LDPC codes}},
url = {http://ieeexplore.ieee.org/document/6407078/},
year = {2012}
}
@inproceedings{Andrews2005,
author = {Andrews, K. and Dolinar, S. and Thorpe, J.},
booktitle = {Proceedings. International Symposium on Information Theory, 2005. ISIT 2005.},
doi = {10.1109/ISIT.2005.1523758},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrews, Dolinar, Thorpe - 2005 - Encoders for block-circulant LDPC codes.pdf:pdf},
isbn = {0-7803-9151-9},
pages = {2300--2304},
publisher = {IEEE},
title = {{Encoders for block-circulant LDPC codes}},
url = {http://ieeexplore.ieee.org/document/1523758/},
year = {2005}
}
@techreport{Perez2007,
abstract = {This work describes a method for encoding low-density parity-check (LDPC) codes based on the accumulate-repeat-4-jagged-accumulate (AR4JA) scheme, using the low-density parity-check matrix H instead of the dense generator matrix G. The use of the H matrix to encode allows a significant reduction in memory consumption and provides the encoder design a great flexibility. Also described are new hardware-efficient codes, based on the same kind of pro-tographs, which require less memory storage and area, allowing at the same time a reduction in the encoding delay.},
annote = {This is our basis.
We make this implementation parallel, for both the direct and the R-U method},
author = {Perez, J M and Andrews, K},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perez, Andrews - 2007 - Low-Density Parity-Check Code Design Techniques to Simplify Encoding.pdf:pdf},
keywords = {AR4JA scheme,LDPC,low density parity check codes},
title = {{Low-Density Parity-Check Code Design Techniques to Simplify Encoding}},
url = {https://ipnpr.jpl.nasa.gov/progress_report/42-171/171C.pdf},
year = {2007}
}
@inproceedings{Geethu2015,
abstract = {This paper investigates the performance of two popular packet level erasure coding approaches, i.e., end-to-end and hop-by-hop, for improving the data transmission reliability in Underwater Acoustic Sensor Networks (UWASNs). In the end-to-end approach, encoding and decoding are performed by the source node and sink node, respectively, while the intermediate nodes just forward the data packets without any processing. In this case, the number of redundant packets to be transmitted by the source (i.e., code rate) is chosen based on packet success probability along the path. On the other hand, the hop-by-hop erasure coding is used to achieve reliability over each hop along the path. In this case, apart from the source node, all the intermediate nodes perform the encoding process and each node adaptively computes the number of redundant packets for the next hop based on the quality of the corresponding hop. We present an analytical model to find the communication overhead, energy consumption and average delay of the multi-hop UWASN under the above erasure coding approaches. The results show that hop-by-hop erasure coding outperforms end-to-end erasure coding.},
author = {Geethu, K. S. and Babu, A. V.},
booktitle = {2015 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2015},
doi = {10.1109/ICACCI.2015.7275934},
isbn = {9781479987917},
keywords = {erasure codes,reliable data transfer,underwater acoustic sensor networks},
month = {sep},
pages = {2145--2151},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Performance analysis of erasure coding based data transfer in Underwater Acoustic Sensor Networks}},
year = {2015}
}
@inproceedings{Yang2011,
abstract = {High rate low-density parity-check(LDPC) codes have been under intense research in the serial concatenation of inner Extend partial-response Class 4(EPR4) and outer LDPC codes due to their decoding performance close to the Shannon capacity. The Accumulate Repeat-3 and Accumulate (AR3A) codes, viewed as a subclass of protograph LDPC codes, achieve good decoding performance with simple linear encoder structure and flexible code rates via puncturing variable nodes, which makes us consider the potential of serially concatenating the EPR4 channel with AR3A codes. Simulation results show that AR3A codes can't preserve their performance advantages over regular LDPC codes in the EPR4 channel, although they surpass regular LDPC codes in the AWGN channels. This paper proposes an improved AR3A code where we change the puncturing method, that is, the degree-1 variable nodes are punctured instead of degree-5 ones. The performance curves verify that the improved AR3A code possesses better decoding performance than the regular LDPC code in EPR4 channels and still keeps its original excellent characteristics of low hardware complexity. {\textcopyright} 2011 IEEE.},
author = {Yang, Si Jie and Wang, Lin and Fang, Yi and Chen, Pingping},
booktitle = {ICCRD2011 - 2011 3rd International Conference on Computer Research and Development},
doi = {10.1109/ICCRD.2011.5764084},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2011 - Performance of improved AR3A code over EPR4 channel.pdf:pdf},
isbn = {9781612848372},
keywords = {BCJR,EPR4 channel,PEG,protograph,the improved AR3A codes},
pages = {60--64},
title = {{Performance of improved AR3A code over EPR4 channel}},
volume = {2},
year = {2011}
}
@inproceedings{Fang2017,
abstract = {The protograph low-density parity-check (LDPC) codes have drawn much attention in the past decade due to their simple structures and outstanding error performance. Unfortunately, the conventional protograph codes designed for additive white Gaussian noise (AWGN) channels can not perform well in ergodic Nakagami fading channels. To address this issue, we construct a new rate-1/2 protograph code, called improved accumulate-repeat-Accumulate (IARA) code, by exploiting a modified PEXIT algorithm. We compare the decoding threshold and bit error rate (BER) of the IARA code with the existing protograph codes, the regular LDPC code and the irregular code over ergodic Nakagami fading channels. Both analytical and simulated results show that the proposed IARA code can achieve the lowest BER in the high signal-To-noise-ratio region. Hence, the IARA code can be considered as a good candidate for use in wireless communication systems with fast fading.},
author = {Fang, Yi and Cai, Guofa and Yang, Zhaojie and Chen, Pingping and Han, Guojun},
booktitle = {2017 17th International Symposium on Communications and Information Technologies, ISCIT 2017},
doi = {10.1109/ISCIT.2017.8261162},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fang et al. - 2017 - Performance of protograph LDPC codes over ergodic Nakagami fading channels.pdf:pdf},
isbn = {9781509065141},
keywords = {Channel state information,ergodic Nakagami fading channel,extrinsic information transfer (EXIT) algorithm,protograph low-density parity-check (LDPC) code},
month = {jul},
pages = {1--5},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Performance of protograph LDPC codes over ergodic Nakagami fading channels}},
volume = {2018-Janua},
year = {2017}
}
@misc{Fang2019a,
abstract = {A block-fading (BF) channel, also known as a slow-fading channel, is a type of simple and practical channel model that can characterize the primary feature of a number of wireless-communication applications with low to moderate mobility. Although BF channels have received significant research attention in the past 20 years, designing low-complexity, outage-limit-approaching error-correction codes (ECCs) is still a challenging issue. For this reason, a novel family of protograph low-density paritycheck (LDPC) codes, called rootprotograph (RP) LDPC codes, has been conceived recently. The RP codes not only can realize linearcomplexity encoding and highspeed decoding with the help of the quasi-cyclic (QC) structure but can also achieve near-outage-limit performance in different BF scenarios. In this article, we briefly review the design guidelines of such protograph codes with the aim of inspiring further research activities in this area.},
author = {Fang, Yi and Chen, Pingping and Cai, Guofa and Lau, Francis C.M. and Liew, Soung Chang and Han, Guojun},
booktitle = {IEEE Vehicular Technology Magazine},
doi = {10.1109/MVT.2019.2903343},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fang et al. - 2019 - Outage-limit-approaching channel coding for future wireless communications Root-protograph low-density parity-check.pdf:pdf},
issn = {15566080},
month = {jun},
number = {2},
pages = {85--93},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Outage-limit-approaching channel coding for future wireless communications: Root-protograph low-density parity-check codes}},
volume = {14},
year = {2019}
}
@article{Davarian2020,
annote = {Good intro to optical communications deep space and cubesat},
author = {Davarian, Faramaz and Babuscia, Alessandra and Baker, John and Hodges, Richard and Landau, Damon and Lau, Chi-wung and Lay, Norman and Angert, Matt and Kuroda, Vanessa},
doi = {10.1109/MAES.2020.2980918},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Davarian et al. - 2020 - Improving Small Satellite Communications in Deep Space—A Review of the Existing Systems and Technologies With.pdf:pdf},
issn = {0885-8985},
journal = {IEEE Aerospace and Electronic Systems Magazine},
month = {jul},
number = {7},
pages = {8--25},
title = {{Improving Small Satellite Communications in Deep Space—A Review of the Existing Systems and Technologies With Recommendations for Improvement. Part I: Direct to Earth Links and SmallSat Telecommunications Equipment}},
url = {https://ieeexplore.ieee.org/document/9133660/},
volume = {35},
year = {2020}
}
@article{Fang2018,
abstract = {As one of the most classical data-storage systems, magnetic recording (MR) systems have attracted a significant amount of research attention in the past several decades due to the advantages of low cost and high storage density. Along with the continual increase of areal density of modern MR devices, more severe inter-symbol interference (ISI) and noise appear and thus reliable storage becomes more difficult. To address this challenging problem, turbo detections and error-correction codes (ECCs) have been applied to MR systems so as to significantly improve the overall data-storage reliability. Among all the existing ECCs, low-density parity-check (LDPC) codes are of particular interest because they can offer excellent error performance with relatively low encoding and decoding complexity. This paper presents a comprehensive survey of the latest research advancements in LDPC-code design for MR systems from the perspectives of code construction, decoder design, as well as asymptotic performance-evaluation methodology. More specifically, we summarize the design guidelines of LDPC encoder and decoder over both one-dimensional (OD) ISI and two-dimensional (TD) ISI channels, which are commonly used to characterize MR systems with different areal densities. We also concisely portray the research progress in the design of some LDPC-code variants, such as protograph codes, repeat-accumulate codes, spatially coupled codes, and their non-binary counterparts over the aforementioned ISI channels. In particular, we restrict our attention to the reading process and ignore the written-in errors in MR systems unless otherwise stated. Hopefully, this survey will inspire more research activities in the area of LDPC-coded MR systems.},
author = {Fang, Yi and Han, Guojun and Cai, Guofa and Lau, Francis C.M. and Chen, Pingping and Guan, Yong Liang},
doi = {10.1109/COMST.2018.2797875},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fang et al. - 2018 - Design Guidelines of Low-Density Parity-Check Codes for Magnetic Recording Systems.pdf:pdf},
issn = {1553877X},
journal = {IEEE Communications Surveys and Tutorials},
keywords = {Asymptotic performance,asymptotic weight distribution (AWD),density evolution (DE),extrinsic information transfer (EXIT),inter-symbol interference (ISI),low-density parity-check (LDPC) codes,magnetic recording (MR),turbo detection},
month = {apr},
number = {2},
pages = {1574--1606},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Design Guidelines of Low-Density Parity-Check Codes for Magnetic Recording Systems}},
volume = {20},
year = {2018}
}
Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop
@ARTICLE{Calzolari07, 
author={Calzolari, Gian Paolo and Chiani, Marco and Chiaraluce, Franco and Garello, Roberto and Paolini, Enrico}, 
journal={Proceedings of the IEEE},
title={Channel Coding for Future Space Missions: New Requirements and Trends},   year={2007},  volume={95},  number={11},  pages={2157-2170},  doi={10.1109/JPROC.2007.905134}}

@INPROCEEDINGS{anderson2020,
  author={Andersson, Jan},
  booktitle={2020 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)}, 
  title={Development of a NOEL-V RISC-V SoC Targeting Space Applications}, 
  year={2020},
  volume={},
  number={},
  pages={66-67},
  doi={10.1109/DSN-W50199.2020.00020}}

@misc{derisc2020,
institution={CORDIS},
title = {{De-RISC: Dependable Real-time Infrastructure for Safety-critical Computer}},
url = {https://cordis.europa.eu/project/id/869945},
urldate = {2021-06-26}
}

@InProceedings{Mascio2019,
author="Di Mascio, Stefano
and Menicucci, Alessandra
and Furano, Gianluca
and Monteleone, Claudio
and Ottavi, Marco",
editor="Saponara, Sergio
and De Gloria, Alessandro",
title="The Case for RISC-V in Space",
booktitle="Applications in Electronics Pervading Industry, Environment and Society",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="319--325"
}

@InProceedings{Gobel2017,
author="G{\"o}bel, Matthias
and Elhossini, Ahmed
and Chi, Chi Ching
and Alvarez-Mesa, Mauricio
and Juurlink, Ben",
editor="Wong, Stephan
and Beck, Antonio Carlos
and Bertels, Koen
and Carro, Luigi",
title="A Quantitative Analysis of the Memory Architecture of FPGA-SoCs",
booktitle="Applied Reconfigurable Computing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="241--252",
isbn="978-3-319-56258-2"
}

@INPROCEEDINGS{Skylarov2015,
  author={Sklyarov, Valery and Skliarova, Iouliia and Silva, João and Sudnitson, Alexander},
  booktitle={2015 Euromicro Conference on Digital System Design}, 
  title={Analysis and Comparison of Attainable Hardware Acceleration in All Programmable Systems-on-Chip}, 
  year={2015},
  volume={},
  number={},
  pages={345-352},
  doi={10.1109/DSD.2015.45}}

@article{Kaji2006,
author = {Kaji, Yuichi},
year = {2006},
month = {10},
pages = {},
title = {Encoding LDPC Codes Using the Triangular Factorization},
volume = {E89A},
journal = {IEICE Transactions on Fundamentals of Electronics Communications and Computer Sciences},
doi = {10.1093/ietfec/e89-a.10.2510}
}
@article{Lentaris2018,
author = {Lentaris, George and Maragos, Konstantinos and Stratakos, Ioannis and Papadopoulos, Lazaros and Papanikolaou, Odysseas and Soudris, Dimitrios and Lourakis, Manolis and Zabulis, Xenophon and Gonzalez-Arjona, David and Furano, Gianluca},
title = {High-Performance Embedded Computing in Space: Evaluation of Platforms for Vision-Based Navigation},
journal = {Journal of Aerospace Information Systems},
volume = {15},
number = {4},
pages = {178-192},
year = {2018},
doi = {10.2514/1.I010555},
eprint = { 
        https://doi.org/10.2514/1.I010555
}}
@manual{CCSDS141,
title = {{1064 nm Optical High Data Rate (HDR) Communication}},
howpublished  = {CCSDS Experimental Specification 141.11-O-1},
month = dec,
url={https://public.ccsds.org/Pubs/141x11o1e2.pdf},
year = {2018},
institution={CCSDS}
}

@manual{CCSDS142,
title = {{Optical Communications Coding and Communications Coding and Synchronization}},
howpublished = {CCSDS Recommended Standard 142.0-B-1},
month = aug,
year = {2019},
url = {https://public.ccsds.org/Pubs/142x0b1.pdf},
institution={CCSDS}
}

@techreport{CCSDS130,
title = {{Overview of Space Communication Protocols}},
howpublished = {Informational Report},
type = {130.0-G.3},
month = jul,
year = {2014},
volume = {2014},
url = {https://public.ccsds.org/Pubs/130x0g3.pdf},
institution={CCSDS}
}

@manual{CCSDS131,
title = {{Erasure Correcting Codes for Use in Near-Earth and Deep Space Communications}},
howpublished = {CCSDS Experimental Specification 131.5-O-1},
month = nov,
year = {2014},
url = {https://public.ccsds.org/Pubs/142x0b1.pdf},
institution={CCSDS}
}




@manual{JTC2014,
title = {{Digital Video Broadcasting (DVB)\;Second generation framing structure, channel coding and modulation systems for Broadcasting, Interactive Services, News Gathering and other broadband satellite applications\; Part 1: DVB-S2}},
howpublished  = {ETSI EN 302 307-1 V1.4.1}},
url={https://www.etsi.org/deliver/etsi_en/302300_302399/30230701/01.04.01_60/en_30230701v010401p.pdf},
year = {2014},
institution={ETSI}
}

@manual{ECSS,
title = {{SpaceFibre – Very high-speed serial link}},
howpublished = {ECSS-E-ST-50-11C},
url = {https://ecss.nl/standard/ecss-e-st-50-11c-spacefibre-very-high-speed-serial-link/},
year = {2019},
month = {may},
institution={ECSS}
}
@manual{ion,
title = {{Interplanetary Overlay Network (ION) software distribution (4.0.2)}},
url = {https://sourceforge.net/projects/ion-dtn/},
urldate = {2020-12-21}
}

@manual{Vunit21,
institution = {Asplund, Lars},
title = {{VUnit: a test framework for HDL v.4.4.0}},
url = {https://vunit.github.io/},
year = {2020}
}


@manual{leon3,
howpublished = {Cobham Gaisler},
title = {{LEON3 processor}},
url = {https://www.gaisler.com/index.php/products/processors/leon3},
urldate = {2021-04-12}
}
@manual{leon5,
howpublished = {Cobham Gaisler},
title = {{LEON5 processor}},
url = {https://www.gaisler.com/index.php/products/processors/leon5},
urldate = {2021-04-12}
}
@manual{grlib,
howpublished = {Cobham Gaisler},
title = {{GRLIB IP library processor}},
url = {https://www.gaisler.com/index.php/products/ipcores/soclibrary},
urldate = {2021-04-12}
}
@manual{noelv,
howpublished = {Cobham Gaisler},
title = {{NOEL-V Processor}},
url = {https://www.gaisler.com/index.php/products/processors/noel-v},
urldate = {2021-06-26}
}
@inproceedings{Hund2010,
abstract = {Especially for synchronization-critical wireless networks like ultrawideband impulse radio (UWB-IR), data packets are lost not only due to single bit errors in the payload but also to a large degree because of synchronization errors or preamble failures. Current FEC codes only address bit errors inside a packet. Packets that are lost because of errors in preambles or headers can only be recovered on packet level. In this Paper we propose a low-complexity adaptive packet-level FEC and prove by simulation that it can reduce packet loss with very small overhead. {\textcopyright} 2010 IEEE.},
author = {Hund, Johannes and Heinrich, Andreas and Ziller, Andreas and Schwingenschl{\"{o}}gl, Christian and Kraemer, Rolf},
booktitle = {Proc. 2010 7th Work. Positioning, Navig. Commun. WPNC'10},
doi = {10.1109/WPNC.2010.5653666},
isbn = {9781424471577},
keywords = {Erasure coding,FEC,IEEE 802.15.4a,UWB},
pages = {1--3},
title = {{A packet-level adaptive forward error correction scheme for wireless networks}},
year = {2010}
}
@techreport{Roca2006a,
author = {Roca, Vincent and Neumann, Christoph},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roca, Neumann - 2006 - Design, Evaluation and Comparison of Four Large Block FEC Codecs, LDPC, LDGM, LDGM Staircase and LDGM Triangle, p.pdf:pdf},
title = {{Design, Evaluation and Comparison of Four Large Block FEC Codecs, LDPC, LDGM, LDGM Staircase and LDGM Triangle, plus a Reed-Solomon Small Block FEC Codec}},
url = {https://hal.inria.fr/inria-00070770},
year = {2006}
}



@misc{openFec,
title = {{OpenFEC.org project}},
url = {http://openfec.org/},
urldate = {2021-04-11}
}

@inproceedings{Edwards2019,
author = {Edwards, Bernard L. and Daddato, Robert and Schulz, Klaus Juergen and Alliss, Randall and Hamkins, Jon and Giggenbach, DIrk and Robinson, Bryan and Braatz, Lena},
booktitle = {2019 IEEE Int. Conf. Sp. Opt. Syst. Appl. ICSOS 2019},
doi = {10.1109/ICSOS45490.2019.8978979},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Edwards et al. - 2019 - An Update on the CCSDS Optical Communications Working Group Interoperability Standards.pdf:pdf},
isbn = {9781728105000},
month = {oct},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{An Update on the CCSDS Optical Communications Working Group Interoperability Standards}},
year = {2019}
}
@inproceedings{Ostovari2015,
  author={P. {Ostovari} and J. {Wu}},
  booktitle={2015 IEEE 12th Int. Conf. on Mobile Ad Hoc and Sensor Syst.}, 
  title={Reliable Broadcast with Joint Forward Error Correction and Erasure Codes in Wireless Communication Networks}, 
  year={2015},
  volume={},
  number={},
  pages={324-332},
  doi={10.1109/MASS.2015.68}}
}

@article{Dimitrov2016,
abstract = {In this paper, a packet-level forward error correction coding technique and pre-distortion adaptive optics technology are applied to a digital transmission scheme for optical feeder links in a geostationary Earth orbit satellite communication system. The architectures of the gateway and the satellite are defined, including the building blocks of the interface between the radio frequency front-end and the optical front-end, as well as the digital signal processor. The system is designed to cater for Terabit/s high-throughput satellite applications. The performance of the digital transmission scheme is evaluated in the forward and return links. The turbulent atmospheric optical channel is modeled for different optical ground station altitudes. It is shown that fade mitigation techniques such as packet-level forward error correction coding and pre-distortion adaptive optics in the forward link, as well as large-aperture optical ground station telescope in the return link, are essential to close the link budget of a Terabit/s satellite communication system. Copyright {\textcopyright} 2015 John Wiley {\&} Sons, Ltd.},
author = {Dimitrov, Svilen and Barrios, Ricardo and Matuz, Balazs and Liva, Gianluigi and Mata-Calvo, Ramon and Giggenbach, Dirk},
doi = {10.1002/sat.1163},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dimitrov et al. - 2016 - Digital modulation and coding for satellite optical feeder links with pre-distortion adaptive optics.pdf:pdf},
issn = {15420973},
journal = {Int. J. Satell. Commun. Netw.},
keywords = {Terabit/s satellite communication,correlated fading,digital modulation,optical feeder link,packet-level coding,pre-distortion adaptive optics,scintillation,turbulent optical channel},
month = {sep},
number = {5},
pages = {625--644},
publisher = {John Wiley and Sons Ltd},
title = {{Digital modulation and coding for satellite optical feeder links with pre-distortion adaptive optics}},
url = {http://doi.wiley.com/10.1002/sat.1163},
volume = {34},
year = {2016}
}


@incollection{DeCola2008,
author = {{De Cola}, Tomaso and Ernst, Harald and Marchese, Mario},
doi = {10.1007/978-0-387-47524-0_49},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Cola, Ernst, Marchese - 2008 - Application of Long Erasure Codes and ARQ Schemes for Achieving High Data Transfer Performance Over Lo.pdf:pdf},
pages = {643--656},
title = {{Application of Long Erasure Codes and ARQ Schemes for Achieving High Data Transfer Performance Over Long Delay Networks}},
url = {http://link.springer.com/10.1007/978-0-387-47524-0{\_}49},
year = {2008}
}
@article{Liva2013a,
abstract = {In many applications erasure correcting codes are used to recover packet losses at high protocol stack layers. The objects (e.g. files) to be transmitted often have variable sizes, resulting in a variable number of packets to be encoded by the packet-level encoder. In this paper, algorithms for the (on-line) flexible design of parity-check matrices for irregular-repeat-accumulate codes are investigated. The proposed algorithms allow designing in fast manner parity-check matrices that are suitable for low-complexity maximum-likelihood decoding. The code ensembles generated by the algorithms are analyzed via extrinsic information transfer charts. Numerical results show how the designed codes can attain codeword error rates as low as 10{\^{}}{\{}-5{\}} without appreciable losses w.r.t. the performance of idealized maximum-distance separable codes. Finally, we apply the proposed codes to the upcoming aeronautical communication standard, showing large performance improvements and proving the efficiency and the flexibility of the developed method. {\textcopyright} 2013 IEEE.},
author = {Liva, Gianluigi and Pulini, Paola and Chiani, Marco},
doi = {10.1109/TWC.2012.121412120053},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liva, Pulini, Chiani - 2013 - On-line construction of irregular repeat accumulate codes for packet erasure channels.pdf:pdf},
issn = {15361276},
journal = {IEEE Trans. Wirel. Commun.},
keywords = {Fountain codes,aeronautical communications,erasure channel,low-density parity-check codes,reliable multicast},
number = {2},
pages = {680--689},
title = {{On-line construction of irregular repeat accumulate codes for packet erasure channels}},
volume = {12},
year = {2013}
}
@article{Luby2001,
abstract = {We introduce a simple erasure recovery algorithm for codes derived from cascades of sparse bipartite graphs and analyze the algorithm by analyzing a corresponding discrete-time random process. As a result, we obtain a simple criterion involving the fractions of nodes of different degrees on both sides of the graph which is necessary and sufficient for the decoding process to finish successfully with high probability. By carefully designing these graphs we can construct for any given rate R and any given real number $\epsilon$ a family of linear codes of rate R which can be encoded in time proportional to ln(1/$\epsilon$) times their block length n. Furthermore, a codeword can be recovered with high probability from a portion of its entries of length (1 + $\epsilon$) Rn or more. The recovery algorithm also runs in time proportional to n ln(1/$\epsilon$). Our algorithms have been implemented and work well in practice; various implementation issues are discussed.},
annote = {They propose a acscade parity bits structure. Experiment with packet level code 640k packets 256 bytes each, rate 1/2},
author = {Luby, Michael G. and Mitzenmacher, Michael and Shokrollahi, M. Amin and Spielman, Daniel A.},
doi = {10.1109/18.910575},
file = {:home/mitsor/di/erasure/decoding only/luby2001.pdf:pdf},
issn = {00189448},
journal = {IEEE Trans. Inf. Theory},
keywords = {Erasure channel,Large deviation analysis,Low-density parity-check codes},
number = {2},
pages = {569--584},
title = {{Efficient erasure correcting codes}},
volume = {47},
year = {2001}
}
@article{Paolini2012,
author = {Paolini, Enrico and Liva, Gianluigi and Matuz, Balazs and Chiani, Marco},
doi = {10.1109/TCOMM.2012.081012.110363},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paolini et al. - 2012 - Maximum Likelihood Erasure Decoding of LDPC Codes Pivoting Algorithms and Code Design.pdf:pdf},
issn = {0090-6778},
journal = {IEEE Trans. Commun.},
month = {nov},
number = {11},
pages = {3209--3220},
title = {{Maximum Likelihood Erasure Decoding of LDPC Codes: Pivoting Algorithms and Code Design}},
url = {http://ieeexplore.ieee.org/document/6266770/},
volume = {60},
year = {2012}
}
@inproceedings{Hisamatsu2010,
abstract = {Packet-level erasure correction is considered for downstream packets each of which is delivered from a base station to an individual receiver (i.e., user) over a lossy shared wireless network where only a very limited upstream feedback is provided. Note that, while the destination of each packet is a single user, each packet can be overheard by all users in the shared network. With exploiting this overhearing property of wireless links, we focus on packet recovery by exclusive-OR (XOR) packet composition-based forward-erasure- correction (FEC). For network applications with packet-loss tolerance and delay-time limitation, our goal is to increase the effective packet received rate (the ratio of finally received/recovered packets after applying FEC) of each user with fairness in a low-cost manner. We propose a simple XOR packet composition scheme that can approximately maximize the minimum effective packet received rate among users, based on an experimentally suggested linear relation between the packet loss rates and the optimal packet composition ratios among users. Simulation results clearly indicate the potential effectiveness of the proposal. {\textcopyright}2010 IEEE.},
author = {Hisamatsu, Satoshi and Tamura, Hitomi and Tsuru, Masato and Oie, Yuji},
booktitle = {IEEE Int. Symp. Pers. Indoor Mob. Radio Commun. PIMRC},
doi = {10.1109/PIMRCW.2010.5670506},
isbn = {9781424491162},
keywords = {FEC/FZC (Forward Erasure Correction),Lossy wireless network,Packet composition,Packet recovery},
pages = {496--501},
title = {{Packet-level forward erasure correction with user fairness in lossy wireless networks}},
year = {2010}
}
@article{Adhikary2020,
abstract = {To maximize file transfer from deep-space vehicles, a space-to-earth content-transfer protocol that combines turbo codes, RaptorQ codes, real-time channel prediction, and dynamic code-rate selection is proposed. The protocol features a signal-to-noise ratio prediction model that facilitates the periodic adjustment of turbo encoder to achieve adaptive-rate transmission, and fountain codes to eliminate retransmission of specific packets. Simulation results indicate that an increase of about 132{\%} in file transfer rate is achievable compared to fixed-rate transmission scheme.},
author = {Adhikary, Rojina and Daigle, John N. and Cao, Lei},
doi = {10.1109/TAES.2019.2921212},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adhikary, Daigle, Cao - 2020 - Dynamic Code Selection Method for Content Transfer in Deep-Space Network.pdf:pdf},
issn = {15579603},
journal = {IEEE Trans. Aerosp. Electron. Syst.},
keywords = {Channel prediction,RaptorQ codes,deep-space communications,dynamic code selection method (DCSM),turbo codes},
month = {feb},
number = {1},
pages = {456--474},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Dynamic Code Selection Method for Content Transfer in Deep-Space Network}},
volume = {56},
year = {2020}
}
@inproceedings{Mattoussi2015,
abstract = {Content broadcasting over wireless networks heavily relies on Application-Level FEC codes to improve transmission robustness in front of channel erasures. Because they operate in the higher layers of the protocol stack, they benefit from a lot of flexibility. In particular, since streaming applications and bulk transfer applications have different constraints, different packet scheduling strategies may be used by the sender, offering different trade-offs between decoding latency and long erasure burst protection. This work tries to find the best packet scheduling scheme(s) at a sender for a given type of AL-FEC codes. The contributions are twofold: first we define a methodology to measure the impacts of packet scheduling on AL-FEC performance, both under ITerative (IT) and Maximum Likelihood (ML) decoding, for a large set of channels; then we apply this methodology to GLDPC-Staircase codes, an extension of LDPC-Staircase codes using Reed Solomon codes as inner codes. In previous works we showed that these codes have erasure recovery performance close to ideals codes when packets are transmitted in a random order. In this work we show that these codes perform extremely well when sending source packets sequentially first (a key requirement to keep latency minimum with streaming applications) and then extra-repair packets followed by LDPC repair packets, both in a random order.},
author = {Mattoussi, Ferdaouss and Roca, Vincent and Sayadi, Bessem},
booktitle = {2015 Eur. Conf. Networks Commun. EuCNC 2015},
doi = {10.1109/EuCNC.2015.7194119},
isbn = {9781467373593},
month = {aug},
pages = {465--470},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Impacts of the packet scheduling on the performance of erasure codes: Methodology and application to GLDPC-Staircase codes}},
year = {2015}
}
@article{Davarian2020a,
author = {Davarian, Faramaz and Asmar, Sami and Angert, Matt and Baker, John and Gao, Jay and Hodges, Richard and Israel, David and Landau, Damon and Lay, Norman and Torgerson, Leigh and Walsh, William},
doi = {10.1109/MAES.2020.2975260},
issn = {1557959X},
journal = {IEEE Aerosp. Electron. Syst. Mag.},
month = {jul},
number = {7},
pages = {26--40},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Improving Small Satellite Communications and Tracking in Deep Space - A Review of the Existing Systems and Technologies with Recommendations for Improvement. Part II: Small Satellite Navigation, Proximity Links, and Communications Link Science}},
volume = {35},
year = {2020}
}
@inproceedings{Geethu2015,
abstract = {This paper investigates the performance of two popular packet level erasure coding approaches, i.e., end-to-end and hop-by-hop, for improving the data transmission reliability in Underwater Acoustic Sensor Networks (UWASNs). In the end-to-end approach, encoding and decoding are performed by the source node and sink node, respectively, while the intermediate nodes just forward the data packets without any processing. In this case, the number of redundant packets to be transmitted by the source (i.e., code rate) is chosen based on packet success probability along the path. On the other hand, the hop-by-hop erasure coding is used to achieve reliability over each hop along the path. In this case, apart from the source node, all the intermediate nodes perform the encoding process and each node adaptively computes the number of redundant packets for the next hop based on the quality of the corresponding hop. We present an analytical model to find the communication overhead, energy consumption and average delay of the multi-hop UWASN under the above erasure coding approaches. The results show that hop-by-hop erasure coding outperforms end-to-end erasure coding.},
author = {Geethu, K. S. and Babu, A. V.},
booktitle = {2015 Int. Conf. Adv. Comput. Commun. Informatics, ICACCI 2015},
doi = {10.1109/ICACCI.2015.7275934},
isbn = {9781479987917},
keywords = {erasure codes,reliable data transfer,underwater acoustic sensor networks},
month = {sep},
pages = {2145--2151},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Performance analysis of erasure coding based data transfer in Underwater Acoustic Sensor Networks}},
year = {2015}
}
@article{Cheour2019,
author = {Cheour, Rym and Khriji, Sabrine and Houssaini, Dhouha El and Baklouti, Mouna and Abid, Mohamed and Kanoun, Olfa},
doi = {10.1109/MAES.2019.2901134},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheour et al. - 2019 - Recent Trends of FPGA Used for Low-Power Wireless Sensor Network.pdf:pdf},
issn = {1557959X},
journal = {IEEE Aerosp. Electron. Syst. Mag.},
month = {oct},
number = {10},
pages = {28--38},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Recent Trends of FPGA Used for Low-Power Wireless Sensor Network}},
volume = {34},
year = {2019}
}
@techreport{Chiani2007,
annote = {Interesting EXAMPLE PROFILES for block lengths and data rates.
Decoding demystified (somewhat)},
author = {Chiani, Marco and Paolini, Enrico},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chiani, Paolini - 2007 - Long Erasure Codes for CCSDS Applications Authors.pdf:pdf},
title = {{Long Erasure Codes for CCSDS Applications Authors}},
url = {https://pdfs.semanticscholar.org/6100/8d83881d98a81a49b94e6ac5da9e1fa46317.pdf},
year = {2007}
}
@inproceedings{Garrammone2012,
abstract = {The use of erasure codes in space communications has proved to be promising in order to make communication more robust against both independent and correlated data losses. In particular, erasure codes are an appealing solution to provide space communications with increased reliability, especially in scenarios where large latencies make the use of automatic repeat request (ARQ) strategies problematic. In this regard, preliminary studies on the use of binary low-density parity-check (LDPC) codes under maximum likelihood (ML)/iterative (IT) decoding have been carried out showing the performance benefit they can bring over traditional schemes based on retransmissions. This paper extends the analysis conducted in previous studies towards non-binary LDPC codes. Performance assessment is carried out with respect to reliability metrics (codeword error rate) and encoding/decoding complexity, taking into consideration the limitations of space communications in terms of storage and processing capabilities. Finally, the paper sketches some design guidelines on the integration of the proposed codes into the Consultative Committee for Space Data Systems (CCSDS) protocol stack, implemented as extension of the Licklider Transmission Protocol (LTP). {\textcopyright} 2012 IEEE.},
author = {Garrammone, Giuliano and {De Cola}, Tomaso and Matuz, Balazs and Liva, Gianluigi},
booktitle = {2012 6th Adv. Satell. Multimed. Syst. Conf. ASMS 2012 12th Signal Process. Sp. Commun. Work. SPSC 2012},
doi = {10.1109/ASMS-SPSC.2012.6333092},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garrammone et al. - 2012 - Erasure codes for space communications Recent findings and new challenges.pdf:pdf},
isbn = {9781467326766},
pages = {29--35},
title = {{Erasure codes for space communications: Recent findings and new challenges}},
year = {2012}
}
@article{Paolini2006,
abstract = {In space communications, traditional error correction/detection techniques deliver to the upper layers of the communication stack only the data units for which integrity can be guaranteed. The uncorrectable data units are then "lost", and the upper layers have typically to face data units erasures. Hence, the packet erasure channel (PEC) is the most proper channel model from the point of view of the upper layers. Automatic re-peat/retransmission query (ARQ) is the "traditional" solution implemented at the upper layers in order to face data units erasures. However, ARQ is not always possible for space or satellite communications. In such situations, forward error correction (FEC) must be used. Nowadays new techniques for FEC are available also for application at the upper layers. Long erasure correcting (LEC) codes represent a new and very promising proposal for packet erasure FEC. They are able to overcome the complexity limitations of other types of codes, while preserving very good erasure correction capability. They are currently under investigation within the CCSDS (Consultative Committee for Space Data Systems) long erasure codes Bird of Feather (LEC-BOF), where a leading role has been so far played by ESA/ESOC and NASA-JPL. In this paper, the activity of the LEC-BOF is be illustrated. More in detail, the basic ideas behind LEC codes are presented, as well as the possible codes structures, the encoding and decoding rules, some theoretical properties. Some numerical results are presented, showing the performance of LEC codes on both memory-less and burst erasure channel.},
author = {Paolini, Enrico and Chiani, Marco and Calzolari, Gian Paolo},
doi = {10.2514/6.2006-5827},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paolini, Chiani, Calzolari - 2006 - Long Erasure Correcting Codes the New Frontier for Zero Loss in Space Applications.pdf:pdf},
title = {{Long Erasure Correcting Codes: the New Frontier for Zero Loss in Space Applications?}},
url = {http://arc.aiaa.org},
year = {2006}
}
@article{Han2005,
abstract = {In this paper, we introduce packet low-density parity-check (packet-LDPC) codes for high-density tape storage systems. We report on the performance of two error control code (ECC) architectures based on the packet-LDPC codes. The architectures are designed to be (approximately) compatible with the widely used ECMA-319 ECC standard based on two interleaved concatenated 8-bit Reed-Solomon (RS) codes. One architecture employs an inner RS code; the other employs an inner turbo product code with single parity-check constituent codes (TPC-SPC). Both employ a packet-LDPC code as the outer code. As for the ECMA-319 system, both schemes are required to correct noise bursts due to media defects and synchronization loss, as well as the loss of one of eight tracks (due to a head clog, for example). We show that the first packet-LDPC code architecture substantially outperforms the ECMA-319 scheme and is only a few tenths of a decibel inferior to a long, highly complex 12-bit RS scheme. The second architecture outperforms both the ECMA-319 and the long RS code scheme. {\textcopyright} 2005 IEEE.},
author = {Han, Yang and Ryan, William E.},
doi = {10.1109/TMAG.2005.844834},
issn = {00189464},
journal = {IEEE Trans. Magn.},
keywords = {Error control code (ECC),Low-density parity-check (LDPC),Packet-LDPC,Tape recording},
month = {apr},
number = {4},
pages = {1340--1347},
title = {{Packet-LDPC codes for tape drives}},
volume = {41},
year = {2005}
}
@article{Davarian2020,
annote = {Good intro to optical communications deep space and cubesat},
author = {Davarian, Faramaz and Babuscia, Alessandra and Baker, John and Hodges, Richard and Landau, Damon and Lau, Chi-wung and Lay, Norman and Angert, Matt and Kuroda, Vanessa},
doi = {10.1109/MAES.2020.2980918},
issn = {0885-8985},
journal = {IEEE Aerosp. Electron. Syst. Mag.},
month = {jul},
number = {7},
pages = {8--25},
title = {{Improving Small Satellite Communications in Deep Space—A Review of the Existing Systems and Technologies With Recommendations for Improvement. Part I: Direct to Earth Links and SmallSat Telecommunications Equipment}},
volume = {35},
year = {2020}
}
@article{Reed1960,
abstract = {This paper presents a survey of coding theory for statisticians and mathematicians who have some familiarity with modern algebra, finite fields and possibly some acquaintance with block designs. No knowledge of stochastic processes, information theory or ...},
author = {Reed, I. S. and Solomon, G.},
doi = {10.1137/0108018},
issn = {0368-4245},
journal = {J. Soc. Ind. Appl. Math.},
month = {jun},
number = {2},
pages = {300--304},
publisher = {Society for Industrial {\&} Applied Mathematics (SIAM)},
title = {{Polynomial Codes Over Certain Finite Fields}},
volume = {8},
year = {1960}
}
@article{Liang2020,
abstract = {Emerging computing paradigm edge computing expects to store and process data at the network edge with reduced latency and improved network bandwidth. To the best of our knowledge, key performance issues such as coding performance of erasure-coded storage systems haven't been investigated for edge computing. In this paper, we present an erasure-coded storage system for edge computing. Unlike the data center and cloud storage systems, it employs edge devices to perform encoding and decoding operations, which can be a performance bottleneck of the whole storage system due to limited computing power. Hence, we present a comprehensive study of the performance of erasure coding to see if it can match the network performance of 5G and Wi-Fi 6 at the network edge. We use the popular edge device Jetson Nano and two state-of-the-art coding libraries: Jerasure and G-CRS. Our evaluation results reveal unsatisfied performance for Jerasure and high variance for G-CRS. To obtain better and stable performance, we accelerate erasure code with OpenMP on a multi-core CPU. Our work demonstrates our acceleration can bring stable performance and match the network bandwidth of 5G and Wi-Fi 6 for some commonly used cases. Besides, our work offers a better understanding of erasure-coded storage systems for edge computing and can be served as a reference to any further optimization for such kind of systems at the network edge.},
author = {Liang, Lixin and He, Huan and Zhao, Jian and Liu, Chengjian and Luo, Qiuming and Chu, Xiaowen},
doi = {10.1109/ACCESS.2020.2995973},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang et al. - 2020 - An erasure-coded storage system for edge computing.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Erasure-coded storage system,edge computing,erasure coding,jetson nano},
pages = {96271--96283},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{An erasure-coded storage system for edge computing}},
volume = {8},
year = {2020}
}
@article{Berger2008,
abstract = {To achieve reliable packet transmission over a wireless link without feedback, we propose a layered coding approach that uses error-correction coding within each packet and erasure-correction coding across the packets. This layered approach is also applicable to an end-to-end data transport over a network where a wireless link is the performance bottleneck. We investigate how to optimally combine the strengths of error- and erasure-correction coding to optimize the system performance with a given resource constraint, or to maximize the resource utilization efficiency subject to a prescribed performance. Our results determine the optimum tradeoff in splitting redundancy between error-correction coding and erasure-correction codes, which depends on the fading statistics and the average signal to noise ratio (SNR) of the wireless channel. For severe fading channels, such as Rayleigh fading channels, the tradeoff leans towards more redundancy on erasure-correction coding across packets, and less so on error-correction coding within each packet. For channels with better fading conditions, more redundancy can be spent on error-correction coding. The analysis has been extended to a limiting case with a large number of packets, and a scenario where only discrete rates are available via a finite number of transmission modes. {\textcopyright} 2008 IEEE.},
author = {Berger, Christian R. and Zhou, Shengli and Wen, Yonggang and Willett, Peter and Pattipati, Krishna},
doi = {10.1109/T-WC.2008.070581},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berger et al. - 2008 - Optimizing joint erasure- and error-correction coding for wireless packet transmissions.pdf:pdf},
issn = {15361276},
journal = {IEEE Trans. Wirel. Commun.},
keywords = {Adaptive modulation and coding,Fountain codes,Inter- and intra-packet coding,Layered coding,Reliable transmission},
month = {nov},
number = {11},
pages = {4586--4595},
title = {{Optimizing joint erasure- and error-correction coding for wireless packet transmissions}},
volume = {7},
year = {2008}
}
@article{Burshtein2004a,
abstract = {We propose an efficient maximum-likelihood (ML) decoding algorithm for decoding low-density parity-check (LDPC) codes over the binary-erasure channel (BEC). We also analyze the computational complexity of the proposed algorithm. {\textcopyright} 2004 IEEE.},
author = {Burshtein, David and Miller, Gadi},
doi = {10.1109/TIT.2004.836694},
file = {:home/mitsor/di/erasure/Academic/Burshtein-Miller Efficient ML Decoding.pdf:pdf},
issn = {00189448},
journal = {IEEE Trans. Inf. Theory},
month = {nov},
number = {11},
pages = {2837--2844},
title = {{An efficient maximum-likelihood decoding of LDPC codes over the binary erasure channel}},
volume = {50},
year = {2004}
}

@article{Alessi2020,
abstract = {Interplanetary networks are affected by long propagation delays, intermittent connectivity, possible packet losses due to residual errors, and other impairments. To cope with these challenges, the delay-/disruption-tolerant networking (DTN) architecture utilizes the Licklider transmission protocol (LTP) as convergence layer on space links. The LTP reliable service (red) relies on Automatic Repeat reQuest, but very long propagation delays make packet layer forward error correcting (PL-FEC) codes very appealing to protect LTP segments from losses. The key advantage of FEC is that LTP retransmissions would be limited to the unlikely case of decoding failures. To this end, a new FEC-based protocol, to be inserted immediately below LTP, the erasure coding link service adapter (ECLSA), is presented here. ECLSA is completely transparent to LTP, relies on two alternative external libraries for coding/decoding, LibecDLR and OpenFEC, both using low density parity check codes and it is fully integrated with the ION DTN software package of NASA-JPL. This paper aims to provide a solid description of ECLSA, including features functional in a real deployment (such as the dynamic selection of codes). Performance is evaluated at the end of the paper, with nearly ideal results. ECLSA is released as free software and is already included in the 'contrib' section of ION.},
annote = {RFC5170 are random codes (random different columns). We cannot use Fvn module for incidence calculations
ML (gaussian elim.) vs IT (trivial) decoding algorithm. We can use hybrid (start with IT and continue with ML)
Very important is Fig.13},
author = {Alessi, Nicola and Caini, Carlo and {De Cola}, Tomaso and Raminella, Marco},
doi = {10.1109/TAES.2019.2916271},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alessi et al. - 2020 - Packet Layer Erasure Coding in Interplanetary Links The LTP Erasure Coding Link Service Adapter.pdf:pdf},
issn = {15579603},
journal = {IEEE Trans. Aerosp. Electron. Syst.},
keywords = {Delay-/disruption-tolerant networking (DTN),InterPlanetary Networking (IPN),Licklider transmission protocol (LTP),low density parity check (LDPC) codes,upper layer forward error correcting (FEC)},
month = {feb},
number = {1},
pages = {403--414},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Packet Layer Erasure Coding in Interplanetary Links: The LTP Erasure Coding Link Service Adapter}},
volume = {56},
year = {2020}
}
@article{DeCola2010,
abstract = {Achieving reliable communications in deep space environments poses formidable networking challenges because of the extreme physical medium peculiarities. In this view, two possible approaches can be considered to carry out reliable data transfers over deep space channels: automatic repeat request schemes and packet layer coding algorithms applied with long erasure codes. In this respect, this article surveys the mechanisms currently available from the Consultative Committee for Space Data Systems protocol stack, by reserving special attention, on one hand, to the ARQ schemes currently implemented at the application layer and, on the other hand, to the potential offered by erasure coding schemes. A comparative analysis gives some insights about the performance improvements the packet layer coding methodology can bring. In particular, the results show that the use of erasure coding is able to attain more satisfactory performance results than ARQ-based schemes in terms of reliability, data transfer delay, resource network utilization, and power consumption. {\textcopyright} 2010 IEEE.},
author = {{De Cola}, Tomaso and Marchese, Mario},
doi = {10.1109/MWC.2010.5450661},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Cola, Marchese - 2010 - Reliable data delivery over deep space networks Benefits of long erasure codes over arq strategies.pdf:pdf},
issn = {15361284},
journal = {IEEE Wirel. Commun.},
month = {apr},
number = {2},
pages = {57--65},
title = {{Reliable data delivery over deep space networks: Benefits of long erasure codes over arq strategies}},
volume = {17},
year = {2010}
}
@article{GuilleniFabregas2006,
abstract = {In this correspondence, we study an M-ary block-erasure channel with B blocks, where with probability $\epsilon$ a block of L coded symbols is erased. The behavior of the error probability of coded systems over such channels is studied, and we show that, if the code is diversity-wise maximum-distance separable, its word error probability is equal to the outage probability, which admits a very simple expression. This correspondence is intended to complement the error probability analysis in previous work by Lapidoth and shed some light on the design of coding schemes for nonergodic channels. {\textcopyright} 2006 IEEE.},
author = {{Guill{\'{e}}n i F{\`{a}}bregas}, Albert},
doi = {10.1109/TIT.2006.883556},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guill{\'{e}}n i F{\`{a}}bregas - 2006 - Coding in the block-erasure channel.pdf:pdf},
issn = {00189448},
journal = {IEEE Trans. Inf. Theory},
keywords = {Diversity,Erasure channels,Error probability,Maximum-distance separable (MDS) codes,Maximum-likelihood (ML) decoding,Non-ergodic channels,Outage probability},
month = {nov},
number = {11},
pages = {5116--5121},
title = {{Coding in the block-erasure channel}},
volume = {52},
year = {2006}
}
@article{Tang2020,
abstract = {Recently, a new polynomial basis over finite fields was proposed such that the computational complexity of the fast Fourier transform (FFT) is O(n$\backslash$log n). Based on FFTs, the encoding and decoding algorithms for Reed-Solomon (RS) codes were proposed, which are shown to have the lowest computational complexity in the literature. However, these algorithms require that the code length and the number of parity symbols must be power of two. In this letter, we present the encoding and decoding algorithms for arbitrary RS codes based on FFTs. Furthermore, these new algorithms also reach the best known complexity bound.},
author = {Tang, Nianqi and Lin, Yun},
doi = {10.1109/LCOMM.2020.2965453},
issn = {15582558},
journal = {IEEE Commun. Lett.},
keywords = {Decoding algorithm,Fast fourier transform,Reed-solomon codes},
month = {apr},
number = {4},
pages = {716--719},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Fast Encoding and Decoding Algorithms for Arbitrary F2m}},
volume = {24},
year = {2020}
}

@article{Mattoussi2019,
abstract = {Hybrid broadcast broadband TV is a technique providing Push-VoD services over an interactive hybrid TV. These services are broadcast using a file delivery protocol (FDP), which includes different coding strategies to ensure reliable delivery. This protocol is characterized by three levels of data representation giving rise to segmentation of packet losses, which may result in poor recovery capabilities. This paper provides a first thorough investigation of the coding FDP framework for reliable delivery of Push-VoD service over DVB networks. We propose Markov modeling for characterizing inter-layer loss propagation within FDP on a wide variety of burst erasure channels. Based on this analytical analysis and a simulation study, we determine the possible recovering areas and the accurate loss measurements within FDP. The latter is then used to effectively investigate and configure the different coding strategies provided within FDP. In addition, we present a suitable recovering strategy for FDP, which guarantees transmission robustness against the broadcast network impairments.},
author = {Mattoussi, Ferdaouss and Crussiere, Matthieu and Helard, Jean Francois and Zaharia, Gheorghe},
doi = {10.1109/ACCESS.2019.2893756},
issn = {21693536},
journal = {IEEE Access},
keywords = {AL-FEC,DVB,HbbTV,Markov chain,Push-VoD services,repetition code},
pages = {15489--15508},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Analysis of Coding Strategies Within File Delivery Protocol Framework for HbbTV Based Push-VoD Services over DVB Networks}},
volume = {7},
year = {2019}
}
@article{Tsigkanos2020,
abstract = {Nowadays, hyperspectral imaging is recognized as a cornerstone remote sensing technology. Next generation, high-speed airborne, and space-borne imagers have increased resolution, resulting in an explosive growth in data volume and instrument data rate in the range of gigapixel per second. This competes with limited on-board resources and bandwidth, making hyperspectral image compression a mission critical on-board processing task. At the same time, the 'new space' trend is emerging, where launch costs decrease, and agile approaches are exploited building smallsats using commercial-off-the-shelf (COTS) parts. In this contribution, we introduce a high-performance parallel implementation of the CCSDS-123.0-B-1 hyperspectral compression algorithm targeting SRAM field-programmable gate array (FPGA) technology. The architecture exploits image segmentation to provide the robustness to data corruption and enables scalable throughput performance by leveraging segment-level parallelism. Furthermore, we exploit the capabilities of a COTS FPGA system-on-chip (SoC) device to optimize size, weight, power, and cost (SWaP-C). The architecture partitions a hyperspectral cube stored in a DRAM framebuffer into segments, compressing them in parallel using a flexible software scheduler hosted in the SoC CPU and several compressor accelerator cores in the FPGA fabric. A 5-core implementation demonstrated on a Zynq-7045 FPGA achieves a throughput performance of 1387 Msamples/s [22.2 Gb/s at 16 bits per pixel per band (bpppb)] and outperforms previous implementations in equivalent FPGA technology, allowing seamless integration with next-generation hyperspectral sensors.},
author = {Tsigkanos, Antonis and Kranitis, Nektarios and Theodoropoulos, DImitris and Paschalis, Antonios},
doi = {10.1109/TVLSI.2020.3020164},
issn = {15579999},
journal = {IEEE Trans. Very Large Scale Integr. Syst.},
keywords = {Consultative Committee for Space Data Systems (CCS,field-programmable gate array (FPGA),hyperspectral compression,on-board data processing,system-on-chip (SoC)},
month = {nov},
number = {11},
pages = {2397--2409},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{High-Performance COTS FPGA SoC for Parallel Hyperspectral Image Compression with CCSDS-123.0-B-1}},
volume = {28},
year = {2020}
}


@inproceedings{Schmidt2018,
abstract = {Direct optical downlinks from small LEO spacecraft to Earth have the potential to solve the increasing demands for higher data rates due to increased mission requirements. The Institute of Communications and Navigation of the German Aerospace Center (DLR) has been working since more than 10 years on the development and demonstration of highly compact and lightweight experimental terminals to enable optical communications for small LEO spacecraft. In the framework of the OSIRIS program (Optical Space Infrared Downlink System), the optical communication payload for DLR's BiROS satellite has been developed. Launched in 2016, BiROS and OSIRIS will demonstrate their performance in a measurement campaign in 2017. This paper will give an overview over the program OSIRIS and the development roadmap.},
author = {Schmidt, Christopher and Fuchs, Christian},
booktitle = {2017 IEEE Int. Conf. Sp. Opt. Syst. Appl. ICSOS 2017},
doi = {10.1109/ICSOS.2017.8357205},
isbn = {9781509065110},
keywords = {Free-Space Optics,Optical Communication,Satellite Communication},
month = {may},
pages = {19--22},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{The OSIRIS program - First results and Outlook}},
year = {2018}
}
@article{Courtade2011,
abstract = {For a block-fading channel, this paper optimizes the allocation of redundancy between packet-level erasure coding (which provides additional packets to compensate for packet loss) and physical layer channel coding (which lowers the probability of packet loss). After some manipulation, standard optimization techniques determine the trade-off between the amount of packet-level erasure coding and physical-layer channel coding that minimizes the transmit power required to provide reliable communication. Our results indicate that the optimal combination of packet-level erasure coding and physical-layer coding provides a significant benefit over pure physical-layer coding when no form of channel diversity is present within a packet transmission. However, the benefit of including packet-level erasure coding diminishes as more diversity becomes available within a packet transmission. Even with no diversity within a packet transmission, this paper shows that as the total redundancy becomes large the optimal redundancy for packet-level erasure coding reaches a limit while the optimal redundancy for physical-layer coding continues to increase. Hence providing limitless redundancy at the packet-level with rateless codes such as fountain codes is not the best use of limitless redundancy for block-fading channels. {\textcopyright} 2011 IEEE.},
author = {Courtade, Thomas A. and Wesel, Richard D.},
doi = {10.1109/TCOMM.2011.062311.090277},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Courtade, Wesel - 2011 - Optimal allocation of redundancy between packet-level erasure coding and physical-layer channel coding in fadin.pdf:pdf},
issn = {00906778},
journal = {IEEE Trans. Commun.},
keywords = {Cross-layer coding,Rayleigh fading channels,cross-layer optimization,rateless codes,selection diversity},
month = {aug},
number = {8},
pages = {2101--2109},
title = {{Optimal allocation of redundancy between packet-level erasure coding and physical-layer channel coding in fading channels}},
volume = {59},
year = {2011}
}
@misc{Scott,
author = {Scott, K and Burleigh, S},
title = {{Bundle Protocol Specification}},
url = {https://www.rfc-editor.org/rfc/rfc5050.txt},
urldate = {2020-12-21}
}
@article{Richardson2001,
author = {Richardson, Thomas J and Urbanke, R{\"{u}}diger L},
journal = {IEEE Trans. Inf. Theory},
keywords = {Index Terms-Binary erasure channel,decoding,encoding,parity check,random graphs,sparse matrices,turbo codes},
number = {2},
title = {{Efficient Encoding of Low-Density Parity-Check Codes}},
volume = {47},
year = {2001}
}
@inproceedings{Edwards2019a,
author={B. L. {Edwards} and R. {Daddato} and K. {Schulz} and R. {Alliss} and J. {Hamkins} and D. {Giggenbach} and B. {Robinson} and L. {Braatz}},
  booktitle={2019 IEEE Int. Conf. Space Opt. Syst.Appl. (ICSOS)}, 
  title={An Update on the CCSDS Optical Communications Working Group Interoperability Standards}, 
  year={2019},
  volume={},
  number={},
  pages={1-9},
  month = {oct},
  doi={10.1109/ICSOS45490.2019.8978979}}







@inproceedings{Poulenard2019,
author = {S. Poulenard and B. Gadat and J. F. Chouteau and T. Anfray and C. Poulliat and C. Jego and O. Hartmann and G. Artaud and H. Meric},
title = {{Forward error correcting code for high data rate LEO satellite optical downlinks}},
volume = {11180},
booktitle = {International Conference on Space Optics — ICSO 2018},
editor = {Zoran Sodnik and Nikos Karafolas and Bruno Cugny},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {2029 -- 2038},
year = {2019},
doi = {10.1117/12.2536120}}



@manual{MIL-STD-1750,
title = {{Sixteen-Bit Computer Instruction Set Architecture}},
howpublished = {DoD Military Standard MIL-STD-1750},
month = aug,
year = {1980},
url = {https://quicksearch.dla.mil/qsDocDetails.aspx?ident_number=37110},
institution={Defense Information Systems Agency (DISA)}
}

@article{DiMascio2020,
author = {{Di Mascio}, Stefano and Menicucci, Alessandra and Gill, Eberhard and Furano, Gianluca and Monteleone, Claudio},
doi = {10.2514/1.I010735},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Di Mascio et al. - 2020 - Leveraging the openness and modularity of risc-v in space.pdf:pdf},
issn = {23273097},
journal = {Journal of Aerospace Information Systems},
keywords = {Application Specific Integrated Circuits,Artificial Intelligence,Commercial off the Shelf,Fault Tolerance,General Purpose Computing,Rockets,Satellite Data System,Small Satellites,Space Systems,Technology Readiness Level},
month = {jan},
number = {11},
pages = {454--472},
publisher = {AIAA International},
title = {{Leveraging the openness and modularity of risc-v in space}},
url = {www.aiaa.org/randp.},
volume = {16},
year = {2020}
}
@inproceedings{Anrersson2010,
author = {Andersson, Jan and Gaisler, Jiri and Weigand, Roland},
booktitle = {DAta Systems In Aerospace 2010 (DASIA2010)},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andersson, Gaisler, Weigand - Unknown - NEXT GENERATION MULTIPURPOSE MICROPROCESSOR.pdf:pdf},
keywords = {DASIA10,NGMP},
title = {{Next generation multipurpose microprocessor}},
year = {2010}}

@manual{ECSS-E-HB-11A,
title = {{ECSS-E-HB-11A Space engineering Technology readiness level (TRL) guidelines}},
howpublished = {ECSS guidelines},
month = mar,
year = {2017},
url = {https://quicksearch.dla.mil/qsDocDetails.aspx?ident_number=37110},
institution={Defense Information Systems Agency (DISA)}
}
@article{Ecoffet2013,
author = {Ecoffet, R.},
doi = {10.1109/TNS.2013.2262002},
issn = {00189499},
journal = {IEEE Transactions on Nuclear Science},
keywords = {In-orbit anomalies,radiation effects,space environment,spacecraft anomalies},
number = {3},
pages = {1791--1815},
title = {{Overview of in-orbit radiation induced spacecraft anomalies}},
volume = {60},
year = {2013}
}
@article{George2019,
author = {George, Jeffrey S.},
doi = {10.1063/1.5127719},
isbn = {9780735419056},
issn = {0094-243X},
journal = {AIP Conference Proceedings},
month = {oct},
number = {1},
pages = {060002},
publisher = {AIP Publishing LLC AIP Publishing},
title = {{An overview of radiation effects in electronics}},
url = {https://aip.scitation.org/doi/abs/10.1063/1.5127719},
volume = {2160},
year = {2019}
}
@INPROCEEDINGS{Zhou2004,
  author={Quming Zhou and Mohanram, K.},
  booktitle={2004 IEEE International Reliability Physics Symposium. Proceedings}, 
  title={Transistor sizing for radiation hardening}, 
  year={2004},
  volume={},
  number={},
  pages={310-315},
  doi={10.1109/RELPHY.2004.1315343}}

@article{LIU201045,
title = {Total-dose-induced edge effect in SOI NMOS transistors with different layouts},
journal = {Microelectronics Reliability},
volume = {50},
number = {1},
pages = {45-47},
year = {2010},
issn = {0026-2714},
doi = {https://doi.org/10.1016/j.microrel.2009.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0026271409003539},
author = {Jie Liu and Jicheng Zhou and Hongwei Luo and Xuedong Kong and Yunfei En and Qian Shi and Yujuan He}}

@article{HUANG2019105,
title = {An overview of radiation effects on electronic devices under severe accident conditions in NPPs, rad-hardened design techniques and simulation tools},
journal = {Progress in Nuclear Energy},
volume = {114},
pages = {105-120},
year = {2019},
issn = {0149-1970},
doi = {https://doi.org/10.1016/j.pnucene.2019.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0149197019300563},
author = {Qiang Huang and Jin Jiang}
}
@inbook{Furano2018,
address = {Cham},
author = {Furano, Gianluca and Menicucci, Alessandra},
booktitle = {Dependable Multicore Architectures at Nanoscale},
doi = {10.1007/978-3-319-54422-9_10},
editor = {Ottavi, Marco and Gizopoulos, Dimitris and Pontarelli, Salvatore},
isbn = {978-3-319-54422-9},
pages = {253--281},
publisher = {Springer International Publishing},
title = {{Roadmap for On-Board Processing and Data Handling Systems in Space}},
url = {https://doi.org/10.1007/978-3-319-54422-9_10},
year = {2018}
}
@ARTICLE{newspace,
  author={Mathieu, Pierre-Philippe and Borgeaud, Maurice and Desnos, Yves-Louis and Rast, Michael and Brockmann, Carsten and See, Linda and Kapur, Ravi and Mahecha, Miguel and Benz, Ursula and Fritz, Steffen},
  journal={IEEE Geoscience and Remote Sensing Magazine}, 
  title={The ESA's Earth Observation Open Science Program [Space Agencies]}, 
  year={2017},
  volume={5},
  number={2},
  pages={86-96},
  doi={10.1109/MGRS.2017.2688704}}

@inproceedings{Oltrogge,
author = {Oltrogge, Daniel L and Leveque, Kyle},
booktitle = {25 th Annual AIAA/USU Conference on Small Satellites},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oltrogge, Leveque - Unknown - An Evaluation of CubeSat Orbital Decay.pdf:pdf},
isbn = {6508594621},
title = {{An Evaluation of CubeSat Orbital Decay}},
year = {2011}
}

@inproceedings{Vidmar2021,
author = {Vidmar, Jason and Maillard, Pierre and Jones, Troy and Sawant, Minal and Gambardella, Giulio and Fraser, Nicholas},
booktitle = {2nd European Workshop on On-Board Data Processing (OBDP 2021)},
doi = {10.5281/ZENODO.5639613},
keywords = {board processing,obdp,obdp2021,on},
month = {jun},
title = {{Space DPU: Constructing a Radiation-Tolerant, FPGA-based Platform for Deep Learning Acceleration on Space Payloads}},
url = {https://zenodo.org/record/5639613},
year = {2021}
}

@ARTICLE{leon21,
  author={Leon, Vasileios and Stamoulias, Ioannis and Lentaris, George and Soudris, Dimitrios and Gonzalez-Arjona, David and Domingo, Ruben and Codinachs, David Merodio and Conway, Isabelle},
  journal={IEEE Access}, 
  title={Development and Testing on the European Space-Grade BRAVE FPGAs: Evaluation of NG-Large Using High-Performance DSP Benchmarks}, 
  year={2021},
  volume={9},
  number={},
  pages={131877-131892},
  doi={10.1109/ACCESS.2021.3114502}}
  
 @misc{sonos,
title = {{PolarFire SONOS Technology « Microsemi}},
url = {https://www.microsemi.com/blog/2018/04/10/polarfire-sonos-technology/},
urldate = {2022-03-06}
}
@ARTICLE{Marinella21,
  author={Marinella, Matthew J.},
  journal={IEEE Transactions on Nuclear Science}, 
  title={Radiation Effects in Advanced and Emerging Nonvolatile Memories}, 
  year={2021},
  volume={68},
  number={5},
  pages={546-572},
  doi={10.1109/TNS.2021.3074139}}
  
  @article{Hiemstra2015,
   author = {David M. Hiemstra and Valeri Kirischian},
   doi = {10.1109/REDW.2015.7336735},
   isbn = {9781467376419},
   journal = {IEEE Radiation Effects Data Workshop},
   keywords = {ARM® Cortex™-A9,Processing unit,Proton irradiation,Single event upset,Zynq-7000},
   month = {11},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Single event upset characterization of the Zynq-7000 ARM® Cortex™-A9 processor unit using proton irradiation},
   volume = {2015-November},
   year = {2015},
}

@ARTICLE{Vlagkoulis21,  author={Vlagkoulis, Vasileios and Sari, Aitzan and Vrachnis, John and Antonopoulos, Georgios and Segkos, Nikolaos and Psarakis, Mihalis and Tavoularis, Antonios and Furano, Gianluca and Boatella Polo, Cesar and Poivey, Christian and Ferlet-Cavrois, Veronique and Kastriotou, Maria and Fernandez Martinez, Pablo and Alia, Ruben Garcia and Voss, Kay-Obbe and Schuy, Christoph},  journal={IEEE Transactions on Nuclear Science},   title={Single Event Effects Characterization of the Programmable Logic of Xilinx Zynq-7000 FPGA Using Very/Ultra High-Energy Heavy Ions},   year={2021},  volume={68},  number={1},  pages={36-45},  doi={10.1109/TNS.2020.3033188}}

@INPROCEEDINGS{Sabogal19,  author={Sabogal, Sebastian and George, Alan and Crum, Gary},  booktitle={2019 IEEE Space Computing Conference (SCC)},   title={ReCoN: A Reconfigurable CNN Acceleration Framework for Hybrid Semantic Segmentation on Hybrid SoCs for Space Applications},   year={2019},  volume={},  number={},  pages={41-52},  doi={10.1109/SpaceComp.2019.00010}}

@INPROCEEDINGS{Sanchez19,  author={Sánchez, Antonio and Barrios, Yubal and Santos, Lucana and Sarmiento, Roberto},  booktitle={2019 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)},   title={Evaluation of TMR effectiveness for soft error mitigation in SHyLoC compression IP core implemented on Zynq SoC under heavy ion radiation},   year={2019},  volume={},  number={},  pages={1-4},  doi={10.1109/DFT.2019.8875281}}

@INPROCEEDINGS{Tambara15,  author={Tambara, Lucas Antunes and Kastensmidt, Fernanda Lima and Medina, Nilberto H. and Added, Nemitala and Aguiar, Vitor A. P. and Aguirre, Fernando and Macchione, Eduardo L. A. and Silveira, Marcilei A. G.},  booktitle={2015 IEEE Radiation Effects Data Workshop (REDW)},   title={Heavy Ions Induced Single Event Upsets Testing of the 28 nm Xilinx Zynq-7000 All Programmable SoC},   year={2015},  volume={},  number={},  pages={1-6},  doi={10.1109/REDW.2015.7336716}}
@INPROCEEDINGS{Bezerra17,  author={Bezerra, F. and Dangla, D. and Manni, F. and Mekki, J. and Standarovski, D. and Alia, R. G. and Brugger, M. and Danzeca, S.},  booktitle={2017 17th European Conference on Radiation and Its Effects on Components and Systems (RADECS)},   title={Evaluation of an Alternative Low Cost Approach for SEE Assessment of a SoC},   year={2017},  volume={},  number={},  pages={1-5},  doi={10.1109/RADECS.2017.8696219}}
@ARTICLE{Kibar19,  author={Kibar, Ogun O. and Mohan, Prashanth and Rech, Paolo and Mai, Ken},  journal={IEEE Transactions on Nuclear Science},   title={Evaluating the Impact of Repetition, Redundancy, Scrubbing, and Partitioning on 28-nm FPGA Reliability Through Neutron Testing},   year={2019},  volume={66},  number={1},  pages={248-254},  doi={10.1109/TNS.2018.2885066}}

@article{Cohen2009,
author = {Cohen, A.E. and Parhi, K.K.},
doi = {10.1109/TSP.2009.2022919},
issn = {1053-587X},
journal = {IEEE Trans. Signal Process.},
month = {oct},
number = {10},
pages = {4085--4094},
title = {{A Low-Complexity Hybrid LDPC Code Encoder for IEEE 802.3an (10GBase-T) Ethernet}},
volume = {57},
year = {2009}
}
@inproceedings{XiangranSun2011,
author = {{Xiangran Sun} and {Dongxin Shi}},
booktitle = {2011 Int. Conf. Comput. Sci. Serv. Syst.},
doi = {10.1109/CSSS.2011.5974805},
isbn = {978-1-4244-9762-1},
month = {jun},
pages = {2181--2184},
publisher = {IEEE},
title = {{Design and optimization of LDPC encoder based on LU decomposition with simulated annealing}},
year = {2011}
}
@inproceedings{Chia-YuLin2008,
annote = {Interesting. Add to the different (?) But basically it is H2},
author = {{Chia-Yu Lin} and {Chih-Chun Wei} and {Mong-Kai Ku}},
booktitle = {APCCAS 2008 - 2008 IEEE Asia Pacific Conf. Circuits Syst.},
doi = {10.1109/APCCAS.2008.4746353},
isbn = {978-1-4244-2341-5},
month = {nov},
pages = {1648--1651},
publisher = {IEEE},
title = {{Efficient encoding for dual-diagonal structured LDPC codes based on parity bit prediction and correction}},
year = {2008}
}
@inproceedings{Kopparthi2007,
annote = {802.16e},
author = {Kopparthi, Sunitha and Gruenbacher, Don M.},
booktitle = {2007 IEEE Pacific Rim Conf. Commun. Comput. Signal Process.},
doi = {10.1109/PACRIM.2007.4313268},
isbn = {1-4244-1190-4},
month = {aug},
pages = {438--441},
publisher = {IEEE},
title = {{Implementation of a Flexible Encoder for Structured Low-Density Parity-Check Codes}},
year = {2007}
}
@inproceedings{Neto2015,
author = {Neto, Nelson Alves Ferreira and de Oliveira, Joaquim Ranyere S. and de Oliveira, Wagner Luiz A. and Bittencourt, Joao Carlos N.},
booktitle = {2015 25th Int. Work. Power Timing Model. Optim. Simul.},
doi = {10.1109/PATMOS.2015.7347589},
isbn = {978-1-4673-9419-2},
month = {sep},
pages = {71--76},
publisher = {IEEE},
title = {{VLSI architecture design and implementation of a LDPC encoder for the IEEE 802.22 WRAN standard}},
year = {2015}
}
@inproceedings{YongminJung2012,
author = {{Yongmin Jung} and {Chulho Chung} and {Jaeseok Kim} and {Yunho Jung}},
booktitle = {2012 Int. SoC Des. Conf.},
doi = {10.1109/ISOCC.2012.6407078},
isbn = {978-1-4673-2990-3},
month = {nov},
pages = {215--218},
publisher = {IEEE},
title = {{7.7Gbps encoder design for IEEE 802.11n/ac QC-LDPC codes}},
year = {2012}
}
@inproceedings{Perez2010a,
author = {P{\'{e}}rez, Jes{\'{u}}s M. and Fern{\'{a}}ndez, V{\'{i}}ctor},
booktitle = {2010 Eur. Wirel. Conf. EW 2010},
doi = {10.1109/EW.2010.5483407},
isbn = {9781424459995},
keywords = {3GPP2,802.20,RC/QC-LDPC,VLSI},
title = {{3GPP2/802.20 RC/QC-LDPC encoding}},
year = {2010}
}
@inproceedings{Hariri2014,
author = {Hariri, Alaa Aldin Al and Monteiro, Fabrice and Sieler, Loic and Dandache, Abbas},
booktitle = {2014 21st IEEE Int. Conf. Electron. Circuits Syst.},
doi = {10.1109/ICECS.2014.7050104},
isbn = {978-1-4799-4242-8},
month = {dec},
pages = {790--793},
publisher = {IEEE},
title = {{Configurable and high-throughput architectures for Quasi-cyclic low-density parity-check codes}},
year = {2014}
}
@inproceedings{ZhiyongHe2006,
author = {{Zhiyong He} and Roy, S. and Fortier, P.},
booktitle = {2006 IEEE Int. Symp. Circuits Syst.},
doi = {10.1109/ISCAS.2006.1693323},
isbn = {0-7803-9389-9},
pages = {4},
publisher = {IEEE},
title = {{Encoder architecture with throughput over 10 Gbit/sec for quasi-cyclic LDPC codes}},
year = {2006}
}
@inproceedings{AlHariri2013,
author = {{Al Hariri}, Alaa Aldin and Monteiro, Fabrice and Sieler, Loic and Dandache, Abbas},
booktitle = {2013 IEEE 19th Int. On-Line Test. Symp.},
doi = {10.1109/IOLTS.2013.6604069},
isbn = {978-1-4799-0664-2},
month = {jul},
pages = {163--166},
publisher = {IEEE},
title = {{A high throughput configurable parallel encoder architecture for Quasi-Cyclic Low-Density Parity-Check Codes}},
year = {2013}
}
@inproceedings{Gomes2007,
author = {Gomes, Marco and Falcao, Gabriel and Sengo, Alexandre and Ferreira, Vitor and Silva, Vitor and Falcao, Miguel},
booktitle = {2007 Internatonal Conf. Microelectron.},
doi = {10.1109/ICM.2007.4497709},
isbn = {978-1-4244-1846-6},
month = {dec},
pages = {271--274},
publisher = {IEEE},
title = {{High throughput encoder architecture for DVB-S2 LDPC-IRA codes}},
year = {2007}
}
@article{Kaji2006,
author = {Kaji, Yuichi},
doi = {10.1093/ietfec/e89-a.10.2510},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaji - 2006 - Encoding LDPC Codes Using the Triangular Factorization.pdf:pdf},
journal = {IEICE TRANS. Fundam.},
keywords = {LDPC codes,encoding algorithm,sparse matrix,triangular factorization},
number = {10},
title = {{Encoding LDPC Codes Using the Triangular Factorization}},
url = {https://core.ac.uk/download/pdf/59176564.pdf},
year = {2006}
}
@inproceedings{Jia-ningSu2005,
author = {{Jia-ning Su} and {Hou Iang} and Ke iu and Iao-yang eng and {Ao Min} and {Ao Min}},
booktitle = {2005 6th Int. Conf. ASIC},
doi = {10.1109/ICASIC.2005.1611277},
isbn = {0-7803-9210-8},
pages = {168--171},
publisher = {IEEE},
title = {{An Efficient Low Complexity LDPC Encoder Based On Factorization With Pivoting}},
volume = {1},
year = {2005}
}
@article{Wang2017,
author = {Wang, Xiumin and Ge, Tingting and Li, Jun and Su, Chen and Hong, Fangfei},
doi = {10.1049/cje.2017.01.006},
issn = {1022-4653},
journal = {Chinese J. Electron.},
month = {mar},
number = {2},
pages = {250--255},
title = {{Efficient Multi-rate Encoder of QC-LDPC Codes Based on FPGA for WIMAX Standard}},
volume = {26},
year = {2017}
}
@article{HaibinZhang2008,
author = {{Haibin Zhang} and {Jia Zhu} and {Huifeng Shi} and {Dawei Wang}},
doi = {10.1109/TCSI.2008.916433},
issn = {1549-8328},
journal = {IEEE Trans. Circuits Syst. I Regul. Pap.},
month = {mar},
number = {2},
pages = {572--585},
title = {{Layered Approx-Regular LDPC: Code Construction and Encoder/Decoder Design}},
volume = {55},
year = {2008}
}
@article{HaoZhong2005,
annote = {PhiInv in parallel!},
author = {{Hao Zhong} and {Tong Zhang}},
doi = {10.1109/TCSI.2005.844113},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hao Zhong, Tong Zhang - 2005 - Block-LDPC a practical LDPC coding system design approach.pdf:pdf},
issn = {1057-7122},
journal = {IEEE Trans. Circuits Syst. I Regul. Pap.},
month = {apr},
number = {4},
pages = {766--775},
title = {{Block-LDPC: a practical LDPC coding system design approach}},
volume = {52},
year = {2005}
}
@article{Yu2014,
author = {Yu, Shuo and Liu, Changyin and Zhang, Peng and Jiang, Lanxiang},
doi = {10.1049/el.2013.2390},
issn = {0013-5194},
journal = {Electron. Lett.},
month = {feb},
number = {4},
pages = {320--321},
title = {{Efficient encoding of QC-LDPC codes with multiple-diagonal parity-check structure}},
volume = {50},
year = {2014}
}
@inproceedings{Tzimpragos2013,
author = {Tzimpragos, Georgios and Kachris, Christoforos and Soudris, Dimitrios and Tomkos, Ioannis},
booktitle = {2013 23rd Int. Conf. F. Program. Log. Appl.},
doi = {10.1109/FPL.2013.6645587},
isbn = {978-1-4799-0004-6},
month = {sep},
pages = {1--4},
publisher = {IEEE},
title = {{A low-complexity implementation of QC-LDPC encoder in reconfigurable logic}},
year = {2013}
}

@article{Yen2012,
author = {Yen, Shao-Wei and Hung, Shiang-Yu and Chen, Chih-Lung and Chang, Hsie-Chia and Jou, Shyh-Jye and Lee, Chen-Yi},
doi = {10.1109/JSSC.2012.2194176},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yen et al. - 2012 - A 5.79-Gbs Energy-Efficient Multirate LDPC Codec Chip for IEEE 802.15.3c Applications.pdf:pdf},
issn = {0018-9200},
journal = {IEEE J. Solid-State Circuits},
month = {sep},
number = {9},
pages = {2246--2257},
title = {{A 5.79-Gb/s Energy-Efficient Multirate LDPC Codec Chip for IEEE 802.15.3c Applications}},
volume = {47},
year = {2012}
}
@inproceedings{Andrews2005,
author = {Andrews, K. and Dolinar, S. and Thorpe, J.},
booktitle = {Proceedings. Int. Symp. Inf. Theory, 2005. ISIT 2005.},
doi = {10.1109/ISIT.2005.1523758},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrews, Dolinar, Thorpe - 2005 - Encoders for block-circulant LDPC codes.pdf:pdf},
isbn = {0-7803-9151-9},
pages = {2300--2304},
publisher = {IEEE},
title = {{Encoders for block-circulant LDPC codes}},
year = {2005}
}
@inproceedings{Yasotharan2009,
author = {Yasotharan, Hemesh and Carusone, Anthony Chan},
booktitle = {2009 52nd IEEE Int. Midwest Symp. Circuits Syst.},
doi = {10.1109/MWSCAS.2009.5236155},
file = {:home/mitsor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yasotharan, Carusone - 2009 - A flexible hardware encoder for systematic low-density parity-check codes.pdf:pdf},
isbn = {978-1-4244-4479-3},
month = {aug},
pages = {54--57},
publisher = {IEEE},
title = {{A flexible hardware encoder for systematic low-density parity-check codes}},
year = {2009}
}
@article{ZongwangLi2006,
author = {{Zongwang Li} and {Lei Chen} and {Lingqi Zeng} and Lin, S. and Fong, W.H.},
doi = {10.1109/TCOMM.2005.861667},
issn = {0090-6778},
journal = {IEEE Trans. Commun.},
month = {jan},
number = {1},
pages = {71--81},
title = {{Efficient encoding of quasi-cyclic low-density parity-check codes}},
volume = {54},
year = {2006}
}
@article{Miles2006,
author = {Miles, L.H. and Gambles, J.W. and Maki, G.K. and Ryan, W.E. and Whitaker, S.R.},
doi = {10.1109/JSSC.2006.877253},
issn = {0018-9200},
journal = {IEEE J. Solid-State Circuits},
month = {aug},
number = {8},
pages = {1686--1691},
title = {{An 860-Mb/s (8158,7136) Low-Density Parity-Check Encoder}},
volume = {41},
year = {2006}
}
@inproceedings{ZhaohuiWangXinHaoChangxingLin2018,
address = {Chongqing},
author = {{Zhaohui Wang, Xin Hao, Changxing Lin}, Qiuyu Wu},
booktitle = {2018 IEEE 18th Int. Conf. Commun. Technol.},
doi = {10.1109/ICCT.2018.8599970},
pages = {136--139},
publisher = {IEEE},
title = {{An Efficient Hardware LDPC Encoder Based on Partial Parallel Structure for CCSDS}},
year = {2018}
}
@inproceedings{Theodoropoulos2016,
author = {Theodoropoulos, Dimitris and Kranitis, Nektarios and Paschalis, Antonios},

booktitle = {2016 IEEE 22nd Int. Symp. On-Line Test. Robust Syst. Des.},
doi = {10.1109/IOLTS.2016.7604689},
isbn = {978-1-5090-1507-8},
month = {jul},
pages = {149--154},
publisher = {IEEE},
title = {{An efficient LDPC encoder architecture for space applications}},
year = {2016}
}
@inproceedings{Lee2004,
author = {Lee, Dong-U and Luk, Wayne and Wang, Connie and Jones, Christopher and Smith, Michael and Villasenor, John},
booktitle = {12th Annu. IEEE Symp. Field-Programmable Cust. Comput. Mach.},
doi = {10.1109/FCCM.2004.4},
pages = {101--111},
publisher = {IEEE},
title = {{A Flexible Hardware Encoder for Low-Density Parity-Check Codes}},
year = {2004}
}
@inproceedings{Wang2008,
annote = {LU},
author = {Wang, Peng and Chen, Yong-en},
booktitle = {2008 Int. Conf. Intell. Inf. Hiding Multimed. Signal Process.},
doi = {10.1109/IIH-MSP.2008.15},
isbn = {978-0-7695-3278-3},
month = {aug},
pages = {1209--1212},
publisher = {IEEE},
title = {{Low-Complexity Real-Time LDPC Encoder Design for CMMB}},
year = {2008}
}
@article{Mahdi2014,
author = {Mahdi, Ahmed and Paliouras, Vassilis},
doi = {10.1109/TSP.2014.2314435},
issn = {1053-587X},
journal = {IEEE Trans. Signal Process.},
month = {may},
number = {10},
pages = {2696--2708},
title = {{A Low Complexity-High Throughput QC-LDPC Encoder}},
volume = {62},
year = {2014}
}
@article{Gallager1962,
author = {Gallager, R.},
doi = {10.1109/TIT.1962.1057683},
issn = {0018-9448},
journal = {IRE Trans. Inf. Theory},
month = {jan},
number = {1},
pages = {21--28},
title = {{Low-density parity-check codes}},
volume = {8},
year = {1962}
}
@article{Shannon,
author = {{E. Shannon}, Claude},
doi = {10.1145/584091.584093},
journal = {Bell Syst. Tech. J.},
pages = {379--423},
title = {{A Mathematical Theory of Communication}},
volume = {27},
year = {1948}
}

@INPROCEEDINGS{Berrou1993,
  author={Berrou, C. and Glavieux, A. and Thitimajshima, P.},
  booktitle={Proceedings of ICC '93 - IEEE International Conference on Communications}, 
  title={Near Shannon limit error-correcting coding and decoding: Turbo-codes. 1}, 
  year={1993},
  volume={2},
  number={},
  pages={1064-1070 vol.2},
  doi={10.1109/ICC.1993.397441}}
@book{Ryan2009,
place={Cambridge}, title={Channel Codes: Classical and Modern}, DOI={10.1017/CBO9780511803253}, publisher={Cambridge University Press}, author={Ryan, William and Lin, Shu}, year={2009}}
@manual{CCSDS141,
title = {{1064 nm Optical High Data Rate (HDR) Communication}},
howpublished  = {CCSDS Experimental Specification 141.11-O-1},
month = dec,
url={https://public.ccsds.org/Pubs/141x11o1e2.pdf},
year = {2018},
institution={CCSDS}
}

@manual{CCSDS142,
title = {{Optical Communications Coding and Communications Coding and Synchronization}},
howpublished = {CCSDS Recommended Standard 142.0-B-1},
month = aug,
year = {2019},
url = {https://public.ccsds.org/Pubs/142x0b1.pdf},
institution={CCSDS}
}
@manual{CCSDS131.0,
title = {{TM Synchronization and Channel Coding}},
howpublished = {CCSDS Recommended Standard 131.0-B-1},
month = sep,
year = {2017},
url = {https://public.ccsds.org/Pubs/131x0b3e1.pdf},
institution={CCSDS}
}

@techreport{CCSDS130,
title = {{Overview of Space Communication Protocols}},
howpublished = {Informational Report},
type = {130.0-G.3},
month = jul,
year = {2014},
volume = {2014},
url = {https://public.ccsds.org/Pubs/130x0g3.pdf},
institution={CCSDS}
}

@manual{CCSDS131.5,
title = {{Erasure Correcting Codes for Use in Near-Earth and Deep Space Communications}},
howpublished = {CCSDS Experimental Specification 131.5-O-1},
month = nov,
year = {2014},
url = {https://public.ccsds.org/Pubs/142x0b1.pdf},
institution={CCSDS}
}




@manual{JTC2014,
title = {{Digital Video Broadcasting (DVB)\;Second generation framing structure, channel coding and modulation systems for Broadcasting, Interactive Services, News Gathering and other broadband satellite applications\; Part 1: DVB-S2}},
howpublished  = {ETSI EN 302 307-1 V1.4.1}},
url={https://www.etsi.org/deliver/etsi_en/302300_302399/30230701/01.04.01_60/en_30230701v010401p.pdf},
year = {2014},
institution={ETSI}
}

@manual{ECSS,
title = {{SpaceFibre – Very high-speed serial link}},
howpublished = {ECSS-E-ST-50-11C},
url = {https://ecss.nl/standard/ecss-e-st-50-11c-spacefibre-very-high-speed-serial-link/},
year = {2019},
month = {may},
institution={ECSS}
}
@manual{ion,
title = {{Interplanetary Overlay Network (ION) software distribution (4.0.2)}},
url = {https://sourceforge.net/projects/ion-dtn/},
urldate = {2020-12-21}
}

@manual{Vunit21,
institution = {Asplund, Lars},
title = {{VUnit: a test framework for HDL v.4.4.0}},
url = {https://vunit.github.io/},
year = {2020}
}

@manual{leon3,
howpublished = {Cobham Gaisler},
title = {{GRLIB IP Library}},
url = {https://www.gaisler.com/index.php/products/ipcores/soclibrary},
urldate = {2021-04-12}
}



@inproceedings{Hund2010,
abstract = {Especially for synchronization-critical wireless networks like ultrawideband impulse radio (UWB-IR), data packets are lost not only due to single bit errors in the payload but also to a large degree because of synchronization errors or preamble failures. Current FEC codes only address bit errors inside a packet. Packets that are lost because of errors in preambles or headers can only be recovered on packet level. In this Paper we propose a low-complexity adaptive packet-level FEC and prove by simulation that it can reduce packet loss with very small overhead. {\textcopyright} 2010 IEEE.},
author = {Hund, Johannes and Heinrich, Andreas and Ziller, Andreas and Schwingenschl{\"{o}}gl, Christian and Kraemer, Rolf},
booktitle = {Proc. 2010 7th Work. Positioning, Navig. Commun. WPNC'10},
doi = {10.1109/WPNC.2010.5653666},
isbn = {9781424471577},
keywords = {Erasure coding,FEC,IEEE 802.15.4a,UWB},
pages = {1--3},
title = {{A packet-level adaptive forward error correction scheme for wireless networks}},
year = {2010}
}
@techreport{Roca2006a,
author = {Roca, Vincent and Neumann, Christoph},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roca, Neumann - 2006 - Design, Evaluation and Comparison of Four Large Block FEC Codecs, LDPC, LDGM, LDGM Staircase and LDGM Triangle, p.pdf:pdf},
title = {{Design, Evaluation and Comparison of Four Large Block FEC Codecs, LDPC, LDGM, LDGM Staircase and LDGM Triangle, plus a Reed-Solomon Small Block FEC Codec}},
url = {https://hal.inria.fr/inria-00070770},
year = {2006}
}



@misc{openFec,
title = {{OpenFEC.org project}},
url = {http://openfec.org/},
urldate = {2021-04-11}
}

@inproceedings{Edwards2019,
author = {Edwards, Bernard L. and Daddato, Robert and Schulz, Klaus Juergen and Alliss, Randall and Hamkins, Jon and Giggenbach, DIrk and Robinson, Bryan and Braatz, Lena},
booktitle = {2019 IEEE Int. Conf. Sp. Opt. Syst. Appl. ICSOS 2019},
doi = {10.1109/ICSOS45490.2019.8978979},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Edwards et al. - 2019 - An Update on the CCSDS Optical Communications Working Group Interoperability Standards.pdf:pdf},
isbn = {9781728105000},
month = {oct},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{An Update on the CCSDS Optical Communications Working Group Interoperability Standards}},
year = {2019}
}
@inproceedings{Ostovari2015,
  author={P. {Ostovari} and J. {Wu}},
  booktitle={2015 IEEE 12th Int. Conf. on Mobile Ad Hoc and Sensor Syst.}, 
  title={Reliable Broadcast with Joint Forward Error Correction and Erasure Codes in Wireless Communication Networks}, 
  year={2015},
  volume={},
  number={},
  pages={324-332},
  doi={10.1109/MASS.2015.68}}
}

@article{Dimitrov2016,
abstract = {In this paper, a packet-level forward error correction coding technique and pre-distortion adaptive optics technology are applied to a digital transmission scheme for optical feeder links in a geostationary Earth orbit satellite communication system. The architectures of the gateway and the satellite are defined, including the building blocks of the interface between the radio frequency front-end and the optical front-end, as well as the digital signal processor. The system is designed to cater for Terabit/s high-throughput satellite applications. The performance of the digital transmission scheme is evaluated in the forward and return links. The turbulent atmospheric optical channel is modeled for different optical ground station altitudes. It is shown that fade mitigation techniques such as packet-level forward error correction coding and pre-distortion adaptive optics in the forward link, as well as large-aperture optical ground station telescope in the return link, are essential to close the link budget of a Terabit/s satellite communication system. Copyright {\textcopyright} 2015 John Wiley {\&} Sons, Ltd.},
author = {Dimitrov, Svilen and Barrios, Ricardo and Matuz, Balazs and Liva, Gianluigi and Mata-Calvo, Ramon and Giggenbach, Dirk},
doi = {10.1002/sat.1163},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dimitrov et al. - 2016 - Digital modulation and coding for satellite optical feeder links with pre-distortion adaptive optics.pdf:pdf},
issn = {15420973},
journal = {Int. J. Satell. Commun. Netw.},
keywords = {Terabit/s satellite communication,correlated fading,digital modulation,optical feeder link,packet-level coding,pre-distortion adaptive optics,scintillation,turbulent optical channel},
month = {sep},
number = {5},
pages = {625--644},
publisher = {John Wiley and Sons Ltd},
title = {{Digital modulation and coding for satellite optical feeder links with pre-distortion adaptive optics}},
url = {http://doi.wiley.com/10.1002/sat.1163},
volume = {34},
year = {2016}
}


@incollection{DeCola2008,
author = {{De Cola}, Tomaso and Ernst, Harald and Marchese, Mario},
doi = {10.1007/978-0-387-47524-0_49},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Cola, Ernst, Marchese - 2008 - Application of Long Erasure Codes and ARQ Schemes for Achieving High Data Transfer Performance Over Lo.pdf:pdf},
pages = {643--656},
title = {{Application of Long Erasure Codes and ARQ Schemes for Achieving High Data Transfer Performance Over Long Delay Networks}},
url = {http://link.springer.com/10.1007/978-0-387-47524-0{\_}49},
year = {2008}
}
@article{Liva2013a,
abstract = {In many applications erasure correcting codes are used to recover packet losses at high protocol stack layers. The objects (e.g. files) to be transmitted often have variable sizes, resulting in a variable number of packets to be encoded by the packet-level encoder. In this paper, algorithms for the (on-line) flexible design of parity-check matrices for irregular-repeat-accumulate codes are investigated. The proposed algorithms allow designing in fast manner parity-check matrices that are suitable for low-complexity maximum-likelihood decoding. The code ensembles generated by the algorithms are analyzed via extrinsic information transfer charts. Numerical results show how the designed codes can attain codeword error rates as low as 10{\^{}}{\{}-5{\}} without appreciable losses w.r.t. the performance of idealized maximum-distance separable codes. Finally, we apply the proposed codes to the upcoming aeronautical communication standard, showing large performance improvements and proving the efficiency and the flexibility of the developed method. {\textcopyright} 2013 IEEE.},
author = {Liva, Gianluigi and Pulini, Paola and Chiani, Marco},
doi = {10.1109/TWC.2012.121412120053},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liva, Pulini, Chiani - 2013 - On-line construction of irregular repeat accumulate codes for packet erasure channels.pdf:pdf},
issn = {15361276},
journal = {IEEE Trans. Wirel. Commun.},
keywords = {Fountain codes,aeronautical communications,erasure channel,low-density parity-check codes,reliable multicast},
number = {2},
pages = {680--689},
title = {{On-line construction of irregular repeat accumulate codes for packet erasure channels}},
volume = {12},
year = {2013}
}
@article{Luby2001,
abstract = {We introduce a simple erasure recovery algorithm for codes derived from cascades of sparse bipartite graphs and analyze the algorithm by analyzing a corresponding discrete-time random process. As a result, we obtain a simple criterion involving the fractions of nodes of different degrees on both sides of the graph which is necessary and sufficient for the decoding process to finish successfully with high probability. By carefully designing these graphs we can construct for any given rate R and any given real number $\epsilon$ a family of linear codes of rate R which can be encoded in time proportional to ln(1/$\epsilon$) times their block length n. Furthermore, a codeword can be recovered with high probability from a portion of its entries of length (1 + $\epsilon$) Rn or more. The recovery algorithm also runs in time proportional to n ln(1/$\epsilon$). Our algorithms have been implemented and work well in practice; various implementation issues are discussed.},
annote = {They propose a acscade parity bits structure. Experiment with packet level code 640k packets 256 bytes each, rate 1/2},
author = {Luby, Michael G. and Mitzenmacher, Michael and Shokrollahi, M. Amin and Spielman, Daniel A.},
doi = {10.1109/18.910575},
file = {:home/mitsor/di/erasure/decoding only/luby2001.pdf:pdf},
issn = {00189448},
journal = {IEEE Trans. Inf. Theory},
keywords = {Erasure channel,Large deviation analysis,Low-density parity-check codes},
number = {2},
pages = {569--584},
title = {{Efficient erasure correcting codes}},
volume = {47},
year = {2001}
}
@article{Paolini2012,
author = {Paolini, Enrico and Liva, Gianluigi and Matuz, Balazs and Chiani, Marco},
doi = {10.1109/TCOMM.2012.081012.110363},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paolini et al. - 2012 - Maximum Likelihood Erasure Decoding of LDPC Codes Pivoting Algorithms and Code Design.pdf:pdf},
issn = {0090-6778},
journal = {IEEE Trans. Commun.},
month = {nov},
number = {11},
pages = {3209--3220},
title = {{Maximum Likelihood Erasure Decoding of LDPC Codes: Pivoting Algorithms and Code Design}},
url = {http://ieeexplore.ieee.org/document/6266770/},
volume = {60},
year = {2012}
}
@inproceedings{Hisamatsu2010,
abstract = {Packet-level erasure correction is considered for downstream packets each of which is delivered from a base station to an individual receiver (i.e., user) over a lossy shared wireless network where only a very limited upstream feedback is provided. Note that, while the destination of each packet is a single user, each packet can be overheard by all users in the shared network. With exploiting this overhearing property of wireless links, we focus on packet recovery by exclusive-OR (XOR) packet composition-based forward-erasure- correction (FEC). For network applications with packet-loss tolerance and delay-time limitation, our goal is to increase the effective packet received rate (the ratio of finally received/recovered packets after applying FEC) of each user with fairness in a low-cost manner. We propose a simple XOR packet composition scheme that can approximately maximize the minimum effective packet received rate among users, based on an experimentally suggested linear relation between the packet loss rates and the optimal packet composition ratios among users. Simulation results clearly indicate the potential effectiveness of the proposal. {\textcopyright}2010 IEEE.},
author = {Hisamatsu, Satoshi and Tamura, Hitomi and Tsuru, Masato and Oie, Yuji},
booktitle = {IEEE Int. Symp. Pers. Indoor Mob. Radio Commun. PIMRC},
doi = {10.1109/PIMRCW.2010.5670506},
isbn = {9781424491162},
keywords = {FEC/FZC (Forward Erasure Correction),Lossy wireless network,Packet composition,Packet recovery},
pages = {496--501},
title = {{Packet-level forward erasure correction with user fairness in lossy wireless networks}},
year = {2010}
}
@article{Adhikary2020,
abstract = {To maximize file transfer from deep-space vehicles, a space-to-earth content-transfer protocol that combines turbo codes, RaptorQ codes, real-time channel prediction, and dynamic code-rate selection is proposed. The protocol features a signal-to-noise ratio prediction model that facilitates the periodic adjustment of turbo encoder to achieve adaptive-rate transmission, and fountain codes to eliminate retransmission of specific packets. Simulation results indicate that an increase of about 132{\%} in file transfer rate is achievable compared to fixed-rate transmission scheme.},
author = {Adhikary, Rojina and Daigle, John N. and Cao, Lei},
doi = {10.1109/TAES.2019.2921212},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adhikary, Daigle, Cao - 2020 - Dynamic Code Selection Method for Content Transfer in Deep-Space Network.pdf:pdf},
issn = {15579603},
journal = {IEEE Trans. Aerosp. Electron. Syst.},
keywords = {Channel prediction,RaptorQ codes,deep-space communications,dynamic code selection method (DCSM),turbo codes},
month = {feb},
number = {1},
pages = {456--474},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Dynamic Code Selection Method for Content Transfer in Deep-Space Network}},
volume = {56},
year = {2020}
}
@inproceedings{Mattoussi2015,
abstract = {Content broadcasting over wireless networks heavily relies on Application-Level FEC codes to improve transmission robustness in front of channel erasures. Because they operate in the higher layers of the protocol stack, they benefit from a lot of flexibility. In particular, since streaming applications and bulk transfer applications have different constraints, different packet scheduling strategies may be used by the sender, offering different trade-offs between decoding latency and long erasure burst protection. This work tries to find the best packet scheduling scheme(s) at a sender for a given type of AL-FEC codes. The contributions are twofold: first we define a methodology to measure the impacts of packet scheduling on AL-FEC performance, both under ITerative (IT) and Maximum Likelihood (ML) decoding, for a large set of channels; then we apply this methodology to GLDPC-Staircase codes, an extension of LDPC-Staircase codes using Reed Solomon codes as inner codes. In previous works we showed that these codes have erasure recovery performance close to ideals codes when packets are transmitted in a random order. In this work we show that these codes perform extremely well when sending source packets sequentially first (a key requirement to keep latency minimum with streaming applications) and then extra-repair packets followed by LDPC repair packets, both in a random order.},
author = {Mattoussi, Ferdaouss and Roca, Vincent and Sayadi, Bessem},
booktitle = {2015 Eur. Conf. Networks Commun. EuCNC 2015},
doi = {10.1109/EuCNC.2015.7194119},
isbn = {9781467373593},
month = {aug},
pages = {465--470},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Impacts of the packet scheduling on the performance of erasure codes: Methodology and application to GLDPC-Staircase codes}},
year = {2015}
}
@article{Davarian2020a,
author = {Davarian, Faramaz and Asmar, Sami and Angert, Matt and Baker, John and Gao, Jay and Hodges, Richard and Israel, David and Landau, Damon and Lay, Norman and Torgerson, Leigh and Walsh, William},
doi = {10.1109/MAES.2020.2975260},
issn = {1557959X},
journal = {IEEE Aerosp. Electron. Syst. Mag.},
month = {jul},
number = {7},
pages = {26--40},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Improving Small Satellite Communications and Tracking in Deep Space - A Review of the Existing Systems and Technologies with Recommendations for Improvement. Part II: Small Satellite Navigation, Proximity Links, and Communications Link Science}},
volume = {35},
year = {2020}
}
@inproceedings{Geethu2015,
abstract = {This paper investigates the performance of two popular packet level erasure coding approaches, i.e., end-to-end and hop-by-hop, for improving the data transmission reliability in Underwater Acoustic Sensor Networks (UWASNs). In the end-to-end approach, encoding and decoding are performed by the source node and sink node, respectively, while the intermediate nodes just forward the data packets without any processing. In this case, the number of redundant packets to be transmitted by the source (i.e., code rate) is chosen based on packet success probability along the path. On the other hand, the hop-by-hop erasure coding is used to achieve reliability over each hop along the path. In this case, apart from the source node, all the intermediate nodes perform the encoding process and each node adaptively computes the number of redundant packets for the next hop based on the quality of the corresponding hop. We present an analytical model to find the communication overhead, energy consumption and average delay of the multi-hop UWASN under the above erasure coding approaches. The results show that hop-by-hop erasure coding outperforms end-to-end erasure coding.},
author = {Geethu, K. S. and Babu, A. V.},
booktitle = {2015 Int. Conf. Adv. Comput. Commun. Informatics, ICACCI 2015},
doi = {10.1109/ICACCI.2015.7275934},
isbn = {9781479987917},
keywords = {erasure codes,reliable data transfer,underwater acoustic sensor networks},
month = {sep},
pages = {2145--2151},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Performance analysis of erasure coding based data transfer in Underwater Acoustic Sensor Networks}},
year = {2015}
}
@article{Cheour2019,
author = {Cheour, Rym and Khriji, Sabrine and Houssaini, Dhouha El and Baklouti, Mouna and Abid, Mohamed and Kanoun, Olfa},
doi = {10.1109/MAES.2019.2901134},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheour et al. - 2019 - Recent Trends of FPGA Used for Low-Power Wireless Sensor Network.pdf:pdf},
issn = {1557959X},
journal = {IEEE Aerosp. Electron. Syst. Mag.},
month = {oct},
number = {10},
pages = {28--38},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Recent Trends of FPGA Used for Low-Power Wireless Sensor Network}},
volume = {34},
year = {2019}
}
@techreport{Chiani2007,
annote = {Interesting EXAMPLE PROFILES for block lengths and data rates.
Decoding demystified (somewhat)},
author = {Chiani, Marco and Paolini, Enrico},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chiani, Paolini - 2007 - Long Erasure Codes for CCSDS Applications Authors.pdf:pdf},
title = {{Long Erasure Codes for CCSDS Applications Authors}},
url = {https://pdfs.semanticscholar.org/6100/8d83881d98a81a49b94e6ac5da9e1fa46317.pdf},
year = {2007}
}
@inproceedings{Garrammone2012,
abstract = {The use of erasure codes in space communications has proved to be promising in order to make communication more robust against both independent and correlated data losses. In particular, erasure codes are an appealing solution to provide space communications with increased reliability, especially in scenarios where large latencies make the use of automatic repeat request (ARQ) strategies problematic. In this regard, preliminary studies on the use of binary low-density parity-check (LDPC) codes under maximum likelihood (ML)/iterative (IT) decoding have been carried out showing the performance benefit they can bring over traditional schemes based on retransmissions. This paper extends the analysis conducted in previous studies towards non-binary LDPC codes. Performance assessment is carried out with respect to reliability metrics (codeword error rate) and encoding/decoding complexity, taking into consideration the limitations of space communications in terms of storage and processing capabilities. Finally, the paper sketches some design guidelines on the integration of the proposed codes into the Consultative Committee for Space Data Systems (CCSDS) protocol stack, implemented as extension of the Licklider Transmission Protocol (LTP). {\textcopyright} 2012 IEEE.},
author = {Garrammone, Giuliano and {De Cola}, Tomaso and Matuz, Balazs and Liva, Gianluigi},
booktitle = {2012 6th Adv. Satell. Multimed. Syst. Conf. ASMS 2012 12th Signal Process. Sp. Commun. Work. SPSC 2012},
doi = {10.1109/ASMS-SPSC.2012.6333092},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garrammone et al. - 2012 - Erasure codes for space communications Recent findings and new challenges.pdf:pdf},
isbn = {9781467326766},
pages = {29--35},
title = {{Erasure codes for space communications: Recent findings and new challenges}},
year = {2012}
}
@article{Paolini2006,
abstract = {In space communications, traditional error correction/detection techniques deliver to the upper layers of the communication stack only the data units for which integrity can be guaranteed. The uncorrectable data units are then "lost", and the upper layers have typically to face data units erasures. Hence, the packet erasure channel (PEC) is the most proper channel model from the point of view of the upper layers. Automatic re-peat/retransmission query (ARQ) is the "traditional" solution implemented at the upper layers in order to face data units erasures. However, ARQ is not always possible for space or satellite communications. In such situations, forward error correction (FEC) must be used. Nowadays new techniques for FEC are available also for application at the upper layers. Long erasure correcting (LEC) codes represent a new and very promising proposal for packet erasure FEC. They are able to overcome the complexity limitations of other types of codes, while preserving very good erasure correction capability. They are currently under investigation within the CCSDS (Consultative Committee for Space Data Systems) long erasure codes Bird of Feather (LEC-BOF), where a leading role has been so far played by ESA/ESOC and NASA-JPL. In this paper, the activity of the LEC-BOF is be illustrated. More in detail, the basic ideas behind LEC codes are presented, as well as the possible codes structures, the encoding and decoding rules, some theoretical properties. Some numerical results are presented, showing the performance of LEC codes on both memory-less and burst erasure channel.},
author = {Paolini, Enrico and Chiani, Marco and Calzolari, Gian Paolo},
doi = {10.2514/6.2006-5827},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paolini, Chiani, Calzolari - 2006 - Long Erasure Correcting Codes the New Frontier for Zero Loss in Space Applications.pdf:pdf},
title = {{Long Erasure Correcting Codes: the New Frontier for Zero Loss in Space Applications?}},
url = {http://arc.aiaa.org},
year = {2006}
}
@article{Han2005,
abstract = {In this paper, we introduce packet low-density parity-check (packet-LDPC) codes for high-density tape storage systems. We report on the performance of two error control code (ECC) architectures based on the packet-LDPC codes. The architectures are designed to be (approximately) compatible with the widely used ECMA-319 ECC standard based on two interleaved concatenated 8-bit Reed-Solomon (RS) codes. One architecture employs an inner RS code; the other employs an inner turbo product code with single parity-check constituent codes (TPC-SPC). Both employ a packet-LDPC code as the outer code. As for the ECMA-319 system, both schemes are required to correct noise bursts due to media defects and synchronization loss, as well as the loss of one of eight tracks (due to a head clog, for example). We show that the first packet-LDPC code architecture substantially outperforms the ECMA-319 scheme and is only a few tenths of a decibel inferior to a long, highly complex 12-bit RS scheme. The second architecture outperforms both the ECMA-319 and the long RS code scheme. {\textcopyright} 2005 IEEE.},
author = {Han, Yang and Ryan, William E.},
doi = {10.1109/TMAG.2005.844834},
issn = {00189464},
journal = {IEEE Trans. Magn.},
keywords = {Error control code (ECC),Low-density parity-check (LDPC),Packet-LDPC,Tape recording},
month = {apr},
number = {4},
pages = {1340--1347},
title = {{Packet-LDPC codes for tape drives}},
volume = {41},
year = {2005}
}
@article{Davarian2020,
annote = {Good intro to optical communications deep space and cubesat},
author = {Davarian, Faramaz and Babuscia, Alessandra and Baker, John and Hodges, Richard and Landau, Damon and Lau, Chi-wung and Lay, Norman and Angert, Matt and Kuroda, Vanessa},
doi = {10.1109/MAES.2020.2980918},
issn = {0885-8985},
journal = {IEEE Aerosp. Electron. Syst. Mag.},
month = {jul},
number = {7},
pages = {8--25},
title = {{Improving Small Satellite Communications in Deep Space—A Review of the Existing Systems and Technologies With Recommendations for Improvement. Part I: Direct to Earth Links and SmallSat Telecommunications Equipment}},
volume = {35},
year = {2020}
}
@article{Reed1960,
abstract = {This paper presents a survey of coding theory for statisticians and mathematicians who have some familiarity with modern algebra, finite fields and possibly some acquaintance with block designs. No knowledge of stochastic processes, information theory or ...},
author = {Reed, I. S. and Solomon, G.},
doi = {10.1137/0108018},
issn = {0368-4245},
journal = {J. Soc. Ind. Appl. Math.},
month = {jun},
number = {2},
pages = {300--304},
publisher = {Society for Industrial {\&} Applied Mathematics (SIAM)},
title = {{Polynomial Codes Over Certain Finite Fields}},
volume = {8},
year = {1960}
}
@article{Liang2020,
abstract = {Emerging computing paradigm edge computing expects to store and process data at the network edge with reduced latency and improved network bandwidth. To the best of our knowledge, key performance issues such as coding performance of erasure-coded storage systems haven't been investigated for edge computing. In this paper, we present an erasure-coded storage system for edge computing. Unlike the data center and cloud storage systems, it employs edge devices to perform encoding and decoding operations, which can be a performance bottleneck of the whole storage system due to limited computing power. Hence, we present a comprehensive study of the performance of erasure coding to see if it can match the network performance of 5G and Wi-Fi 6 at the network edge. We use the popular edge device Jetson Nano and two state-of-the-art coding libraries: Jerasure and G-CRS. Our evaluation results reveal unsatisfied performance for Jerasure and high variance for G-CRS. To obtain better and stable performance, we accelerate erasure code with OpenMP on a multi-core CPU. Our work demonstrates our acceleration can bring stable performance and match the network bandwidth of 5G and Wi-Fi 6 for some commonly used cases. Besides, our work offers a better understanding of erasure-coded storage systems for edge computing and can be served as a reference to any further optimization for such kind of systems at the network edge.},
author = {Liang, Lixin and He, Huan and Zhao, Jian and Liu, Chengjian and Luo, Qiuming and Chu, Xiaowen},
doi = {10.1109/ACCESS.2020.2995973},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang et al. - 2020 - An erasure-coded storage system for edge computing.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Erasure-coded storage system,edge computing,erasure coding,jetson nano},
pages = {96271--96283},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{An erasure-coded storage system for edge computing}},
volume = {8},
year = {2020}
}
@article{Berger2008,
abstract = {To achieve reliable packet transmission over a wireless link without feedback, we propose a layered coding approach that uses error-correction coding within each packet and erasure-correction coding across the packets. This layered approach is also applicable to an end-to-end data transport over a network where a wireless link is the performance bottleneck. We investigate how to optimally combine the strengths of error- and erasure-correction coding to optimize the system performance with a given resource constraint, or to maximize the resource utilization efficiency subject to a prescribed performance. Our results determine the optimum tradeoff in splitting redundancy between error-correction coding and erasure-correction codes, which depends on the fading statistics and the average signal to noise ratio (SNR) of the wireless channel. For severe fading channels, such as Rayleigh fading channels, the tradeoff leans towards more redundancy on erasure-correction coding across packets, and less so on error-correction coding within each packet. For channels with better fading conditions, more redundancy can be spent on error-correction coding. The analysis has been extended to a limiting case with a large number of packets, and a scenario where only discrete rates are available via a finite number of transmission modes. {\textcopyright} 2008 IEEE.},
author = {Berger, Christian R. and Zhou, Shengli and Wen, Yonggang and Willett, Peter and Pattipati, Krishna},
doi = {10.1109/T-WC.2008.070581},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berger et al. - 2008 - Optimizing joint erasure- and error-correction coding for wireless packet transmissions.pdf:pdf},
issn = {15361276},
journal = {IEEE Trans. Wirel. Commun.},
keywords = {Adaptive modulation and coding,Fountain codes,Inter- and intra-packet coding,Layered coding,Reliable transmission},
month = {nov},
number = {11},
pages = {4586--4595},
title = {{Optimizing joint erasure- and error-correction coding for wireless packet transmissions}},
volume = {7},
year = {2008}
}
@article{Burshtein2004a,
author = {Burshtein, David and Miller, Gadi},
doi = {10.1109/TIT.2004.836694},
issn = {00189448},
journal = {IEEE Trans. Inf. Theory},
month = {nov},
number = {11},
pages = {2837--2844},
title = {{An efficient maximum-likelihood decoding of LDPC codes over the binary erasure channel}},
volume = {50},
year = {2004}
}

@article{Alessi2020,
abstract = {Interplanetary networks are affected by long propagation delays, intermittent connectivity, possible packet losses due to residual errors, and other impairments. To cope with these challenges, the delay-/disruption-tolerant networking (DTN) architecture utilizes the Licklider transmission protocol (LTP) as convergence layer on space links. The LTP reliable service (red) relies on Automatic Repeat reQuest, but very long propagation delays make packet layer forward error correcting (PL-FEC) codes very appealing to protect LTP segments from losses. The key advantage of FEC is that LTP retransmissions would be limited to the unlikely case of decoding failures. To this end, a new FEC-based protocol, to be inserted immediately below LTP, the erasure coding link service adapter (ECLSA), is presented here. ECLSA is completely transparent to LTP, relies on two alternative external libraries for coding/decoding, LibecDLR and OpenFEC, both using low density parity check codes and it is fully integrated with the ION DTN software package of NASA-JPL. This paper aims to provide a solid description of ECLSA, including features functional in a real deployment (such as the dynamic selection of codes). Performance is evaluated at the end of the paper, with nearly ideal results. ECLSA is released as free software and is already included in the 'contrib' section of ION.},
annote = {RFC5170 are random codes (random different columns). We cannot use Fvn module for incidence calculations
ML (gaussian elim.) vs IT (trivial) decoding algorithm. We can use hybrid (start with IT and continue with ML)
Very important is Fig.13},
author = {Alessi, Nicola and Caini, Carlo and {De Cola}, Tomaso and Raminella, Marco},
doi = {10.1109/TAES.2019.2916271},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alessi et al. - 2020 - Packet Layer Erasure Coding in Interplanetary Links The LTP Erasure Coding Link Service Adapter.pdf:pdf},
issn = {15579603},
journal = {IEEE Trans. Aerosp. Electron. Syst.},
keywords = {Delay-/disruption-tolerant networking (DTN),InterPlanetary Networking (IPN),Licklider transmission protocol (LTP),low density parity check (LDPC) codes,upper layer forward error correcting (FEC)},
month = {feb},
number = {1},
pages = {403--414},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Packet Layer Erasure Coding in Interplanetary Links: The LTP Erasure Coding Link Service Adapter}},
volume = {56},
year = {2020}
}
@article{DeCola2010,
abstract = {Achieving reliable communications in deep space environments poses formidable networking challenges because of the extreme physical medium peculiarities. In this view, two possible approaches can be considered to carry out reliable data transfers over deep space channels: automatic repeat request schemes and packet layer coding algorithms applied with long erasure codes. In this respect, this article surveys the mechanisms currently available from the Consultative Committee for Space Data Systems protocol stack, by reserving special attention, on one hand, to the ARQ schemes currently implemented at the application layer and, on the other hand, to the potential offered by erasure coding schemes. A comparative analysis gives some insights about the performance improvements the packet layer coding methodology can bring. In particular, the results show that the use of erasure coding is able to attain more satisfactory performance results than ARQ-based schemes in terms of reliability, data transfer delay, resource network utilization, and power consumption. {\textcopyright} 2010 IEEE.},
author = {{De Cola}, Tomaso and Marchese, Mario},
doi = {10.1109/MWC.2010.5450661},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Cola, Marchese - 2010 - Reliable data delivery over deep space networks Benefits of long erasure codes over arq strategies.pdf:pdf},
issn = {15361284},
journal = {IEEE Wirel. Commun.},
month = {apr},
number = {2},
pages = {57--65},
title = {{Reliable data delivery over deep space networks: Benefits of long erasure codes over arq strategies}},
volume = {17},
year = {2010}
}
@article{GuilleniFabregas2006,
abstract = {In this correspondence, we study an M-ary block-erasure channel with B blocks, where with probability $\epsilon$ a block of L coded symbols is erased. The behavior of the error probability of coded systems over such channels is studied, and we show that, if the code is diversity-wise maximum-distance separable, its word error probability is equal to the outage probability, which admits a very simple expression. This correspondence is intended to complement the error probability analysis in previous work by Lapidoth and shed some light on the design of coding schemes for nonergodic channels. {\textcopyright} 2006 IEEE.},
author = {{Guill{\'{e}}n i F{\`{a}}bregas}, Albert},
doi = {10.1109/TIT.2006.883556},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guill{\'{e}}n i F{\`{a}}bregas - 2006 - Coding in the block-erasure channel.pdf:pdf},
issn = {00189448},
journal = {IEEE Trans. Inf. Theory},
keywords = {Diversity,Erasure channels,Error probability,Maximum-distance separable (MDS) codes,Maximum-likelihood (ML) decoding,Non-ergodic channels,Outage probability},
month = {nov},
number = {11},
pages = {5116--5121},
title = {{Coding in the block-erasure channel}},
volume = {52},
year = {2006}
}
@article{Tang2020,
abstract = {Recently, a new polynomial basis over finite fields was proposed such that the computational complexity of the fast Fourier transform (FFT) is O(n$\backslash$log n). Based on FFTs, the encoding and decoding algorithms for Reed-Solomon (RS) codes were proposed, which are shown to have the lowest computational complexity in the literature. However, these algorithms require that the code length and the number of parity symbols must be power of two. In this letter, we present the encoding and decoding algorithms for arbitrary RS codes based on FFTs. Furthermore, these new algorithms also reach the best known complexity bound.},
author = {Tang, Nianqi and Lin, Yun},
doi = {10.1109/LCOMM.2020.2965453},
issn = {15582558},
journal = {IEEE Commun. Lett.},
keywords = {Decoding algorithm,Fast fourier transform,Reed-solomon codes},
month = {apr},
number = {4},
pages = {716--719},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Fast Encoding and Decoding Algorithms for Arbitrary F2m}},
volume = {24},
year = {2020}
}

@article{Mattoussi2019,
abstract = {Hybrid broadcast broadband TV is a technique providing Push-VoD services over an interactive hybrid TV. These services are broadcast using a file delivery protocol (FDP), which includes different coding strategies to ensure reliable delivery. This protocol is characterized by three levels of data representation giving rise to segmentation of packet losses, which may result in poor recovery capabilities. This paper provides a first thorough investigation of the coding FDP framework for reliable delivery of Push-VoD service over DVB networks. We propose Markov modeling for characterizing inter-layer loss propagation within FDP on a wide variety of burst erasure channels. Based on this analytical analysis and a simulation study, we determine the possible recovering areas and the accurate loss measurements within FDP. The latter is then used to effectively investigate and configure the different coding strategies provided within FDP. In addition, we present a suitable recovering strategy for FDP, which guarantees transmission robustness against the broadcast network impairments.},
author = {Mattoussi, Ferdaouss and Crussiere, Matthieu and Helard, Jean Francois and Zaharia, Gheorghe},
doi = {10.1109/ACCESS.2019.2893756},
issn = {21693536},
journal = {IEEE Access},
keywords = {AL-FEC,DVB,HbbTV,Markov chain,Push-VoD services,repetition code},
pages = {15489--15508},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Analysis of Coding Strategies Within File Delivery Protocol Framework for HbbTV Based Push-VoD Services over DVB Networks}},
volume = {7},
year = {2019}
}
@article{Tsigkanos2020,
abstract = {Nowadays, hyperspectral imaging is recognized as a cornerstone remote sensing technology. Next generation, high-speed airborne, and space-borne imagers have increased resolution, resulting in an explosive growth in data volume and instrument data rate in the range of gigapixel per second. This competes with limited on-board resources and bandwidth, making hyperspectral image compression a mission critical on-board processing task. At the same time, the 'new space' trend is emerging, where launch costs decrease, and agile approaches are exploited building smallsats using commercial-off-the-shelf (COTS) parts. In this contribution, we introduce a high-performance parallel implementation of the CCSDS-123.0-B-1 hyperspectral compression algorithm targeting SRAM field-programmable gate array (FPGA) technology. The architecture exploits image segmentation to provide the robustness to data corruption and enables scalable throughput performance by leveraging segment-level parallelism. Furthermore, we exploit the capabilities of a COTS FPGA system-on-chip (SoC) device to optimize size, weight, power, and cost (SWaP-C). The architecture partitions a hyperspectral cube stored in a DRAM framebuffer into segments, compressing them in parallel using a flexible software scheduler hosted in the SoC CPU and several compressor accelerator cores in the FPGA fabric. A 5-core implementation demonstrated on a Zynq-7045 FPGA achieves a throughput performance of 1387 Msamples/s [22.2 Gb/s at 16 bits per pixel per band (bpppb)] and outperforms previous implementations in equivalent FPGA technology, allowing seamless integration with next-generation hyperspectral sensors.},
author = {Tsigkanos, Antonis and Kranitis, Nektarios and Theodoropoulos, DImitris and Paschalis, Antonios},
doi = {10.1109/TVLSI.2020.3020164},
issn = {15579999},
journal = {IEEE Trans. Very Large Scale Integr. Syst.},
keywords = {Consultative Committee for Space Data Systems (CCS,field-programmable gate array (FPGA),hyperspectral compression,on-board data processing,system-on-chip (SoC)},
month = {nov},
number = {11},
pages = {2397--2409},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{High-Performance COTS FPGA SoC for Parallel Hyperspectral Image Compression with CCSDS-123.0-B-1}},
volume = {28},
year = {2020}
}


@inproceedings{Schmidt2018,
abstract = {Direct optical downlinks from small LEO spacecraft to Earth have the potential to solve the increasing demands for higher data rates due to increased mission requirements. The Institute of Communications and Navigation of the German Aerospace Center (DLR) has been working since more than 10 years on the development and demonstration of highly compact and lightweight experimental terminals to enable optical communications for small LEO spacecraft. In the framework of the OSIRIS program (Optical Space Infrared Downlink System), the optical communication payload for DLR's BiROS satellite has been developed. Launched in 2016, BiROS and OSIRIS will demonstrate their performance in a measurement campaign in 2017. This paper will give an overview over the program OSIRIS and the development roadmap.},
author = {Schmidt, Christopher and Fuchs, Christian},
booktitle = {2017 IEEE Int. Conf. Sp. Opt. Syst. Appl. ICSOS 2017},
doi = {10.1109/ICSOS.2017.8357205},
isbn = {9781509065110},
keywords = {Free-Space Optics,Optical Communication,Satellite Communication},
month = {may},
pages = {19--22},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{The OSIRIS program - First results and Outlook}},
year = {2018}
}
@article{Courtade2011,
abstract = {For a block-fading channel, this paper optimizes the allocation of redundancy between packet-level erasure coding (which provides additional packets to compensate for packet loss) and physical layer channel coding (which lowers the probability of packet loss). After some manipulation, standard optimization techniques determine the trade-off between the amount of packet-level erasure coding and physical-layer channel coding that minimizes the transmit power required to provide reliable communication. Our results indicate that the optimal combination of packet-level erasure coding and physical-layer coding provides a significant benefit over pure physical-layer coding when no form of channel diversity is present within a packet transmission. However, the benefit of including packet-level erasure coding diminishes as more diversity becomes available within a packet transmission. Even with no diversity within a packet transmission, this paper shows that as the total redundancy becomes large the optimal redundancy for packet-level erasure coding reaches a limit while the optimal redundancy for physical-layer coding continues to increase. Hence providing limitless redundancy at the packet-level with rateless codes such as fountain codes is not the best use of limitless redundancy for block-fading channels. {\textcopyright} 2011 IEEE.},
author = {Courtade, Thomas A. and Wesel, Richard D.},
doi = {10.1109/TCOMM.2011.062311.090277},
file = {:home/mitsor/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Courtade, Wesel - 2011 - Optimal allocation of redundancy between packet-level erasure coding and physical-layer channel coding in fadin.pdf:pdf},
issn = {00906778},
journal = {IEEE Trans. Commun.},
keywords = {Cross-layer coding,Rayleigh fading channels,cross-layer optimization,rateless codes,selection diversity},
month = {aug},
number = {8},
pages = {2101--2109},
title = {{Optimal allocation of redundancy between packet-level erasure coding and physical-layer channel coding in fading channels}},
volume = {59},
year = {2011}
}
@misc{Scott,
author = {Scott, K and Burleigh, S},
title = {{Bundle Protocol Specification}},
url = {https://www.rfc-editor.org/rfc/rfc5050.txt},
urldate = {2020-12-21}
}
@article{Richardson2001,
author = {Richardson, Thomas J and Urbanke, R{\"{u}}diger L},
journal = {IEEE Trans. Inf. Theory},
keywords = {Index Terms-Binary erasure channel,decoding,encoding,parity check,random graphs,sparse matrices,turbo codes},
number = {2},
title = {{Efficient Encoding of Low-Density Parity-Check Codes}},
volume = {47},
year = {2001}
}
@inproceedings{Edwards2019a,
author={B. L. {Edwards} and R. {Daddato} and K. {Schulz} and R. {Alliss} and J. {Hamkins} and D. {Giggenbach} and B. {Robinson} and L. {Braatz}},
  booktitle={2019 IEEE Int. Conf. Space Opt. Syst.Appl. (ICSOS)}, 
  title={An Update on the CCSDS Optical Communications Working Group Interoperability Standards}, 
  year={2019},
  volume={},
  number={},
  pages={1-9},
  month = {oct},
  doi={10.1109/ICSOS45490.2019.8978979}}







@inproceedings{Poulenard2019,
author = {S. Poulenard and B. Gadat and J. F. Chouteau and T. Anfray and C. Poulliat and C. Jego and O. Hartmann and G. Artaud and H. Meric},
title = {{Forward error correcting code for high data rate LEO satellite optical downlinks}},
volume = {11180},
booktitle = {International Conference on Space Optics — ICSO 2018},
editor = {Zoran Sodnik and Nikos Karafolas and Bruno Cugny},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {2029 -- 2038},
year = {2019},
doi = {10.1117/12.2536120},
URL = {https://doi.org/10.1117/12.2536120}
}